"""
QA/QC test for new visualizations in saocom_analysis_clean.ipynb
Tests sections 12.1 through 12.11
"""

import sys
import traceback
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Change to project directory
import os
os.chdir('C:/Users/colto/Documents/GitHub/saocom_project')
sys.path.insert(0, str(Path.cwd() / 'src'))

print("="*80)
print("QA/QC TEST - NEW VISUALIZATIONS")
print("="*80)
print()

# Track test results
tests = []

try:
    print("TEST 1: Import all required libraries")
    print("-"*80)
    import numpy as np
    import pandas as pd
    import geopandas as gpd
    import rasterio
    from rasterio.transform import from_bounds, rowcol
    from shapely.geometry import Point
    import matplotlib.pyplot as plt
    import seaborn as sns

    from utils import read_raster_meta, load_dem_array
    from preprocessing import (
        resample_to_10m, sample_raster_at_points,
        create_difference_grid, calculate_terrain_derivatives
    )
    from calibration import calibrate_heights
    from outlier_detection import (
        remove_isolated_knn, score_outliers_isolation_forest,
        filter_by_score_iqr
    )
    from statistics_prog import nmad

    print("[PASS] All imports successful")
    tests.append(("Imports", True, None))

except Exception as e:
    print(f"[FAIL] Import error: {e}")
    tests.append(("Imports", False, str(e)))
    sys.exit(1)

print()

try:
    print("TEST 2: Load and prepare data (reproduce workflow)")
    print("-"*80)

    # Setup paths
    DATA_DIR = Path('./data')
    RESULTS_DIR = Path('./results')
    IMAGES_DIR = Path('./images')

    SAOCOM_CSV = DATA_DIR / 'saocom_csv' / 'verona_mstgraph_ASI056_weighted_Tcoh00_Bn0_202307-202507.csv'
    TINITALY_DEM = DATA_DIR / 'tinitaly' / 'tinitaly_crop.tif'
    COPERNICUS_DEM = DATA_DIR / 'copernicus.tif'

    # Load SAOCOM
    saocom_df = pd.read_csv(SAOCOM_CSV)
    lat_col = 'LAT2' if 'LAT2' in saocom_df.columns else 'LAT'
    lon_col = 'LON2' if 'LON2' in saocom_df.columns else 'LON'

    geometry = [Point(xy) for xy in zip(saocom_df[lon_col], saocom_df[lat_col])]
    saocom_gdf = gpd.GeoDataFrame(saocom_df, geometry=geometry, crs='EPSG:4326')
    saocom_gdf = saocom_gdf.to_crs('EPSG:32632')
    saocom_gdf['HEIGHT_RELATIVE'] = saocom_gdf['HEIGHT']

    # Spatial filter
    saocom_gdf = remove_isolated_knn(saocom_gdf, k=100, distance_threshold=1000)

    # Grid setup
    bounds = saocom_gdf.total_bounds
    RESOLUTION = 10.0
    grid_width = int((bounds[2] - bounds[0]) / RESOLUTION)
    grid_height = int((bounds[3] - bounds[1]) / RESOLUTION)
    target_transform = from_bounds(bounds[0], bounds[1], bounds[2], bounds[3], grid_width, grid_height)
    TARGET_CRS = 'EPSG:32632'

    # Resample DEMs
    tinitaly_10m, _ = resample_to_10m(
        src_path=TINITALY_DEM,
        output_path=RESULTS_DIR / 'tinitaly_10m.tif',
        target_transform=target_transform,
        target_crs=TARGET_CRS,
        grid_height=grid_height,
        grid_width=grid_width
    )

    copernicus_10m, _ = resample_to_10m(
        src_path=COPERNICUS_DEM,
        output_path=RESULTS_DIR / 'copernicus_10m.tif',
        target_transform=target_transform,
        target_crs=TARGET_CRS,
        grid_height=grid_height,
        grid_width=grid_width
    )

    # Sample DEMs
    rows, cols = rowcol(target_transform, saocom_gdf.geometry.x, saocom_gdf.geometry.y)
    rows = np.array(rows, dtype=int)
    cols = np.array(cols, dtype=int)
    inbounds = (
        (rows >= 0) & (rows < grid_height) &
        (cols >= 0) & (cols < grid_width)
    )

    saocom_gdf['tinitaly_height'] = sample_raster_at_points(tinitaly_10m, rows, cols, inbounds, -9999)
    saocom_gdf['copernicus_height'] = sample_raster_at_points(copernicus_10m, rows, cols, inbounds, -9999)

    # Calibrate
    offset_tin, rmse_tin, n_tin = calibrate_heights(
        saocom_gdf, ref_col='tinitaly_height', out_col='HEIGHT_ABSOLUTE_TIN', coherence_threshold=0.8
    )
    saocom_gdf['diff_tinitaly'] = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']

    offset_cop, rmse_cop, n_cop = calibrate_heights(
        saocom_gdf, ref_col='copernicus_height', out_col='HEIGHT_ABSOLUTE_COP', coherence_threshold=0.8
    )
    saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height']

    # Outlier detection
    saocom_scored = score_outliers_isolation_forest(
        saocom_gdf, residual_col='diff_tinitaly', contamination=0.05, n_estimators=100, random_state=42
    )
    saocom_cleaned, outliers = filter_by_score_iqr(saocom_scored, iqr_multiplier=1.5)

    # Terrain derivatives
    slope_tin, aspect_tin = calculate_terrain_derivatives(tinitaly_10m, cellsize=10, nodata=-9999)

    rows_clean, cols_clean = rowcol(target_transform, saocom_cleaned.geometry.x, saocom_cleaned.geometry.y)
    rows_clean = np.array(rows_clean, dtype=int)
    cols_clean = np.array(cols_clean, dtype=int)
    inbounds_clean = (
        (rows_clean >= 0) & (rows_clean < grid_height) &
        (cols_clean >= 0) & (cols_clean < grid_width)
    )

    saocom_cleaned['slope_tin'] = sample_raster_at_points(slope_tin, rows_clean, cols_clean, inbounds_clean, -9999)

    # Slope categories
    slope_bins = [0, 5, 15, 30, 90]
    slope_labels = ['Flat (0-5째)', 'Gentle (5-15째)', 'Moderate (15-30째)', 'Steep (>30째)']
    saocom_cleaned['slope_category'] = pd.cut(saocom_cleaned['slope_tin'], bins=slope_bins, labels=slope_labels)

    # Calculate residuals
    residuals_tin = saocom_cleaned['diff_tinitaly'].dropna()
    residuals_cop = saocom_cleaned['diff_copernicus'].dropna()
    nmad_tin = nmad(residuals_tin)
    nmad_cop = nmad(residuals_cop)

    # Slope stats
    slope_stats = saocom_cleaned.groupby('slope_category')['diff_tinitaly'].agg([
        ('count', 'count'),
        ('mean', 'mean'),
        ('std', 'std'),
        ('nmad', lambda x: nmad(x.dropna()))
    ]).round(2)

    # Valid data for scatter plots
    valid_tin = saocom_cleaned[['HEIGHT_ABSOLUTE_TIN', 'tinitaly_height']].dropna()
    valid_cop = saocom_cleaned[['HEIGHT_ABSOLUTE_COP', 'copernicus_height']].dropna()

    print(f"[PASS] Data loaded and processed")
    print(f"  SAOCOM points: {len(saocom_gdf):,}")
    print(f"  Cleaned points: {len(saocom_cleaned):,}")
    print(f"  Grid: {grid_width} x {grid_height}")
    print(f"  NMAD (TINItaly): {nmad_tin:.2f} m")
    tests.append(("Data Preparation", True, None))

except Exception as e:
    print(f"[FAIL] Data preparation error: {e}")
    traceback.print_exc()
    tests.append(("Data Preparation", False, str(e)))
    sys.exit(1)

print()

# Test each new visualization
viz_tests = [
    ("12.1 Spatial Coverage", """
fig, ax = plt.subplots(figsize=(12, 10))
with rasterio.open(TINITALY_DEM) as src:
    dem_bounds = src.bounds
    import rasterio.warp
    dem_bounds_utm = rasterio.warp.transform_bounds(src.crs, TARGET_CRS, *dem_bounds)
    from matplotlib.patches import Rectangle
    ax.add_patch(Rectangle(
        (dem_bounds_utm[0], dem_bounds_utm[1]),
        dem_bounds_utm[2] - dem_bounds_utm[0],
        dem_bounds_utm[3] - dem_bounds_utm[1],
        linewidth=3, edgecolor='blue', facecolor='none', label='TINItaly Extent'
    ))
saocom_cleaned.plot(ax=ax, markersize=1, color='red', alpha=0.5, label='SAOCOM Points')
hull = saocom_cleaned.geometry.unary_union.convex_hull
hull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)
hull_gdf.boundary.plot(ax=ax, color='green', linewidth=2, linestyle='--', label='Study Area Hull')
ax.set_xlabel('UTM Easting (m)')
ax.set_ylabel('UTM Northing (m)')
ax.set_title('Spatial Coverage: SAOCOM vs TINItaly DEM')
ax.legend()
ax.grid(True, alpha=0.3)
ax.set_aspect('equal')
plt.close()
"""),

    ("12.2 Gridded Comparison", """
fig, ax = plt.subplots(figsize=(10, 8))
valid_tin_pts = saocom_cleaned[saocom_cleaned['diff_tinitaly'].notna()]
if len(valid_tin_pts) > 0:
    vmin, vmax = np.percentile(valid_tin_pts['diff_tinitaly'], [2, 98])
    hb = ax.hexbin(
        valid_tin_pts.geometry.x, valid_tin_pts.geometry.y,
        C=valid_tin_pts['diff_tinitaly'],
        gridsize=100, cmap='RdBu_r', vmin=vmin, vmax=vmax,
        reduce_C_function=np.mean
    )
plt.close()
"""),

    ("12.3 Hexbin Density", """
fig, ax = plt.subplots(figsize=(10, 8))
hb = ax.hexbin(valid_tin['tinitaly_height'], valid_tin['HEIGHT_ABSOLUTE_TIN'],
               gridsize=50, cmap='YlOrRd', mincnt=1, edgecolors='none')
lims = [valid_tin['tinitaly_height'].min(), valid_tin['tinitaly_height'].max()]
ax.plot(lims, lims, 'k--', alpha=0.5, linewidth=2)
plt.close()
"""),

    ("12.4 2D Histogram", """
fig, ax = plt.subplots(figsize=(10, 8))
h = ax.hist2d(valid_tin['tinitaly_height'], valid_tin['HEIGHT_ABSOLUTE_TIN'],
              bins=100, cmap='viridis', cmin=1)
plt.close()
"""),

    ("12.5 Violin Plot", """
fig, ax = plt.subplots(figsize=(12, 7))
slope_data = saocom_cleaned[['slope_category', 'diff_tinitaly']].dropna()
parts = ax.violinplot(
    [slope_data[slope_data['slope_category'] == cat]['diff_tinitaly'].values
     for cat in slope_labels],
    positions=range(len(slope_labels)),
    showmeans=True, showmedians=True, widths=0.7
)
plt.close()
"""),

    ("12.6 Residuals vs Coherence", """
fig, ax = plt.subplots(figsize=(10, 6))
valid_data = saocom_cleaned[['COHER', 'diff_tinitaly']].dropna()
ax.scatter(valid_data['COHER'], valid_data['diff_tinitaly'], s=5, alpha=0.3)
ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
plt.close()
"""),

    ("12.7 Terrain Slope Map", """
fig, ax = plt.subplots(figsize=(12, 10))
slope_plot = ax.imshow(slope_tin, cmap='terrain', vmin=0, vmax=45)
ax.set_title('Terrain Slope from TINItaly DEM')
ax.axis('off')
plt.close()
"""),

    ("12.8 Reference DEM Comparison", """
dem_diff = tinitaly_10m - copernicus_10m
dem_diff[tinitaly_10m == -9999] = np.nan
dem_diff[copernicus_10m == -9999] = np.nan
fig, axes = plt.subplots(2, 2, figsize=(18, 16))
tin_plot = tinitaly_10m.copy()
tin_plot[tin_plot == -9999] = np.nan
axes[0, 0].imshow(tin_plot, cmap='terrain')
axes[0, 0].set_title('TINItaly DEM')
axes[0, 0].axis('off')
plt.close()
"""),

    ("12.9 Coverage Grid", """
coverage_grid = np.zeros((grid_height, grid_width), dtype=bool)
for idx, row in saocom_cleaned.head(1000).iterrows():  # Test with subset
    r, c = rowcol(target_transform, row.geometry.x, row.geometry.y)
    r, c = int(r), int(c)
    if 0 <= r < grid_height and 0 <= c < grid_width:
        coverage_grid[r, c] = True
fig, ax = plt.subplots(figsize=(10, 8))
ax.imshow(coverage_grid, cmap='binary')
ax.set_title('Coverage Grid')
plt.close()
"""),

    ("12.10 Elevation Bins", """
height_bins = [0, 200, 400, 600, 800, 1000]
height_labels = ['0-200m', '200-400m', '400-600m', '600-800m', '800-1000m']
saocom_cleaned['height_category'] = pd.cut(
    saocom_cleaned['tinitaly_height'], bins=height_bins, labels=height_labels
)
height_stats = saocom_cleaned.groupby('height_category')['diff_tinitaly'].agg([
    ('count', 'count'), ('mean', 'mean'), ('std', 'std'),
    ('nmad', lambda x: nmad(x.dropna()))
]).round(2)
fig, ax = plt.subplots(figsize=(10, 6))
height_stats['nmad'].plot(kind='bar', ax=ax)
plt.close()
"""),

    ("12.11 Summary Dashboard", """
fig = plt.figure(figsize=(20, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
ax1 = fig.add_subplot(gs[0, 0])
saocom_cleaned.head(1000).plot(ax=ax1, markersize=0.5, color='blue', alpha=0.3)
ax1.set_title('Point Distribution')
plt.close()
"""),
]

print("TEST 3: Execute new visualization code")
print("-"*80)

for test_name, code in viz_tests:
    try:
        print(f"Testing {test_name}...", end=" ")
        exec(code)
        print("[PASS]")
        tests.append((test_name, True, None))
    except Exception as e:
        print(f"[FAIL]")
        print(f"  Error: {e}")
        tests.append((test_name, False, str(e)))
        if "--verbose" in sys.argv:
            traceback.print_exc()

print()
print("="*80)
print("QA/QC TEST SUMMARY")
print("="*80)

passed = sum(1 for _, status, _ in tests if status)
failed = sum(1 for _, status, _ in tests if not status)

for test_name, status, error in tests:
    symbol = "[PASS]" if status else "[FAIL]"
    print(f"{symbol} {test_name:40s}", end="")
    if error and not status:
        print(f" - {error[:50]}")
    else:
        print()

print()
print(f"Total tests: {len(tests)}")
print(f"Passed: {passed}")
print(f"Failed: {failed}")
print()

if failed == 0:
    print("="*80)
    print("ALL TESTS PASSED - NEW VISUALIZATIONS ARE WORKING")
    print("="*80)
    print()
    print("The new visualizations in saocom_analysis_clean.ipynb are:")
    print("  - Properly coded")
    print("  - Execute without errors")
    print("  - Compatible with actual data")
    print("  - Ready for use")
    sys.exit(0)
else:
    print("="*80)
    print(f"SOME TESTS FAILED ({failed} failures)")
    print("="*80)
    print()
    print("Review errors above and fix issues in notebook")
    sys.exit(1)
