{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# !pip install geopandas rasterio shapely scipy scikit-learn scikit-image seaborn matplotlib_scalebar"
   ],
   "id": "a055d97c9fc979d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Environment location:\", os.path.dirname(sys.executable))"
   ],
   "id": "b10b70589832a5e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ],
   "id": "4bb2c5d80d8a6e09"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from unittest.mock import sentinel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, calculate_default_transform\n",
    "from rasterio.transform import from_bounds, rowcol\n",
    "from rasterio.mask import mask\n",
    "from rasterio import features\n",
    "from shapely.geometry import Point, box, shape\n",
    "from rasterio.features import shapes\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn as sns\n",
    "from dbfread import DBF\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "print(DATA_DIR)\n",
    "\n",
    "COHERENCE_THRESHOLD = 0.3\n",
    "NODATA = -9999\n",
    "GRID_SIZE = 10\n",
    "TARGET_CRS = 'EPSG:32632'\n",
    "\n",
    "CORINE_CLASSES = {\n",
    "    111: 'Continuous urban fabric', 112: 'Discontinuous urban fabric',\n",
    "    121: 'Industrial or commercial units', 122: 'Road and rail networks and associated land',\n",
    "    123: 'Port areas', 124: 'Airports', 131: 'Mineral extraction sites',\n",
    "    132: 'Dump sites', 133: 'Construction sites', 141: 'Green urban areas',\n",
    "    142: 'Sport and leisure facilities', 211: 'Non-irrigated arable land',\n",
    "    212: 'Permanently irrigated land', 213: 'Rice fields', 221: 'Vineyards',\n",
    "    222: 'Fruit trees and berry plantations', 223: 'Olive groves',\n",
    "    231: 'Pastures', 241: 'Annual crops associated with permanent crops',\n",
    "    242: 'Complex cultivation patterns', 243: 'Agriculture/natural vegetation mix',\n",
    "    244: 'Agro-forestry areas', 311: 'Broad-leaved forest',\n",
    "    312: 'Coniferous forest', 313: 'Mixed forest', 321: 'Natural grasslands',\n",
    "    322: 'Moors and heathland', 323: 'Sclerophyllous vegetation',\n",
    "    324: 'Transitional woodland-shrub', 331: 'Beaches, dunes, sands',\n",
    "    332: 'Bare rocks', 333: 'Sparsely vegetated areas', 334: 'Burnt areas',\n",
    "    335: 'Glaciers and perpetual snow', 411: 'Inland marshes',\n",
    "    412: 'Peat bogs', 421: 'Salt marshes', 422: 'Salines',\n",
    "    423: 'Intertidal flats', 511: 'Water courses', 512: 'Water bodies',\n",
    "    521: 'Coastal lagoons', 522: 'Estuaries', 523: 'Sea and ocean'\n",
    "}\n",
    "\n",
    "CORINE_COLORS = {\n",
    "    111: (102, 0, 102), 112: (153, 51, 153), 121: (204, 102, 204), 122: (80, 80, 80),\n",
    "    123: (120, 120, 120), 124: (160, 160, 160), 131: (255, 0, 255), 132: (178, 34, 34),\n",
    "    133: (255, 150, 180), 141: (120, 200, 120), 142: (100, 180, 100),\n",
    "    211: (230, 230, 50), 212: (235, 200, 0), 213: (220, 180, 0), 221: (255, 140, 0),\n",
    "    222: (255, 165, 79), 223: (204, 153, 0), 231: (210, 210, 80), 241: (200, 170, 100),\n",
    "    242: (210, 160, 70), 243: (190, 150, 80), 244: (179, 143, 0),\n",
    "    311: (0, 153, 102), 312: (0, 102, 76), 313: (0, 128, 128), 321: (150, 220, 150),\n",
    "    322: (102, 204, 153), 323: (130, 180, 130), 324: (51, 153, 102), 331: (210, 180, 140),\n",
    "    332: (140, 140, 140), 333: (170, 170, 120), 334: (40, 40, 40), 335: (180, 210, 230),\n",
    "    411: (120, 170, 230), 412: (80, 140, 220), 421: (150, 190, 240), 422: (140, 170, 210),\n",
    "    423: (100, 160, 210), 511: (0, 102, 204), 512: (0, 76, 153), 521: (51, 102, 153),\n",
    "    522: (0, 51, 102), 523: (0, 25, 76)\n",
    "}\n",
    "CORINE_COLORS_MPL = {k: (r/255, g/255, b/255) for k, (r, g, b) in CORINE_COLORS.items()}\n",
    "\n",
    "file_discovery = {\n",
    "    'saocom': (\"saocom_csv\", \"*.csv\"),\n",
    "    'tinitaly': (\"tinitaly\", \"*.tif\"),\n",
    "    'copernicus': (\"copernicus\", \"*.tif\"),\n",
    "    'corine': (\"ground_cover\", \"*.tif\"),\n",
    "    'sentinel': (\"sentinel_data\", \"*.tif\")\n",
    "}\n",
    "for key, (subdir, pattern) in file_discovery.items():\n",
    "    files = list((DATA_DIR / subdir).glob(pattern))\n",
    "    globals()[f'{key}_path'] = files[0] if files else None\n",
    "\n",
    "corine_dbf_path = None\n",
    "if corine_path:\n",
    "    candidates = list((DATA_DIR / \"ground_cover\").glob(f\"{corine_path.name}.vat.dbf\"))\n",
    "    corine_dbf_path = candidates[0] if candidates else None"
   ],
   "id": "7e3e2f5852301c7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ],
   "id": "f31713848c6ab6a2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv(saocom_path)\n",
    "df.columns = ['ID', 'SVET', 'LVET', 'LAT', 'LAT2', 'LON', 'LON2', 'HEIGHT', 'HEIGHT_WRT_DEM', 'SIGMA_HEIGHT', 'COHER']\n",
    "\n",
    "for col in ['LAT', 'LON', 'LAT2', 'LON2', 'HEIGHT', 'COHER']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.dropna(subset=['LAT', 'LON', 'LAT2', 'LON2', 'HEIGHT', 'COHER']).query('LAT2 != 0 and LON2 != 0')\n",
    "df.rename(columns={'LAT': 'LAT_old', 'LON': 'LON_old', 'LAT2': 'LAT', 'LON2': 'LON'}, inplace=True)\n",
    "df_filtered = df[df['COHER'] >= COHERENCE_THRESHOLD]\n",
    "\n",
    "saocom_gdf = gpd.GeoDataFrame(\n",
    "    df_filtered,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(df_filtered['LON'], df_filtered['LAT'])],\n",
    "    crs='EPSG:4326'\n",
    ").to_crs(TARGET_CRS)\n",
    "saocom_gdf['x_utm'] = saocom_gdf.geometry.x\n",
    "saocom_gdf['y_utm'] = saocom_gdf.geometry.y\n",
    "\n",
    "def _read_raster_meta(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        return src.crs, src.res, src.bounds, src.nodata\n",
    "\n",
    "tinitaly_crs, tinitaly_res, tinitaly_bounds, tinitaly_nodata = _read_raster_meta(tinitaly_path)\n",
    "copernicus_crs, copernicus_res, copernicus_bounds, copernicus_nodata = _read_raster_meta(copernicus_path)"
   ],
   "id": "1caf872440003888",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HORIZONTAL DATUM VERIFICATION"
   ],
   "id": "dc465fd03cf591b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def remove_isolated_knn(gdf, k=100, distance_threshold=1000):\n",
    "    coords = np.column_stack((gdf.geometry.x, gdf.geometry.y))\n",
    "    distances = NearestNeighbors(n_neighbors=k+1).fit(coords).kneighbors(coords, return_distance=True)[0]\n",
    "    print(len(distances))\n",
    "    return gdf[(distances[:, 1:].mean(1) < distance_threshold)].reset_index(drop=True)\n",
    "\n",
    "# ---- Horizontal datum verification\n",
    "tinitaly_needs_reproject  = str(tinitaly_crs)  != TARGET_CRS\n",
    "copernicus_needs_reproject = str(copernicus_crs) != TARGET_CRS\n",
    "# corine_needs_reproject   = str(corine_crs)   != TARGET_CRS\n",
    "\n",
    "# ---- Vertical datum verification\n",
    "tinitaly_wkt, copernicus_wkt = tinitaly_crs.to_wkt(), copernicus_crs.to_wkt()\n",
    "tinitaly_vertical   = ('EGM2008' in tinitaly_wkt)   or ('geoid' in tinitaly_wkt.lower())\n",
    "copernicus_vertical = ('EGM2008' in copernicus_wkt) or ('geoid' in copernicus_wkt.lower())\n",
    "\n",
    "# ---- Study area bounds / hull\n",
    "study_bounds = saocom_gdf.total_bounds  # [xmin, ymin, xmax, ymax]\n",
    "study_area_poly = box(*study_bounds)\n",
    "study_area_gdf = gpd.GeoDataFrame([1], geometry=[study_area_poly], crs=TARGET_CRS)\n",
    "# for i in range(1, 10):\n",
    "#     for j in range(1, 10):\n",
    "#         i_val = (i*50)\n",
    "#         j_val = (j*1000)\n",
    "#         print(f'{i_val}, {j_val}')\n",
    "#         _ = remove_isolated_knn(saocom_gdf, k=i_val, distance_threshold=j_val)\n",
    "saocom_gdf = remove_isolated_knn(saocom_gdf, k=5, distance_threshold=100)\n",
    "data_hull = saocom_gdf.unary_union.convex_hull\n",
    "hull_gdf = gpd.GeoDataFrame(geometry=[data_hull], crs=TARGET_CRS)\n",
    "\n",
    "# ---- 10m grid parameters\n",
    "xmin_grid, ymin_grid, xmax_grid, ymax_grid = (\n",
    "    np.floor(study_bounds[0]/GRID_SIZE)*GRID_SIZE,\n",
    "    np.floor(study_bounds[1]/GRID_SIZE)*GRID_SIZE,\n",
    "    np.ceil( study_bounds[2]/GRID_SIZE)*GRID_SIZE,\n",
    "    np.ceil( study_bounds[3]/GRID_SIZE)*GRID_SIZE\n",
    ")\n",
    "grid_width  = int((xmax_grid - xmin_grid)/GRID_SIZE)\n",
    "grid_height = int((ymax_grid - ymin_grid)/GRID_SIZE)\n",
    "target_transform = from_bounds(xmin_grid, ymin_grid, xmax_grid, ymax_grid, grid_width, grid_height)\n",
    "\n",
    "# ---- Reference dataset metadata\n",
    "reference_dems = {\n",
    "    'tinitaly_crop': {\n",
    "        'path': tinitaly_path,\n",
    "        'crs': tinitaly_crs,\n",
    "        'needs_reproject': tinitaly_needs_reproject,\n",
    "        'vertical_datum': 'WGS84 ellipsoid'\n",
    "    },\n",
    "    'copernicus': {\n",
    "        'path': copernicus_path,\n",
    "        'crs': copernicus_crs,\n",
    "        'needs_reproject': copernicus_needs_reproject,\n",
    "        'vertical_datum': 'EGM2008 geoid'\n",
    "    }\n",
    "}\n"
   ],
   "id": "1ef11f12d8fee9a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESAMPLE TO 10M"
   ],
   "id": "6987ef8171380f76"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Resample helpers (10 m)\n",
    "profile = {\n",
    "    'driver':'GTiff','dtype':'float32','width':grid_width,'height':grid_height,\n",
    "    'count':1,'crs':TARGET_CRS,'transform':target_transform,\n",
    "    'nodata':NODATA,'compress':'lzw'\n",
    "}\n",
    "\n",
    "def _resample_to_10m(src_path, out_name):\n",
    "    arr = np.full((grid_height, grid_width), NODATA, np.float32)\n",
    "    with rasterio.open(src_path) as src:\n",
    "        reproject(\n",
    "            rasterio.band(src, 1), arr,\n",
    "            src_transform=src.transform, src_crs=src.crs,\n",
    "            dst_transform=target_transform, dst_crs=TARGET_CRS,\n",
    "            resampling=Resampling.cubic,\n",
    "            src_nodata=src.nodata, dst_nodata=NODATA\n",
    "        )\n",
    "    out_path = RESULTS_DIR / out_name\n",
    "    with rasterio.open(out_path, 'w', **profile) as dst: dst.write(arr, 1)\n",
    "    return arr, out_path\n",
    "\n",
    "# --- Resample TINITALY & Copernicus\n",
    "tinitaly_10m, tinitaly_10m_path       = _resample_to_10m(tinitaly_path,  \"tinitaly_10m.tif\")\n",
    "copernicus_10m, copernicus_10m_path   = _resample_to_10m(copernicus_path,\"copernicus_10m.tif\")\n",
    "\n",
    "# --- Update reference metadata\n",
    "reference_dems['tinitaly_crop'].update(resampled_path=tinitaly_10m_path, is_10m=True)\n",
    "reference_dems['copernicus'].update(resampled_path=copernicus_10m_path, is_10m=True)\n"
   ],
   "id": "a7db7a2d091390e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE RASTERIZED MASK FROM SAOCOM CONVEX HULL"
   ],
   "id": "a0c1fc7061f83d1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Rasterized hull mask (10 m grid)\n",
    "hull_mask = features.rasterize(\n",
    "    [data_hull], out_shape=(grid_height, grid_width),\n",
    "    transform=target_transform, fill=0, all_touched=True, dtype='uint8'\n",
    ").astype(bool)\n",
    "\n",
    "def _mask_and_write(arr, out_name):\n",
    "    masked = arr.copy()\n",
    "    masked[~hull_mask] = NODATA\n",
    "    out_path = RESULTS_DIR / out_name\n",
    "    with rasterio.open(out_path, 'w', **profile) as dst: dst.write(masked, 1)\n",
    "    return masked, out_path\n",
    "\n",
    "# --- Mask + save\n",
    "tinitaly_10m,     tinitaly_masked_path   = _mask_and_write(tinitaly_10m,   \"tinitaly_10m_masked.tif\")\n",
    "copernicus_10m,   copernicus_masked_path = _mask_and_write(copernicus_10m, \"copernicus_10m_masked.tif\")\n",
    "\n",
    "# --- Update reference metadata\n",
    "reference_dems['tinitaly_crop']['masked_path'] = tinitaly_masked_path\n",
    "reference_dems['copernicus']['masked_path']    = copernicus_masked_path\n"
   ],
   "id": "45e5b2e67224677e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE REFERENCE DEMS AT SAOCOM LOCATIONS"
   ],
   "id": "1b1c4a8d3537d4c9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Sample reference DEMs at SAOCOM locations (vectorized)\n",
    "xs, ys = saocom_gdf.geometry.x.values, saocom_gdf.geometry.y.values\n",
    "rows, cols = rowcol(target_transform, xs, ys)\n",
    "inb = (rows>=0)&(rows<grid_height)&(cols>=0)&(cols<grid_width)\n",
    "\n",
    "def _sample(arr):\n",
    "    out = np.full(len(saocom_gdf), np.nan, dtype=np.float32)\n",
    "    v = arr[rows[inb], cols[inb]]\n",
    "    out[inb] = np.where(v==NODATA, np.nan, v)\n",
    "    return out\n",
    "\n",
    "saocom_gdf['tinitaly_height']   = _sample(tinitaly_10m)\n",
    "saocom_gdf['copernicus_height'] = _sample(copernicus_10m)\n",
    "saocom_gdf['HEIGHT_RELATIVE']   = saocom_gdf['HEIGHT']\n",
    "\n",
    "# --- Calibration helper (constant offset)\n",
    "def _calibrate(ref_col, out_col):\n",
    "    m = (\n",
    "        (saocom_gdf['COHER']>=0.8) &\n",
    "        saocom_gdf[ref_col].notna() &\n",
    "        saocom_gdf['HEIGHT_RELATIVE'].notna() &\n",
    "        (np.abs(saocom_gdf['HEIGHT_RELATIVE'])<1000)\n",
    "    )\n",
    "    sp = saocom_gdf[m]\n",
    "    diff = sp[ref_col] - sp['HEIGHT_RELATIVE']\n",
    "    offset = np.median(diff)\n",
    "    saocom_gdf[out_col] = saocom_gdf['HEIGHT_RELATIVE'] + offset\n",
    "    rmse = np.sqrt(np.mean((sp[ref_col] - (sp['HEIGHT_RELATIVE'] + offset))**2))\n",
    "    return offset, rmse, len(sp)\n",
    "\n",
    "# --- Calibrate to TINITALY & Copernicus\n",
    "offset_tinitaly,  rmse_tin, n_tin = _calibrate('tinitaly_height',   'HEIGHT_ABSOLUTE_TIN')\n",
    "offset_copernicus, rmse_cop, n_cop = _calibrate('copernicus_height', 'HEIGHT_ABSOLUTE_COP')\n",
    "\n",
    "# --- Concise report\n",
    "print(f\"TINITALY: n={n_tin:,}, offset={offset_tinitaly:.3f} m, RMSE={rmse_tin:.3f} m\")\n",
    "print(f\"COPERNICUS: n={n_cop:,}, offset={offset_copernicus:.3f} m, RMSE={rmse_cop:.3f} m\")\n",
    "print(\"Recommendation: Use HEIGHT_ABSOLUTE_TIN (usually lower RMSE).\")\n"
   ],
   "id": "a53c0e3977775ea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE SAOCOM COVERAGE GRID"
   ],
   "id": "26f94c9d0d90d795"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- SAOCOM coverage grid (10 m)\n",
    "saocom_rows, saocom_cols = rowcol(\n",
    "    target_transform,\n",
    "    saocom_gdf.geometry.x.values,\n",
    "    saocom_gdf.geometry.y.values\n",
    ")\n",
    "inb = (saocom_rows>=0)&(saocom_rows<grid_height)&(saocom_cols>=0)&(saocom_cols<grid_width)\n",
    "saocom_coverage = np.zeros((grid_height, grid_width), dtype=bool)\n",
    "saocom_coverage[saocom_rows[inb], saocom_cols[inb]] = True\n",
    "\n",
    "# --- Void stats (inside hull, excluding nodata)\n",
    "study_area_mask = hull_mask\n",
    "void_mask = study_area_mask & ~saocom_coverage\n",
    "\n",
    "n_total_cells     = study_area_mask.sum()\n",
    "n_occupied_cells  = (study_area_mask & saocom_coverage).sum()\n",
    "n_void_cells      = void_mask.sum()\n",
    "void_percentage   = 100 * n_void_cells / n_total_cells if n_total_cells else 0\n",
    "print(void_percentage)\n",
    "\n",
    "# --- Save void mask raster (0=data area, 1=void, 255=outside)\n",
    "void_mask_path = RESULTS_DIR / \"saocom_void_mask.tif\"\n",
    "profile_void = {**profile, 'dtype':'uint8', 'nodata':255}\n",
    "void_raster = np.where(~study_area_mask, 255, np.where(void_mask, 1, 0)).astype(np.uint8)\n",
    "\n",
    "with rasterio.open(void_mask_path, 'w', **profile_void) as dst:\n",
    "    dst.write(void_raster, 1)\n"
   ],
   "id": "5aef0bd6f5327e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD REFERENCE DEM DATA (Already in memory from Cell 4)"
   ],
   "id": "25694f9d11a365fe"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Load reference DEM data (already in memory)\n",
    "tinitaly_data   = tinitaly_10m.copy()\n",
    "copernicus_data = copernicus_10m.copy()\n",
    "\n",
    "# --- Elevation difference & valid mask\n",
    "elevation_diff = tinitaly_data - copernicus_data\n",
    "valid_mask     = (tinitaly_data != NODATA) & (copernicus_data != NODATA)\n",
    "\n",
    "valid_pixels    = int(valid_mask.sum())\n",
    "valid_diffs     = elevation_diff[valid_mask]\n",
    "valid_tinitaly  = tinitaly_data[valid_mask]\n",
    "valid_copernicus= copernicus_data[valid_mask]\n",
    "\n",
    "# --- Reference comparison statistics\n",
    "m  = float(np.mean(valid_diffs))\n",
    "md = float(np.median(valid_diffs))\n",
    "sd = float(np.std(valid_diffs))\n",
    "rm = float(np.sqrt(np.mean(valid_diffs**2)))\n",
    "ma = float(np.mean(np.abs(valid_diffs)))\n",
    "nmad = float(1.4826 * np.median(np.abs(valid_diffs - md)))\n",
    "ref_metrics = {\n",
    "    'n_pixels': valid_pixels, 'mean_diff': m, 'median_diff': md, 'std_diff': sd,\n",
    "    'rmse': rm, 'mae': ma, 'nmad': nmad,\n",
    "    'min_diff': float(np.min(valid_diffs)), 'max_diff': float(np.max(valid_diffs)),\n",
    "    'correlation': float(np.corrcoef(valid_tinitaly, valid_copernicus)[0,1])\n",
    "}\n",
    "\n",
    "# --- Equality tolerance using NMAD\n",
    "equal_tolerance = ref_metrics['nmad']\n",
    "\n",
    "# --- Directional comparison grids with equality buffer\n",
    "tinitaly_higher_mask = valid_mask & (elevation_diff >  equal_tolerance)\n",
    "tinitaly_lower_mask  = valid_mask & (elevation_diff < -equal_tolerance)\n",
    "roughly_equal_mask   = valid_mask & (np.abs(elevation_diff) <= equal_tolerance)\n",
    "\n",
    "tinitaly_higher_data = np.where(tinitaly_higher_mask, elevation_diff, np.nan)\n",
    "tinitaly_lower_data  = np.where(tinitaly_lower_mask,  elevation_diff, np.nan)\n",
    "roughly_equal_data   = np.where(roughly_equal_mask,   elevation_diff, np.nan)\n",
    "\n",
    "higher_pixels = int(tinitaly_higher_mask.sum())\n",
    "lower_pixels  = int(tinitaly_lower_mask.sum())\n",
    "equal_pixels  = int(roughly_equal_mask.sum())\n",
    "\n",
    "pct_higher = float(100 * higher_pixels / valid_pixels) if valid_pixels else 0.0\n",
    "pct_lower  = float(100 * lower_pixels  / valid_pixels) if valid_pixels else 0.0\n",
    "pct_equal  = float(100 * equal_pixels  / valid_pixels) if valid_pixels else 0.0\n",
    "\n",
    "# --- Height statistics comparison\n",
    "def calculate_height_stats(data, name):\n",
    "    v = np.asarray(data)\n",
    "    v = v[~np.isnan(v)]\n",
    "    if v.size == 0: return None\n",
    "    q25, q75 = np.percentile(v, [25, 75])\n",
    "    return {\n",
    "        'Dataset': name, 'Count': int(v.size),\n",
    "        'Min': float(v.min()), 'Max': float(v.max()),\n",
    "        'Mean': float(v.mean()), 'Median': float(np.median(v)),\n",
    "        'Std Dev': float(v.std()), 'Range': float(v.max()-v.min()),\n",
    "        'Q25': float(q25), 'Q75': float(q75), 'IQR': float(q75-q25)\n",
    "    }\n",
    "\n",
    "stats_list = [\n",
    "    calculate_height_stats(saocom_gdf['HEIGHT_RELATIVE'].values, 'SAOCOM (Relative)'),\n",
    "    calculate_height_stats(saocom_gdf['tinitaly_height'].values,  'TINITALY (at SAOCOM pts)'),\n",
    "    calculate_height_stats(saocom_gdf['copernicus_height'].values,'Copernicus (at SAOCOM pts)'),\n",
    "    calculate_height_stats(tinitaly_10m[tinitaly_10m!=NODATA],     'TINITALY (Full Grid)'),\n",
    "    calculate_height_stats(copernicus_10m[copernicus_10m!=NODATA], 'Copernicus (Full Grid)')\n",
    "]\n",
    "stats_df = pd.DataFrame([s for s in stats_list if s])\n",
    "\n",
    "# --- Compact displays\n",
    "print(\"\\nHEIGHT STATS SUMMARY (m)\\n\", stats_df.to_string(index=False, float_format=lambda x: f'{x:.2f}'), sep='')\n",
    "\n",
    "# SAOCOM vs references\n",
    "diff_tin_valid = (saocom_gdf['HEIGHT_RELATIVE'] - saocom_gdf['tinitaly_height']).dropna().values\n",
    "diff_cop_valid = (saocom_gdf['HEIGHT_RELATIVE'] - saocom_gdf['copernicus_height']).dropna().values\n",
    "\n",
    "def _summ(v):\n",
    "    return f\"mean={np.mean(v):+.3f}, median={np.median(v):+.3f}, sd={np.std(v):.3f}, rmse={np.sqrt(np.mean(v**2)):.3f} m\"\n",
    "\n",
    "print(\"\\nSAOCOM−TINITALY:\",  _summ(diff_tin_valid))\n",
    "print(\"SAOCOM−Copernicus:\", _summ(diff_cop_valid))\n",
    "\n",
    "# Reference check (TINITALY−Copernicus)\n",
    "ref_diff_valid = (tinitaly_10m[valid_mask] - copernicus_10m[valid_mask])\n",
    "ref_diff_valid = ref_diff_valid[~np.isnan(ref_diff_valid)]\n",
    "print(\"\\nTINITALY−Copernicus:\", _summ(ref_diff_valid))\n"
   ],
   "id": "cb49db135e505282",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DBF LOOKUP TABLE"
   ],
   "id": "1c6a6fa07b94412b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- 3) Load DBF lookup\n",
    "dbf_table  = DBF(corine_dbf_path, load=True)\n",
    "lookup_df  = pd.DataFrame(iter(dbf_table))\n",
    "value_to_code = dict(zip(lookup_df['Value'],   lookup_df['CODE_18']))\n",
    "value_to_label= dict(zip(lookup_df['Value'],   lookup_df['LABEL3']))\n",
    "code_to_label = dict(zip(lookup_df['CODE_18'], lookup_df['LABEL3']))\n",
    "\n",
    "# --- 4) Load, crop by hull, and remap CORINE\n",
    "with rasterio.open(corine_path) as src:\n",
    "    hull_corine_crs = hull_gdf.to_crs(src.crs)\n",
    "    corine_raw, crop_transform = mask(src, hull_corine_crs.geometry, crop=True, filled=False)\n",
    "    corine_raw     = corine_raw[0]\n",
    "    corine_crs     = src.crs\n",
    "    corine_res     = src.res\n",
    "    corine_nodata  = src.nodata if src.nodata is not None else 255\n",
    "    corine_bounds  = src.bounds\n",
    "\n",
    "# Remap: Value → CODE_18 (default 0); keep 0 for nodata\n",
    "corine_remapped = np.vectorize(value_to_code.get, otypes=[np.uint16])(corine_raw)\n",
    "corine_remapped[corine_raw == corine_nodata] = 0\n",
    "\n",
    "# (Optional) Save intermediate remapped crop\n",
    "corine_remapped_path = RESULTS_DIR / \"corine_remapped_cropped.tif\"\n",
    "profile_remapped = {\n",
    "    'driver':'GTiff','dtype':'uint16','width':corine_remapped.shape[1],'height':corine_remapped.shape[0],\n",
    "    'count':1,'crs':corine_crs,'transform':crop_transform,'nodata':0,'compress':'lzw'\n",
    "}\n",
    "with rasterio.open(corine_remapped_path,'w',**profile_remapped) as dst: dst.write(corine_remapped,1)\n",
    "\n",
    "# --- 5) Resample to 10 m grid (nearest for categorical)\n",
    "corine_10m = np.zeros((grid_height, grid_width), dtype=np.uint16)\n",
    "reproject(\n",
    "    source=corine_remapped, destination=corine_10m,\n",
    "    src_transform=crop_transform, src_crs=corine_crs,\n",
    "    dst_transform=target_transform, dst_crs=TARGET_CRS,\n",
    "    resampling=Resampling.nearest, src_nodata=0, dst_nodata=0\n",
    ")\n",
    "\n",
    "corine_10m_path = RESULTS_DIR / \"corine_10m.tif\"\n",
    "profile_10m = {'driver':'GTiff','dtype':'uint16','width':grid_width,'height':grid_height,\n",
    "               'count':1,'crs':TARGET_CRS,'transform':target_transform,'nodata':0,'compress':'lzw'}\n",
    "with rasterio.open(corine_10m_path,'w',**profile_10m) as dst: dst.write(corine_10m,1)\n",
    "\n",
    "# --- 6) Mask to hull\n",
    "corine_10m_masked = corine_10m.copy()\n",
    "corine_10m_masked[~hull_mask] = 0\n",
    "corine_masked_path = RESULTS_DIR / \"corine_10m_masked.tif\"\n",
    "with rasterio.open(corine_masked_path,'w',**profile_10m) as dst: dst.write(corine_10m_masked,1)\n",
    "corine_10m = corine_10m_masked  # update working array\n",
    "\n",
    "# --- Summary (concise)\n",
    "unique_codes = np.unique(corine_10m[corine_10m>0])\n",
    "print(f\"CORINE done | CRS={corine_crs} | classes={len(unique_codes)} | res={GRID_SIZE} m\")\n",
    "print(f\"Classes: {sorted(unique_codes)}\")\n",
    "print(f\"Output: {corine_masked_path}\")\n"
   ],
   "id": "8c5b65856bf784ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMPLE SPATIAL OVERLAP VISUALIZATION"
   ],
   "id": "28251c0a2039784c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Simple spatial overlap visualization\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# 1) TINITALY extent (reprojected for plotting)\n",
    "with rasterio.open(tinitaly_path) as src:\n",
    "    dem_bounds_target = rasterio.warp.transform_bounds(src.crs, TARGET_CRS, *src.bounds)\n",
    "    ax.add_patch(Rectangle(\n",
    "        (dem_bounds_target[0], dem_bounds_target[1]),\n",
    "        dem_bounds_target[2]-dem_bounds_target[0],\n",
    "        dem_bounds_target[3]-dem_bounds_target[1],\n",
    "        linewidth=3, edgecolor='blue', facecolor='none', label='TINITALY Extent'\n",
    "    ))\n",
    "\n",
    "# 2) SAOCOM points + 3) hull\n",
    "saocom_gdf.plot(ax=ax, markersize=1, color='red', alpha=0.5, label='SAOCOM Points')\n",
    "hull_gdf.boundary.plot(ax=ax, color='green', linewidth=2, linestyle='--', label='Study Area Hull')\n",
    "\n",
    "# Labels / legend / grid\n",
    "ax.set(xlabel='UTM Easting (m)', ylabel='UTM Northing (m)', title='Spatial Coverage: SAOCOM vs TINITALY DEM')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, color='gray')\n",
    "\n",
    "# Extent textbox\n",
    "sxmin, sxmax = saocom_gdf.geometry.x.min(), saocom_gdf.geometry.x.max()\n",
    "symin, symax = saocom_gdf.geometry.y.min(), saocom_gdf.geometry.y.max()\n",
    "info_text = (\n",
    "    f\"SAOCOM Extent:\\nX: [{sxmin:.0f}, {sxmax:.0f}]\\nY: [{symin:.0f}, {symax:.0f}]\\n\\n\"\n",
    "    f\"TINITALY Extent (UTM 32N):\\nX: [{dem_bounds_target[0]:.0f}, {dem_bounds_target[2]:.0f}]\\n\"\n",
    "    f\"Y: [{dem_bounds_target[1]:.0f}, {dem_bounds_target[3]:.0f}]\"\n",
    ")\n",
    "ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=9, va='top', family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"spatial_coverage.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- Overlap check\n",
    "print(\"\\n=== OVERLAP CHECK ===\")\n",
    "overlap_x = not (sxmax < dem_bounds_target[0] or sxmin > dem_bounds_target[2])\n",
    "overlap_y = not (symax < dem_bounds_target[1] or symin > dem_bounds_target[3])\n",
    "print(f\"X-axis overlap: {overlap_x}\")\n",
    "print(f\"Y-axis overlap: {overlap_y}\")\n",
    "print(f\"Full overlap: {overlap_x and overlap_y}\")\n",
    "if not (overlap_x and overlap_y):\n",
    "    print(\"\\n⚠️ NO OVERLAP DETECTED - SAOCOM data is outside TINITALY coverage!\\n\"\n",
    "          \"Use a different TINITALY tile that covers this area.\")\n"
   ],
   "id": "e29c1f62561d2a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPREHENSIVE REFERENCE DEM COMPARISON VISUALIZATION"
   ],
   "id": "e745d169ca9be05f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Comprehensive reference DEM comparison visualization (condensed)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(20, 28), facecolor='white')\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "def _imshow(ax, data, cmap, title, cbar_label, vlims=None, stats_arr=None):\n",
    "    ax.set_facecolor('white')\n",
    "    disp = np.ma.masked_equal(data, NODATA) if (data is tinitaly_data or data is copernicus_data) else np.ma.masked_invalid(data)\n",
    "    cm = cmap.copy(); cm.set_bad(color='white', alpha=0)\n",
    "    im = ax.imshow(disp, cmap=cm, origin='upper', extent=extent, **({'vmin':vlims[0],'vmax':vlims[1]} if vlims else {}))\n",
    "    hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "    ax.set(title=title, xlabel='UTM Easting (m)', ylabel='UTM Northing (m)')\n",
    "    ax.grid(True, color='black', alpha=0.3, linewidth=0.5); ax.tick_params(colors='black')\n",
    "    cb = plt.colorbar(im, ax=ax, label=cbar_label, shrink=0.8)\n",
    "    cb.ax.yaxis.label.set_color('black'); cb.ax.tick_params(colors='black')\n",
    "    if stats_arr is not None and stats_arr.size:\n",
    "        txt = f\"Min: {np.nanmin(stats_arr):.1f}m\\nMax: {np.nanmax(stats_arr):.1f}m\\nMean: {np.nanmean(stats_arr):.1f}m\\nStd: {np.nanstd(stats_arr):.1f}m\"\n",
    "        ax.text(0.02, 0.98, txt, transform=ax.transAxes, fontsize=9, va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "    return im\n",
    "\n",
    "# 1) TINITALY elevation\n",
    "_imshow(axes[0,0], tinitaly_data, plt.cm.terrain, 'TINITALY Elevation', 'Elevation (m)', stats_arr=np.where(tinitaly_data!=NODATA, tinitaly_data, np.nan))\n",
    "\n",
    "# 2) Copernicus elevation\n",
    "_imshow(axes[0,1], copernicus_data, plt.cm.terrain, 'Copernicus Elevation', 'Elevation (m)', stats_arr=np.where(copernicus_data!=NODATA, copernicus_data, np.nan))\n",
    "\n",
    "# 3) Difference map (TINITALY − Copernicus) over valid area\n",
    "diff_display = np.where(valid_mask, elevation_diff, np.nan)\n",
    "diff_limit   = np.percentile(np.abs(valid_diffs), 95)\n",
    "stats3 = (\n",
    "    f\"Pixels: {valid_pixels:,}\\n\"\n",
    "    f\"Mean: {ref_metrics['mean_diff']:+.2f}m\\nRMSE: {ref_metrics['rmse']:.2f}m\\n\"\n",
    "    f\"NMAD: {ref_metrics['nmad']:.2f}m\\nMAE: {ref_metrics['mae']:.2f}m\\n\"\n",
    "    f\"Std: {ref_metrics['std_diff']:.2f}m\\nCorr: {ref_metrics['correlation']:.3f}\\n\"\n",
    "    f\"Range: [{ref_metrics['min_diff']:.1f}, {ref_metrics['max_diff']:.1f}]m\"\n",
    ")\n",
    "ax = axes[1,0]\n",
    "_imshow(ax, diff_display, plt.cm.coolwarm, 'Elevation Difference\\n(TINITALY - Copernicus)', 'Difference (m)',\n",
    "        vlims=(-diff_limit, diff_limit))\n",
    "ax.text(0.02, 0.98, stats3, transform=ax.transAxes, fontsize=8, va='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# 4) Statistics summary\n",
    "ax = axes[1,1]; ax.set_facecolor('white'); ax.axis('off'); ax.set_title('Summary Statistics', fontweight='bold', fontsize=12, color='black')\n",
    "le68, le90, le95 = np.percentile(np.abs(valid_diffs), [68.27, 90, 95])\n",
    "stats_text = f\"\"\"REFERENCE DEM COMPARISON\n",
    "\n",
    "Valid Pixels: {valid_pixels:,}\n",
    "\n",
    "CRITICAL METRICS:\n",
    "Mean Error (Bias): {ref_metrics['mean_diff']:+.2f} m\n",
    "RMSE: {ref_metrics['rmse']:.2f} m\n",
    "NMAD (robust): {ref_metrics['nmad']:.2f} m\n",
    "Std Deviation: {ref_metrics['std_diff']:.2f} m\n",
    "\n",
    "SECONDARY METRICS:\n",
    "MAE: {ref_metrics['mae']:.2f} m\n",
    "Correlation: {ref_metrics['correlation']:.4f}\n",
    "LE68: {le68:.2f} m\n",
    "LE90: {le90:.2f} m\n",
    "LE95: {le95:.2f} m\n",
    "Median: {ref_metrics['median_diff']:+.2f} m\n",
    "\n",
    "DIRECTIONAL BREAKDOWN:\n",
    "(Tolerance: ±{equal_tolerance:.2f} m)\n",
    "TINITALY Higher: {higher_pixels:,} ({pct_higher:.1f}%)\n",
    "Copernicus Higher: {lower_pixels:,} ({pct_lower:.1f}%)\n",
    "Roughly Equal: {equal_pixels:,} ({pct_equal:.1f}%)\n",
    "\n",
    "Range: {ref_metrics['min_diff']:+.1f} to {ref_metrics['max_diff']:+.1f} m\n",
    "\"\"\"\n",
    "ax.text(0.05, 0.5, stats_text, transform=ax.transAxes, fontfamily='monospace', fontsize=9, va='center', color='black')\n",
    "\n",
    "# 5) Where TINITALY > Copernicus\n",
    "ax = axes[2,0]\n",
    "_imshow(ax, tinitaly_higher_data, plt.cm.YlOrRd, 'TINITALY > Copernicus', 'Difference (m)', vlims=(0, np.nanmax(tinitaly_higher_data)))\n",
    "hv = tinitaly_higher_data[~np.isnan(tinitaly_higher_data)]\n",
    "ax.text(0.02, 0.98, f\"Pixels: {higher_pixels:,} ({pct_higher:.1f}%)\\nMean: {np.mean(hv):.2f}m\\nStd: {np.std(hv):.2f}m\\nRMSE: {np.sqrt((hv**2).mean()):.2f}m\\nMax: {np.max(hv):.2f}m\",\n",
    "        transform=ax.transAxes, fontsize=8, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# 6) Where TINITALY < Copernicus\n",
    "ax = axes[2,1]\n",
    "_imshow(ax, tinitaly_lower_data, plt.cm.Blues_r, 'Copernicus > TINITALY', 'Difference (m)',\n",
    "        vlims=(np.nanmin(tinitaly_lower_data), 0))\n",
    "lv = tinitaly_lower_data[~np.isnan(tinitaly_lower_data)]\n",
    "ax.text(0.02, 0.98, f\"Pixels: {lower_pixels:,} ({pct_lower:.1f}%)\\nMean: {np.mean(lv):.2f}m\\nStd: {np.std(lv):.2f}m\\nRMSE: {np.sqrt((lv**2).mean()):.2f}m\\nMin: {np.min(lv):.2f}m\",\n",
    "        transform=ax.transAxes, fontsize=8, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# 7) Where roughly equal\n",
    "ax = axes[3,0]\n",
    "_imshow(ax, roughly_equal_data, plt.cm.Greens, f'Roughly Equal (±{equal_tolerance:.2f}m)', 'Difference (m)',\n",
    "        vlims=(-equal_tolerance, equal_tolerance))\n",
    "ev = roughly_equal_data[~np.isnan(roughly_equal_data)]\n",
    "ax.text(0.02, 0.98, f\"Pixels: {equal_pixels:,} ({pct_equal:.1f}%)\\nMean: {np.mean(ev):.2f}m\\nStd: {np.std(ev):.2f}m\\nRMSE: {np.sqrt((ev**2).mean()):.2f}m\\nMAE: {np.mean(np.abs(ev)):.2f}m\",\n",
    "        transform=ax.transAxes, fontsize=8, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# 8) Histogram of differences\n",
    "ax = axes[3,1]; ax.set_facecolor('white')\n",
    "n, bins, patches = ax.hist(valid_diffs, bins=50, alpha=0.75, color='steelblue', edgecolor='black')\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "ax.axvline(ref_metrics['mean_diff'], color='green', linestyle='-', linewidth=2, label=f\"Mean: {ref_metrics['mean_diff']:+.2f}m\")\n",
    "ax.axvline(equal_tolerance, color='orange', linestyle='--', linewidth=1.5, label=f'±NMAD: {equal_tolerance:.2f}m')\n",
    "ax.axvline(-equal_tolerance, color='orange', linestyle='--', linewidth=1.5)\n",
    "ax.text(0.97, 0.97,\n",
    "        f\"Mean = {valid_diffs.mean():+.2f} m\\nStd Dev = {valid_diffs.std():.2f} m\\nMin = {valid_diffs.min():.2f} m\\nMax = {valid_diffs.max():.2f} m\\nRMSE = {ref_metrics['rmse']:.2f} m\\nNMAD = {ref_metrics['nmad']:.2f} m\",\n",
    "        transform=ax.transAxes, fontsize=10, va='top', ha='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='black'))\n",
    "x_min, x_max = float(valid_diffs.min()), float(valid_diffs.max())\n",
    "x_pad = (x_max - x_min) * 0.05\n",
    "ax.set_xlim(x_min - x_pad, x_max + x_pad)\n",
    "ax.set(xlabel='Elevation Difference (m)', ylabel='Frequency', title='Difference Distribution'); ax.tick_params(colors='black')\n",
    "ax.set_yscale('log'); ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "for s in ax.spines.values(): s.set_edgecolor('black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Prepare difference data\n",
    "# =============================================================================\n",
    "saocom_gdf['diff_tinitaly']   = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']\n",
    "saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height']\n",
    "\n",
    "if 'coherence_bin' not in saocom_gdf.columns:\n",
    "    cbins = [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "    clabels = [f\"{cbins[i]:.1f}-{cbins[i+1]:.1f}\" for i in range(len(cbins)-1)]\n",
    "    saocom_gdf['coherence_bin'] = pd.cut(saocom_gdf['COHER'], bins=cbins, labels=clabels, include_lowest=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Basic violin plots (filtered to 1st–99th percentile for display)\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8), facecolor='white')\n",
    "plot_data = pd.DataFrame({'SAOCOM - TINITALY': saocom_gdf['diff_tinitaly'], 'SAOCOM - Copernicus': saocom_gdf['diff_copernicus']})\n",
    "p01, p99 = plot_data.quantile(0.01).min(), plot_data.quantile(0.99).max()\n",
    "filtered = [plot_data[c].dropna().clip(p01, p99) for c in plot_data.columns]\n",
    "\n",
    "parts = ax.violinplot(filtered, positions=[1,2], showmeans=True, showmedians=True, showextrema=True)\n",
    "for pc, col in zip(parts['bodies'], ['#4472C4', '#ED7D31']): pc.set_facecolor(col); pc.set_alpha(0.7); pc.set_edgecolor('black')\n",
    "for k in ('cbars','cmins','cmaxes','cmedians','cmeans'):\n",
    "    if k in parts: parts[k].set_edgecolor('black'); parts[k].set_linewidth(1.5)\n",
    "\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Zero')\n",
    "ax.set_xticks([1,2]); ax.set_xticklabels(['SAOCOM -\\nTINITALY', 'SAOCOM -\\nCopernicus'], fontsize=11)\n",
    "ax.set_ylabel('Elevation Difference (m)', fontsize=12)\n",
    "ax.set_title('Distribution of Elevation Differences (1st–99th Percentile)', fontweight='bold', fontsize=14)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3); ax.legend()\n",
    "\n",
    "for i, col in enumerate(plot_data.columns, 1):\n",
    "    data = plot_data[col].dropna()\n",
    "    ymax = filtered[i-1].max()\n",
    "    ax.text(i, ymax*0.9, f\"n={len(data):,}\\nμ={data.mean():.2f}m\\nσ={data.std():.2f}m\", ha='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 4) Summary statistics table\n",
    "# =============================================================================\n",
    "summary_df = pd.DataFrame([{\n",
    "    'Comparison': 'SAOCOM - TINITALY' if name=='diff_tinitaly' else 'SAOCOM - Copernicus',\n",
    "    'N Points': f\"{len(saocom_gdf[name].dropna()):,}\",\n",
    "    'Mean': f\"{saocom_gdf[name].mean():+.2f} m\",\n",
    "    'Median': f\"{saocom_gdf[name].median():+.2f} m\",\n",
    "    'Std Dev': f\"{saocom_gdf[name].std():.2f} m\",\n",
    "    'RMSE': f\"{np.sqrt((saocom_gdf[name].dropna()**2).mean()):.2f} m\",\n",
    "    'Range': f\"[{saocom_gdf[name].min():.1f}, {saocom_gdf[name].max():.1f}] m\"\n",
    "} for name in ('diff_tinitaly','diff_copernicus')])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\nVIOLIN PLOT SUMMARY STATISTICS\\n\" + \"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n"
   ],
   "id": "343490ec6d14820",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAOCOM HEIGHT RESIDUAL OUTLIER DETECTION AND VISUALIZATION"
   ],
   "id": "3d269213a69d42bd"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np, pandas as pd, geopandas as gpd, matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def score_outliers_isolation_forest(gdf: gpd.GeoDataFrame, residual_col: str, **kwargs) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Add 'outlier_score' via Isolation Forest on (x,y,residual).\"\"\"\n",
    "    if gdf.empty or residual_col not in gdf.columns:\n",
    "        gdf = gdf.copy(); gdf['outlier_score'] = np.nan; return gdf\n",
    "    pts = np.column_stack((gdf.geometry.x.values, gdf.geometry.y.values, gdf[residual_col].fillna(0).values))\n",
    "    X = StandardScaler().fit_transform(pts)\n",
    "    params = {'n_estimators':100, 'contamination':'auto', 'random_state':42, 'n_jobs':-1}\n",
    "    params.update(kwargs)\n",
    "    model = IsolationForest(**params).fit(X)\n",
    "    gdf_scored = gdf.copy()\n",
    "    gdf_scored['outlier_score'] = model.decision_function(X)\n",
    "    return gdf_scored\n",
    "\n",
    "def filter_by_score_iqr(gdf_scored: gpd.GeoDataFrame, iqr_multiplier: float = 1) -> tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    \"\"\"Split into cleaned/outliers using IQR on 'outlier_score'.\"\"\"\n",
    "    if 'outlier_score' not in gdf_scored.columns:\n",
    "        raise ValueError(\"Input GeoDataFrame must have an 'outlier_score' column.\")\n",
    "    s = gdf_scored['outlier_score'].values\n",
    "    q1, q3 = np.percentile(s, [25, 75]); thr = q1 - iqr_multiplier*(q3 - q1)\n",
    "    mask = s < thr\n",
    "    return gdf_scored[~mask].copy(), gdf_scored[mask].copy()\n",
    "\n",
    "def visualize_outlier_results(gdf_original: gpd.GeoDataFrame, gdf_cleaned: gpd.GeoDataFrame, outliers: gpd.GeoDataFrame, residual_col: str):\n",
    "    \"\"\"Two-panel: map (cleaned+outliers) and hist (before/after).\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 9), facecolor='white', gridspec_kw={'width_ratios':[1.2,1]})\n",
    "    vmin, vmax = np.nanpercentile(gdf_cleaned[residual_col].values, [2, 98])\n",
    "    sc = ax1.scatter(gdf_cleaned.geometry.x.values, gdf_cleaned.geometry.y.values,\n",
    "                     c=gdf_cleaned[residual_col].values, cmap='RdBu_r', s=5,\n",
    "                     vmin=vmin, vmax=vmax, alpha=0.8, label='Cleaned Data')\n",
    "    plt.colorbar(sc, ax=ax1, label=f'Residual ({residual_col}) (m)', shrink=0.7)\n",
    "    if not outliers.empty:\n",
    "        outliers.plot(ax=ax1, markersize=25, color='yellow', edgecolors='black', linewidth=0.8,\n",
    "                      label=f'Outliers (n={len(outliers):,})', zorder=5)\n",
    "    ax1.set(title='Spatial Distribution of Cleaned Data and Outliers', xlabel='UTM Easting (m)', ylabel='UTM Northing (m)')\n",
    "    ax1.legend(); ax1.grid(True, linestyle='--', alpha=0.4); ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    orig = gdf_original[residual_col].dropna().values\n",
    "    cln  = gdf_cleaned[residual_col].dropna().values\n",
    "    ax2.hist(orig, bins=100, alpha=0.5, label=f'Before (n={orig.size:,})', color='gray')\n",
    "    ax2.hist(cln,  bins=50,  alpha=1.0, label=f'After (n={cln.size:,})',  color='#2E86AB')\n",
    "    ax2.set(title='Residual Distribution Before and After Cleaning', xlabel=f'Residual ({residual_col}) (m)', ylabel='Frequency (Log Scale)')\n",
    "    ax2.set_yscale('log'); ax2.legend(); ax2.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(RESULTS_DIR / \"difference_by_coherence.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# --- Pipeline (unchanged semantics; less noise)\n",
    "print(len(saocom_gdf))\n",
    "saocom_gdf_scored = score_outliers_isolation_forest(saocom_gdf, 'diff_tinitaly')\n",
    "saocom_gdf_cleaned, saocom_outliers = filter_by_score_iqr(saocom_gdf_scored)\n",
    "visualize_outlier_results(saocom_gdf, saocom_gdf_cleaned, saocom_outliers, 'diff_tinitaly')\n",
    "saocom_gdf = saocom_gdf_cleaned\n",
    "\n",
    "def generate_height_statistics_summary(gdf, gdf_name=\"SAOCOM Data\"):\n",
    "    \"\"\"Print compact height stats for HEIGHT_RELATIVE vs references.\"\"\"\n",
    "    need = ['HEIGHT_RELATIVE','tinitaly_height','copernicus_height']\n",
    "    if not all(c in gdf.columns for c in need):\n",
    "        print(f\"Error: Input GeoDataFrame '{gdf_name}' is missing required height columns: {need}\")\n",
    "        return\n",
    "\n",
    "    def _series_stats(s, name):\n",
    "        v = s.dropna().values\n",
    "        if v.size == 0: return None\n",
    "        q25, q75 = np.percentile(v, [25, 75])\n",
    "        return {'Dataset':name, 'Count':int(v.size), 'Min':float(v.min()), 'Max':float(v.max()),\n",
    "                'Mean':float(v.mean()), 'Median':float(np.median(v)), 'Std Dev':float(v.std()),\n",
    "                'Q25':float(q25), 'Q75':float(q75)}\n",
    "\n",
    "    print(\"\\n\" + \"=\"*95)\n",
    "    print(f\" STATISTICAL SUMMARY FOR: {gdf_name.upper()} ({len(gdf)} points)\")\n",
    "    print(\"=\"*95)\n",
    "\n",
    "    rows = [\n",
    "        _series_stats(gdf['HEIGHT_RELATIVE'], f'{gdf_name} (Relative)'),\n",
    "        _series_stats(gdf['tinitaly_height'], f'TINITALY (at {gdf_name} pts)'),\n",
    "        _series_stats(gdf['copernicus_height'], f'Copernicus (at {gdf_name} pts)')\n",
    "    ]\n",
    "    df = pd.DataFrame([r for r in rows if r is not None])\n",
    "    print(\"\\nHEIGHT STATISTICS SUMMARY (m)\\n\" + \"-\"*95)\n",
    "    print(df.to_string(index=False, float_format=lambda x: f'{x:.2f}')); print(\"-\"*95)\n",
    "\n",
    "    def _diff_stats(a, b, label):\n",
    "        d = (a - b).dropna().values\n",
    "        if d.size == 0:\n",
    "            print(f\"\\n{gdf_name} - {label}: No data.\"); return\n",
    "        print(f\"\\n{gdf_name} - {label}:\")\n",
    "        print(f\"  Mean: {d.mean():+.3f} m | Median: {np.median(d):+.3f} m | Std: {d.std():.3f} m | RMSE: {np.sqrt((d**2).mean()):.3f} m\")\n",
    "\n",
    "    print(\"\\nDIFFERENCE STATISTICS (SAOCOM Relative - Reference DEM):\\n\" + \"-\"*95)\n",
    "    _diff_stats(gdf['HEIGHT_RELATIVE'], gdf['tinitaly_height'], 'TINITALY')\n",
    "    _diff_stats(gdf['HEIGHT_RELATIVE'], gdf['copernicus_height'], 'Copernicus')\n",
    "    print(\"=\"*95)\n",
    "\n",
    "# Summaries\n",
    "generate_height_statistics_summary(saocom_gdf_cleaned, gdf_name=\"SAOCOM Cleaned\")\n",
    "generate_height_statistics_summary(saocom_outliers,   gdf_name=\"SAOCOM Outliers\")\n",
    "# generate_height_statistics_summary(saocom_gdf,        gdf_name=\"SAOCOM Original\")\n"
   ],
   "id": "7769b172accc23af",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SPATIAL SAMPLE CORINE LAND COVER AT SAOCOM POINTS"
   ],
   "id": "9da1751abb2662cc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# --- Pre-req: residuals (SAOCOM calibrated to TINITALY)\n",
    "saocom_gdf['diff_tinitaly'] = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']\n",
    "# saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height']  # not needed here\n",
    "\n",
    "# --- 1) Sample CORINE code at SAOCOM points (vectorized & bounds-safe)\n",
    "xs, ys = saocom_gdf.geometry.x.values, saocom_gdf.geometry.y.values\n",
    "r, c = rowcol(target_transform, xs, ys)\n",
    "inb = (r>=0)&(r<grid_height)&(c>=0)&(c<grid_width)\n",
    "codes = np.zeros(len(saocom_gdf), dtype=np.uint16)\n",
    "codes[inb] = corine_10m[r[inb], c[inb]]\n",
    "codes[codes == 255] = 0  # map nodata→0\n",
    "saocom_gdf['corine_code'] = codes\n",
    "\n",
    "# restrict to valid CORINE pixels\n",
    "saocom_lc_analysis = saocom_gdf[saocom_gdf['corine_code'] != 0].copy()\n",
    "\n",
    "# --- 2) Robust stats by land cover (NMAD etc.)\n",
    "def nmad(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x)\n",
    "    med = np.median(x)\n",
    "    return 1.4826 * np.median(np.abs(x - med))\n",
    "\n",
    "lc_height_stats = (\n",
    "    saocom_lc_analysis\n",
    "    .groupby('corine_code', as_index=False)['diff_tinitaly']\n",
    "    .agg(\n",
    "        N_Points='count',\n",
    "        Median_Diff_m='median',\n",
    "        Mean_Diff_m='mean',\n",
    "        Std_Dev_m='std',\n",
    "        NMAD_m=lambda s: nmad(s.dropna().values)\n",
    "    )\n",
    ")\n",
    "lc_height_stats['LC_Label'] = lc_height_stats['corine_code'].map(CORINE_CLASSES)\n",
    "\n",
    "MIN_SAMPLES = 50\n",
    "lc_height_stats_filtered = (\n",
    "    lc_height_stats[lc_height_stats['N_Points'] >= MIN_SAMPLES]\n",
    "    .sort_values('LC_Label', ascending=True)\n",
    ")\n",
    "\n",
    "# --- 3) Display results (compact formatting)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"HEIGHT RESIDUAL STATISTICS by CORINE Land Cover (N > {MIN_SAMPLES})\")\n",
    "print(\"(Residual = Calibrated SAOCOM Height - TINITALY Reference DEM)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "disp_cols = ['corine_code','LC_Label','N_Points','Median_Diff_m','NMAD_m','Mean_Diff_m','Std_Dev_m']\n",
    "fmt = {\n",
    "    'N_Points': '{:,}'.format,\n",
    "    'Median_Diff_m': '{:+.2f} m'.format,\n",
    "    'NMAD_m': '{:.2f} m'.format,\n",
    "    'Mean_Diff_m': '{:+.2f} m'.format,\n",
    "    'Std_Dev_m': '{:.2f} m'.format\n",
    "}\n",
    "print(lc_height_stats_filtered[disp_cols].to_string(index=False, formatters=fmt))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# keep for later use\n",
    "lc_height_stats_final = lc_height_stats_filtered.copy()\n",
    "\n",
    "# ====================== VOID ANALYSIS BY LAND COVER ======================\n",
    "\n",
    "# globals assumed: corine_10m, study_area_mask, saocom_coverage, void_mask, GRID_SIZE, CORINE_CLASSES\n",
    "n_total_cells = int(study_area_mask.sum())\n",
    "n_void_cells  = int(void_mask.sum())\n",
    "void_percentage_global = 100 * n_void_cells / n_total_cells if n_total_cells else 0.0\n",
    "\n",
    "# Vectorized per-class counts inside study area\n",
    "codes_sa = corine_10m[study_area_mask]                      # uint16 codes within hull\n",
    "valid_mask_codes = codes_sa != 0\n",
    "codes_valid = codes_sa[valid_mask_codes]\n",
    "\n",
    "# total cells per LC code\n",
    "max_code = int(codes_valid.max()) if codes_valid.size else 0\n",
    "tot_counts = np.bincount(codes_valid, minlength=max_code+1)\n",
    "\n",
    "# void cells per LC code (only where code!=0 inside hull)\n",
    "void_codes = codes_sa[void_mask[study_area_mask]]\n",
    "void_codes = void_codes[void_codes != 0]\n",
    "void_counts = np.bincount(void_codes, minlength=max_code+1)\n",
    "\n",
    "# Build DataFrame (exclude code 0)\n",
    "idx = np.arange(max_code+1)\n",
    "mask_has = tot_counts > 0\n",
    "df = pd.DataFrame({\n",
    "    'corine_code': idx[mask_has],\n",
    "    'total_cells': tot_counts[mask_has].astype(np.int64),\n",
    "    'void_cells':  void_counts[mask_has].astype(np.int64)\n",
    "})\n",
    "cell_area_km2 = (GRID_SIZE/1000.0)**2\n",
    "df['Area_km2'] = df['total_cells'] * cell_area_km2\n",
    "df['Pct_LC_is_Void']   = 100.0 * df['void_cells'] / df['total_cells']\n",
    "df['Pct_of_Total_Voids'] = (100.0 * df['void_cells'] / n_void_cells) if n_void_cells else 0.0\n",
    "df['label'] = df['corine_code'].map(CORINE_CLASSES).fillna(df['corine_code'].map(lambda x: f'Unknown_{x}'))\n",
    "\n",
    "void_stats_df = df[['corine_code','label','total_cells','void_cells','Area_km2','Pct_LC_is_Void','Pct_of_Total_Voids']].copy()\n",
    "\n",
    "# --- Display filtered summary\n",
    "MIN_AREA_KM2 = 1.0\n",
    "void_stats_filtered = (\n",
    "    void_stats_df[void_stats_df['Area_km2'] >= MIN_AREA_KM2]\n",
    "    .sort_values('Pct_LC_is_Void', ascending=False)\n",
    "    .rename(columns={'total_cells':'total_cells'})  # preserve original naming\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(f\"VOID ANALYSIS by CORINE Land Cover (Area > {MIN_AREA_KM2:.1f} km²)\")\n",
    "print(f\"Overall Void Percentage (Study Area): {void_percentage_global:.2f}%\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "disp_cols_void = ['corine_code','label','Area_km2','void_cells','Pct_LC_is_Void','Pct_of_Total_Voids']\n",
    "fmt_void = {\n",
    "    'Area_km2': '{:.1f} km²'.format,\n",
    "    'void_cells': '{:,}'.format,\n",
    "    'Pct_LC_is_Void': '{:.2f} %'.format,\n",
    "    'Pct_of_Total_Voids': '{:.2f} %'.format\n",
    "}\n",
    "print(void_stats_filtered[disp_cols_void].to_string(index=False, formatters=fmt_void))\n",
    "print(\"=\"*120)\n",
    "\n",
    "# keep for later use\n",
    "lc_void_stats_final = void_stats_filtered.copy()\n",
    "\n"
   ],
   "id": "9d454d3c05f97df5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. PREPARE DATA FOR PLOTTING"
   ],
   "id": "a61ab1c0937ae7d7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARE DATA FOR PLOTTING\n",
    "# =============================================================================\n",
    "# Use the full saocom_lc_analysis DataFrame which contains both the residuals\n",
    "# ('diff_tinitaly') and the sampled land cover codes ('corine_code').\n",
    "\n",
    "# Define major land cover groups for better visualization (CLC Level 1)\n",
    "def get_clc_level1(code):\n",
    "    \"\"\"Maps CLC Level 3 code to Level 1 category\"\"\"\n",
    "    if 100 <= code < 200: return '1. Artificial Surfaces'\n",
    "    if 200 <= code < 300: return '2. Agricultural Areas'\n",
    "    if 300 <= code < 400: return '3. Forest & Semi-Natural Areas'\n",
    "    if 400 <= code < 500: return '4. Wetlands'\n",
    "    if 500 <= code < 600: return '5. Water Bodies'\n",
    "    return 'Other'\n",
    "\n",
    "# Add Level 1 categories to the analysis DataFrame\n",
    "saocom_lc_analysis['LC_Level_1'] = saocom_lc_analysis['corine_code'].apply(get_clc_level1)\n",
    "saocom_lc_analysis['LC_Label'] = saocom_lc_analysis['corine_code'].map(CORINE_CLASSES)\n",
    "\n",
    "# Filter for the most common Level 3 classes (using the N_Points filter from Step 1)\n",
    "common_codes = lc_height_stats_final['corine_code'].unique()\n",
    "plot_df_L3 = saocom_lc_analysis[saocom_lc_analysis['corine_code'].isin(common_codes)].copy()\n",
    "\n",
    "# Filter extreme outliers for better plot scaling (e.g., 99th percentile)\n",
    "q_low = plot_df_L3['diff_tinitaly'].quantile(0.005)\n",
    "q_high = plot_df_L3['diff_tinitaly'].quantile(0.995)\n",
    "plot_df_L3_filtered = plot_df_L3[(plot_df_L3['diff_tinitaly'] >= q_low) &\n",
    "                                (plot_df_L3['diff_tinitaly'] <= q_high)]\n",
    "\n",
    "# Sort the categories by the NMAD metric (best to worst performance)\n",
    "nmad_order = lc_height_stats_final.sort_values('LC_Label', ascending=False)['LC_Label'].tolist()\n",
    "plot_df_L3_filtered['LC_Label'] = pd.Categorical(\n",
    "    plot_df_L3_filtered['LC_Label'],\n",
    "    categories=nmad_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "q_low = plot_df_L3['diff_copernicus'].quantile(0.005)\n",
    "q_high = plot_df_L3['diff_copernicus'].quantile(0.995)\n",
    "plot_df_cop_filtered = plot_df_L3[(plot_df_L3['diff_copernicus'] >= q_low) &\n",
    "                                (plot_df_L3['diff_copernicus'] <= q_high)]\n",
    "\n",
    "# Sort the categories by the NMAD metric (best to worst performance)\n",
    "nmad_order = lc_height_stats_final.sort_values('LC_Label', ascending=False)['LC_Label'].tolist()\n",
    "plot_df_cop_filtered['LC_Label'] = pd.Categorical(\n",
    "    plot_df_cop_filtered['LC_Label'],\n",
    "    categories=nmad_order,\n",
    "    ordered=True\n",
    ")\n"
   ],
   "id": "64aa6aba8124853f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTINEL-2 RGB PREPARATION"
   ],
   "id": "9c5359c1441eb211"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# SENTINEL-2 RGB PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "# File discovery\n",
    "sentinel_files = list((DATA_DIR / \"sentinel_data\").glob(\"*.tif\"))\n",
    "if not sentinel_files:\n",
    "    raise FileNotFoundError(\"No Sentinel files found in sentinel_data directory\")\n",
    "\n",
    "# Load Sentinel bands (assuming separate R, G, B files or multi-band)\n",
    "with rasterio.open(sentinel_files[0]) as src:\n",
    "    sentinel_count = src.count\n",
    "\n",
    "    if sentinel_count >= 3:\n",
    "        # Multi-band file - read RGB bands\n",
    "        sentinel_r = src.read(1)  # Band 1 (Red)\n",
    "        sentinel_g = src.read(2)  # Band 2 (Green)\n",
    "        sentinel_b = src.read(3)  # Band 3 (Blue)\n",
    "        sentinel_transform_orig = src.transform\n",
    "        sentinel_crs = src.crs\n",
    "    else:\n",
    "        # Single band files - need to find R, G, B separately\n",
    "        r_file = next((f for f in sentinel_files if 'B04' in f.name or 'red' in f.name.lower()), None)\n",
    "        g_file = next((f for f in sentinel_files if 'B03' in f.name or 'green' in f.name.lower()), None)\n",
    "        b_file = next((f for f in sentinel_files if 'B02' in f.name or 'blue' in f.name.lower()), None)\n",
    "\n",
    "        if not all([r_file, g_file, b_file]):\n",
    "            raise FileNotFoundError(\"Could not find RGB bands in Sentinel files\")\n",
    "\n",
    "        with rasterio.open(r_file) as r_src:\n",
    "            sentinel_r = r_src.read(1)\n",
    "            sentinel_transform_orig = r_src.transform\n",
    "            sentinel_crs = r_src.crs\n",
    "        with rasterio.open(g_file) as g_src:\n",
    "            sentinel_g = g_src.read(1)\n",
    "        with rasterio.open(b_file) as b_src:\n",
    "            sentinel_b = b_src.read(1)\n",
    "\n",
    "# Resample each band to 10m grid\n",
    "sentinel_r_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "sentinel_g_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "sentinel_b_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "\n",
    "for band_src, band_dst in [(sentinel_r, sentinel_r_10m),\n",
    "                            (sentinel_g, sentinel_g_10m),\n",
    "                            (sentinel_b, sentinel_b_10m)]:\n",
    "    reproject(\n",
    "        source=band_src,\n",
    "        destination=band_dst,\n",
    "        src_transform=sentinel_transform_orig,\n",
    "        src_crs=sentinel_crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=TARGET_CRS,\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "# Stack into RGB array\n",
    "sentinel_rgb = np.stack([sentinel_r_10m, sentinel_g_10m, sentinel_b_10m], axis=2)\n",
    "\n",
    "# Mask to study area\n",
    "sentinel_rgb[~hull_mask] = 0\n",
    "\n",
    "# Normalize to 0-1 for display (using 2-98 percentile stretch for contrast)\n",
    "sentinel_rgb_norm = np.zeros_like(sentinel_rgb, dtype=np.float32)\n",
    "for i in range(3):\n",
    "    band = sentinel_rgb[:, :, i]\n",
    "    valid_pixels = band[hull_mask]\n",
    "\n",
    "    if len(valid_pixels) > 0:\n",
    "        p2, p98 = np.percentile(valid_pixels[valid_pixels > 0], [2, 98])\n",
    "        band_norm = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "        sentinel_rgb_norm[:, :, i] = band_norm\n",
    "\n",
    "print(f\"\\nSentinel-2 RGB Prepared:\")\n",
    "print(f\"  Shape: {sentinel_rgb_norm.shape}\")\n",
    "print(f\"  Resolution: {GRID_SIZE}m\")\n",
    "print(f\"  Value range: [{sentinel_rgb_norm.min():.3f}, {sentinel_rgb_norm.max():.3f}]\")"
   ],
   "id": "28e32d0a008b6325",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GENERATE VIOLIN PLOT (Level 3 - Detailed Performance)"
   ],
   "id": "cf1514ee7f1fc149"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 1. GENERATE STATS WITHIN THE PLOT SCRIPT\n",
    "# =============================================================================\n",
    "print(\"Generating statistics just-in-time for the plot...\")\n",
    "\n",
    "def calculate_nmad(series):\n",
    "    \"\"\"Calculates the Normalized Median Absolute Deviation (NMAD).\"\"\"\n",
    "    return (series - series.median()).abs().median() * 1.4826\n",
    "\n",
    "# Create a new, temporary stats DataFrame by grouping the plotting data\n",
    "stats_for_plot = plot_df_L3_filtered.groupby('LC_Label')['diff_tinitaly'].agg(\n",
    "    Median_Diff_m='median',\n",
    "    NMAD_m=calculate_nmad,\n",
    "    Std_Dev_m='std',\n",
    "    Min_Diff_m='min',\n",
    "    Max_Diff_m='max'\n",
    ").reset_index()\n",
    "\n",
    "# Determine the plotting order based on the NMAD we just calculated\n",
    "nmad_order = stats_for_plot.sort_values('NMAD_m')['LC_Label'].tolist()\n",
    "\n",
    "# Define an anchor point for the text annotations\n",
    "q_high = plot_df_L3_filtered['diff_tinitaly'].quantile(0.99) + 5\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. GENERATE VIOLIN PLOT (Level 3 - Detailed Performance)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(16, 9), facecolor='white')\n",
    "\n",
    "# Use violin plot, ordering it with the 'nmad_order' list we just created\n",
    "sns.violinplot(\n",
    "    x='diff_tinitaly',\n",
    "    y='LC_Label',\n",
    "    data=plot_df_L3_filtered,\n",
    "    order=nmad_order,  # Use the calculated order here\n",
    "    inner='quartile',\n",
    "    palette='Spectral_r',\n",
    "    orient='h',\n",
    "    linewidth=1.0,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Add a vertical line at zero error\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Distribution of SAOCOM Height Residuals by Land Cover (CLC Level 3)', fontweight='bold', fontsize=18)\n",
    "plt.xlabel('Height Residual (Calibrated SAOCOM - TINITALY DEM) [m]', fontsize=14)\n",
    "plt.ylabel('CORINE Land Cover Class (Ordered by NMAD)', fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# --- Add Annotations using the stats we just generated ---\n",
    "for i, label in enumerate(nmad_order):\n",
    "    # Query the 'stats_for_plot' DataFrame we created above\n",
    "    stats = stats_for_plot.query(\"LC_Label == @label\").iloc[0]\n",
    "\n",
    "    stats_text = (\n",
    "        f\"Median: {stats['Median_Diff_m']:+.2f} m\\n\"\n",
    "        f\"NMAD: {stats['NMAD_m']:.2f} m\\n\"\n",
    "        f\"Std Dev: {stats['Std_Dev_m']:.2f} m\\n\"\n",
    "        f\"Min/Max: [{stats['Min_Diff_m']:.1f}, {stats['Max_Diff_m']:.1f}] m\"\n",
    "    )\n",
    "\n",
    "    plt.text(q_high, i, stats_text,\n",
    "             verticalalignment='center',\n",
    "             horizontalalignment='left',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8)\n",
    "            )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.8, 1])\n",
    "plt.show()\n",
    "print(\"Violin Plot for Level 3 Land Cover classes generated successfully.\")\n",
    "# Add this line to save the figure\n",
    "plt.savefig(RESULTS_DIR / 'saocom_tinitaly_residuals_by_landcover.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# COPERNICUS STATISTICS AND VIOLIN PLOT (Level 3)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Generating statistics for Copernicus plot...\")\n",
    "\n",
    "def calculate_nmad(series):\n",
    "    \"\"\"Calculates the Normalized Median Absolute Deviation (NMAD).\"\"\"\n",
    "    return (series - series.median()).abs().median() * 1.4826\n",
    "\n",
    "# Create a new stats DataFrame by grouping the filtered Copernicus plotting data\n",
    "stats_for_cop_plot = plot_df_cop_filtered.groupby('LC_Label')['diff_copernicus'].agg(\n",
    "    Median_Diff_m='median',\n",
    "    NMAD_m=calculate_nmad,\n",
    "    Std_Dev_m='std',\n",
    "    Min_Diff_m='min',\n",
    "    Max_Diff_m='max'\n",
    ").reset_index()\n",
    "\n",
    "# Determine the plotting order based on the NMAD we just calculated\n",
    "nmad_order_cop = stats_for_cop_plot.sort_values('NMAD_m')['LC_Label'].tolist()\n",
    "\n",
    "# Define an anchor point for the text annotations\n",
    "q_high_cop = plot_df_cop_filtered['diff_copernicus'].quantile(0.995) + 5\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. GENERATE COPERNICUS VIOLIN PLOT (Level 3)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(16, 9), facecolor='white')\n",
    "\n",
    "# Generate the violin plot, ordering it with the 'nmad_order_cop' list\n",
    "sns.violinplot(\n",
    "    x='diff_copernicus',\n",
    "    y='LC_Label',\n",
    "    data=plot_df_cop_filtered,\n",
    "    order=nmad_order_cop,  # Use the calculated order here\n",
    "    inner='quartile',\n",
    "    palette='Spectral_r',\n",
    "    orient='h',\n",
    "    linewidth=1.0,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Add a vertical line at zero error\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Distribution of SAOCOM Height Residuals by Land Cover (vs. Copernicus)', fontweight='bold', fontsize=18)\n",
    "plt.xlabel('Height Residual (Calibrated SAOCOM - Copernicus DEM) [m]', fontsize=14)\n",
    "plt.ylabel('CORINE Land Cover Class (Ordered by NMAD)', fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# --- Add Annotations using the stats we just generated ---\n",
    "for i, label in enumerate(nmad_order_cop):\n",
    "    # Query the 'stats_for_cop_plot' DataFrame\n",
    "    stats = stats_for_cop_plot.query(\"LC_Label == @label\").iloc[0]\n",
    "\n",
    "    stats_text = (\n",
    "        f\"Median: {stats['Median_Diff_m']:+.2f} m\\n\"\n",
    "        f\"NMAD: {stats['NMAD_m']:.2f} m\\n\"\n",
    "        f\"Std Dev: {stats['Std_Dev_m']:.2f} m\\n\"\n",
    "        f\"Min/Max: [{stats['Min_Diff_m']:.1f}, {stats['Max_Diff_m']:.1f}] m\"\n",
    "    )\n",
    "\n",
    "    plt.text(q_high_cop, i, stats_text,\n",
    "             verticalalignment='center',\n",
    "             horizontalalignment='left',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8)\n",
    "            )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.8, 1])\n",
    "plt.show()\n",
    "print(\"Violin Plot for Copernicus comparison generated successfully.\")\n",
    "# Add this line to save the figure\n",
    "plt.savefig(RESULTS_DIR / 'saocom_copernicus_residuals_by_landcover.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "# =============================================================================\n",
    "# 3. GENERATE BOX PLOT (Level 1 - Broad Comparison)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(10, 6), facecolor='white')\n",
    "\n",
    "# Use box plot for a cleaner Level 1 aggregation\n",
    "sns.boxplot(\n",
    "    x='LC_Level_1',\n",
    "    y='diff_tinitaly',\n",
    "    data=plot_df_L3_filtered,\n",
    "    palette='Set2',\n",
    "    linewidth=1.0,\n",
    "    showfliers=False # Do not show outliers already filtered\n",
    ")\n",
    "\n",
    "# Add a horizontal line at zero error\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\n",
    "    'SAOCOM Height Residuals by Land Cover (CLC Level 1)',\n",
    "    fontweight='bold',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.xlabel('CORINE Land Cover Category (Level 1)', fontsize=11)\n",
    "plt.ylabel('Height Residual (m)', fontsize=11)\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Box Plot for Level 1 Land Cover categories generated successfully.\")\n",
    "\n",
    "# =============================================================================\n",
    "# CORINE LAND COVER VISUALIZATION\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(figsize=(14, 10), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Get extent\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Mask NoData/zero values for transparency\n",
    "corine_display = np.ma.masked_where((corine_10m == 0) | (corine_10m == 255), corine_10m)\n",
    "\n",
    "# Get unique classes in study area\n",
    "unique_codes = np.unique(corine_display.compressed())\n",
    "\n",
    "# Create colormap for present classes only\n",
    "colors_list = [CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5)) for code in unique_codes]\n",
    "cmap = ListedColormap(colors_list)\n",
    "norm = BoundaryNorm(boundaries=np.append(unique_codes, unique_codes[-1]+1) - 0.5,\n",
    "                    ncolors=len(unique_codes))\n",
    "\n",
    "# Plot CORINE\n",
    "im = ax.imshow(corine_display, cmap=cmap, norm=norm, origin='upper', extent=extent)\n",
    "\n",
    "# Add study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2, label='Study Area')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=14, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=14, color='black')\n",
    "ax.set_title('CORINE Land Cover 2018', fontweight='bold', fontsize=18, color='black')\n",
    "ax.tick_params(colors='black', labelsize=12)\n",
    "ax.grid(True, alpha=0.3, linewidth=0.5, color='black')\n",
    "\n",
    "# Create legend with only present classes\n",
    "legend_elements = [plt.Rectangle((0,0),1,1, facecolor=CORINE_COLORS_MPL[code],\n",
    "                                 edgecolor='black', linewidth=0.5,\n",
    "                                 label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\")\n",
    "                   for code in sorted(unique_codes)]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          fontsize=13, frameon=True, fancybox=False, edgecolor='black')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', box_alpha=0.8, color='black')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Add statistics box\n",
    "total_area_km2 = np.sum(study_area_mask) * 0.0001\n",
    "stats_text = f\"Study Area: {total_area_km2:.2f} km²\\nClasses: {len(unique_codes)}\"\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=12,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "        alpha=0.9, edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCORINE Land Cover Map:\")\n",
    "print(f\"  Total classes present: {len(unique_codes)}\")\n",
    "print(f\"  Study area: {total_area_km2:.2f} km²\")\n",
    "## =============================================================================\n",
    "# SAOCOM HEIGHT RESIDUALS - INTERPOLATED HEAT MAPS\n",
    "# =============================================================================\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 10), facecolor='white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Filter valid points\n",
    "valid_tin = saocom_gdf[saocom_gdf['diff_tinitaly'].notna()].copy()\n",
    "valid_cop = saocom_gdf[saocom_gdf['diff_copernicus'].notna()].copy()\n",
    "\n",
    "# Calculate symmetric color limits (95th percentile)\n",
    "tin_limit = np.percentile(np.abs(valid_tin['diff_tinitaly']), 95)\n",
    "cop_limit = np.percentile(np.abs(valid_cop['diff_copernicus']), 95)\n",
    "common_limit = max(tin_limit, cop_limit)\n",
    "\n",
    "# Create interpolation grid (matching the 10m grid)\n",
    "xi = np.linspace(xmin_grid, xmax_grid, grid_width)\n",
    "yi = np.linspace(ymax_grid, ymin_grid, grid_height)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "# =============================================================================\n",
    "# Plot 1: SAOCOM - TINITALY Heat Map\n",
    "# =============================================================================\n",
    "ax = axes[0]\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Background: Sentinel RGB (very faint)\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.2)\n",
    "\n",
    "# Extract coordinates and values\n",
    "x_tin = valid_tin.geometry.x.values\n",
    "y_tin = valid_tin.geometry.y.values\n",
    "z_tin = valid_tin['diff_tinitaly'].values\n",
    "\n",
    "# Interpolate to grid using cubic method\n",
    "print(\"Interpolating TINITALY differences...\")\n",
    "zi_tin = griddata((x_tin, y_tin), z_tin, (xi_grid, yi_grid),\n",
    "                  method='cubic', fill_value=np.nan)\n",
    "\n",
    "# Apply Gaussian smoothing for smoother heat map\n",
    "zi_tin_smooth = gaussian_filter(np.nan_to_num(zi_tin, nan=0), sigma=2)\n",
    "zi_tin_smooth[~hull_mask] = np.nan  # Mask to study area\n",
    "\n",
    "# Plot heat map\n",
    "im1 = ax.imshow(zi_tin_smooth, extent=extent, origin='upper',\n",
    "                cmap='RdBu_r', alpha=0.8,\n",
    "                vmin=-common_limit, vmax=common_limit,\n",
    "                interpolation='bilinear')\n",
    "\n",
    "# Overlay original points (small, for reference)\n",
    "ax.scatter(x_tin, y_tin, c=z_tin, cmap='RdBu_r',\n",
    "           s=0.5, alpha=0.3, edgecolors='none',\n",
    "           vmin=-common_limit, vmax=common_limit)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Colorbar\n",
    "cbar1 = plt.colorbar(im1, ax=ax, label='Height Difference (m)',\n",
    "                     shrink=0.8, pad=0.02)\n",
    "cbar1.ax.tick_params(labelsize=10, colors='black')\n",
    "cbar1.ax.yaxis.label.set_color('black')\n",
    "\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "ax.set_title('SAOCOM - TINITALY\\nInterpolated Height Residual Heat Map',\n",
    "             fontweight='bold', fontsize=14, color='black')\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "\n",
    "# Statistics box\n",
    "stats_text = f\"\"\"Points: {len(valid_tin):,}\n",
    "Mean: {valid_tin['diff_tinitaly'].mean():+.2f} m\n",
    "Median: {valid_tin['diff_tinitaly'].median():+.2f} m\n",
    "RMSE: {np.sqrt((valid_tin['diff_tinitaly']**2).mean()):.2f} m\n",
    "NMAD: {1.4826 * np.median(np.abs(valid_tin['diff_tinitaly'] - valid_tin['diff_tinitaly'].median())):.2f} m\n",
    "Std: {valid_tin['diff_tinitaly'].std():.2f} m\n",
    "\n",
    "Interpolation: Cubic + Gaussian\n",
    "Color Scale: ±{common_limit:.1f} m\n",
    "Red = SAOCOM Higher\n",
    "Blue = TINITALY Higher\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9,\n",
    "                 edgecolor='black'))\n",
    "\n",
    "# =============================================================================\n",
    "# Plot 2: SAOCOM - Copernicus Heat Map\n",
    "# =============================================================================\n",
    "ax = axes[1]\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Background: Sentinel RGB (very faint)\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.2)\n",
    "\n",
    "# Extract coordinates and values\n",
    "x_cop = valid_cop.geometry.x.values\n",
    "y_cop = valid_cop.geometry.y.values\n",
    "z_cop = valid_cop['diff_copernicus'].values\n",
    "\n",
    "# Interpolate to grid using cubic method\n",
    "print(\"Interpolating Copernicus differences...\")\n",
    "zi_cop = griddata((x_cop, y_cop), z_cop, (xi_grid, yi_grid),\n",
    "                  method='cubic', fill_value=np.nan)\n",
    "\n",
    "# Apply Gaussian smoothing\n",
    "zi_cop_smooth = gaussian_filter(np.nan_to_num(zi_cop, nan=0), sigma=2)\n",
    "zi_cop_smooth[~hull_mask] = np.nan  # Mask to study area\n",
    "\n",
    "# Plot heat map\n",
    "im2 = ax.imshow(zi_cop_smooth, extent=extent, origin='upper',\n",
    "                cmap='RdBu_r', alpha=0.8,\n",
    "                vmin=-common_limit, vmax=common_limit,\n",
    "                interpolation='bilinear')\n",
    "\n",
    "# Overlay original points (small, for reference)\n",
    "ax.scatter(x_cop, y_cop, c=z_cop, cmap='RdBu_r',\n",
    "           s=0.5, alpha=0.3, edgecolors='none',\n",
    "           vmin=-common_limit, vmax=common_limit)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Colorbar\n",
    "cbar2 = plt.colorbar(im2, ax=ax, label='Height Difference (m)',\n",
    "                     shrink=0.8, pad=0.02)\n",
    "cbar2.ax.tick_params(labelsize=10, colors='black')\n",
    "cbar2.ax.yaxis.label.set_color('black')\n",
    "\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "ax.set_title('SAOCOM - Copernicus\\nInterpolated Height Residual Heat Map',\n",
    "             fontweight='bold', fontsize=14, color='black')\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "\n",
    "# Statistics box\n",
    "stats_text = f\"\"\"Points: {len(valid_cop):,}\n",
    "Mean: {valid_cop['diff_copernicus'].mean():+.2f} m\n",
    "Median: {valid_cop['diff_copernicus'].median():+.2f} m\n",
    "RMSE: {np.sqrt((valid_cop['diff_copernicus']**2).mean()):.2f} m\n",
    "NMAD: {1.4826 * np.median(np.abs(valid_cop['diff_copernicus'] - valid_cop['diff_copernicus'].median())):.2f} m\n",
    "Std: {valid_cop['diff_copernicus'].std():.2f} m\n",
    "\n",
    "Interpolation: Cubic + Gaussian\n",
    "Color Scale: ±{common_limit:.1f} m\n",
    "Red = SAOCOM Higher\n",
    "Blue = Copernicus Higher\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9,\n",
    "                 edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'saocom_residual_heatmaps_interpolated.png',\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: saocom_residual_heatmaps_interpolated.png\")\n",
    "print(f\"Interpolation method: Cubic spline + Gaussian smoothing (sigma=2)\")\n",
    "print(f\"Color scale range: ±{common_limit:.2f} m\")\n",
    "\n"
   ],
   "id": "3c7b7d7fc5f1da51",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Overlays Basic\n"
   ],
   "id": "aa52b0d78928a891"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDIVIDUAL CLASS OVERLAY MAPS (COLORBLIND-FRIENDLY)"
   ],
   "id": "d62153f96dd18de3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# INDIVIDUAL CLASS OVERLAY MAPS (COLORBLIND-FRIENDLY)\n",
    "# =============================================================================\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Get unique classes present in data\n",
    "unique_classes = np.unique(corine_10m[corine_10m > 0])\n",
    "\n",
    "# Create one map per class\n",
    "for lc_code in sorted(unique_classes):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Display Sentinel RGB as background\n",
    "    ax.imshow(sentinel_rgb_norm, extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid],\n",
    "              origin='upper', alpha=0.7)  # Slight transparency to help overlay show\n",
    "\n",
    "    # Get color for this land cover class\n",
    "    fill_color = tuple(c/255 for c in CORINE_COLORS.get(lc_code, (128, 128, 128)))\n",
    "\n",
    "    # Create mask for this land cover class\n",
    "    lc_mask = (corine_10m == lc_code)\n",
    "\n",
    "    # Vectorize to get boundaries\n",
    "    mask_shapes = shapes(lc_mask.astype(np.uint8), mask=lc_mask, transform=target_transform)\n",
    "\n",
    "    # Convert to polygons and plot\n",
    "    polys = [shape(geom) for geom, val in mask_shapes if val == 1]\n",
    "\n",
    "    if polys:\n",
    "        for poly in polys:\n",
    "            if poly.is_valid:\n",
    "                x, y = poly.exterior.xy\n",
    "\n",
    "                # Fill with class-specific color + hatching for visibility\n",
    "                ax.fill(x, y, color=fill_color, alpha=0.4,\n",
    "                       edgecolor='none', hatch='///', linewidth=0)\n",
    "\n",
    "                # Bold black outline for definition\n",
    "                ax.plot(x, y, color='black', linewidth=2.5, alpha=0.9)\n",
    "\n",
    "                # Colored inner outline\n",
    "                ax.plot(x, y, color=fill_color, linewidth=1.5, alpha=1.0)\n",
    "\n",
    "    # Add study area boundary\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=3, linestyle='--', alpha=0.8)\n",
    "    hull_gdf.boundary.plot(ax=ax, color='red', linewidth=1.5, linestyle='--', alpha=1.0)\n",
    "\n",
    "    # Calculate statistics\n",
    "    lc_count = np.sum(lc_mask)\n",
    "    area_km2 = lc_count * (GRID_SIZE**2) / 1e6\n",
    "    pct_area = 100 * lc_count / np.sum(corine_10m > 0)\n",
    "\n",
    "    # Title with statistics\n",
    "    class_name = CORINE_CLASSES.get(lc_code, f'Class {lc_code}')\n",
    "    ax.set_title(f'Land Cover: {class_name}\\n'\n",
    "                 f'Code {lc_code} | Area: {area_km2:.1f} km² ({pct_area:.1f}%)',\n",
    "                 fontweight='bold', fontsize=13, pad=15)\n",
    "\n",
    "    ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "    ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "\n",
    "    # Legend with hatching\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=fill_color, edgecolor='black', linewidth=2,\n",
    "              alpha=0.4, hatch='///', label=class_name),\n",
    "        Patch(facecolor='none', edgecolor='red', linestyle='--',\n",
    "              linewidth=2, label='Study Area')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10,\n",
    "              frameon=True, fancybox=False, edgecolor='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    safe_name = class_name.replace(' ', '_').replace(',', '').replace('/', '_')\n",
    "    filename = f'landcover_{lc_code}_{safe_name}.png'\n",
    "    plt.savefig(RESULTS_DIR / filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(unique_classes)} individual land cover overlay maps\")"
   ],
   "id": "1e29cbe07c77b845",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAOCOM VS TINITALY COMPARISON"
   ],
   "id": "dcfddb52b458cc69"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# SAOCOM VS TINITALY COMPARISON\n",
    "# =============================================================================\n",
    "# Filter for valid comparisons with elevation range check\n",
    "valid_elevation_range = (50, 850)\n",
    "\n",
    "saocom_tinitaly_mask = (\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()) &\n",
    "    (saocom_gdf['tinitaly_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'] >= valid_elevation_range[0]) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'] <= valid_elevation_range[1]) &\n",
    "    (saocom_gdf['COHER'] >= 0.5)\n",
    ")\n",
    "saocom_tinitaly_valid = saocom_gdf[saocom_tinitaly_mask]\n",
    "\n",
    "saocom_tinitaly_diff = (saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'] -\n",
    "                        saocom_tinitaly_valid['tinitaly_height']).values\n",
    "\n",
    "saocom_tinitaly_metrics = {\n",
    "    'n_points': int(len(saocom_tinitaly_diff)),\n",
    "    'mean_diff': float(np.mean(saocom_tinitaly_diff)),\n",
    "    'median_diff': float(np.median(saocom_tinitaly_diff)),\n",
    "    'std_diff': float(np.std(saocom_tinitaly_diff)),\n",
    "    'rmse': float(np.sqrt(np.mean(saocom_tinitaly_diff**2))),\n",
    "    'mae': float(np.mean(np.abs(saocom_tinitaly_diff))),\n",
    "    'nmad': float(1.4826 * np.median(np.abs(saocom_tinitaly_diff - np.median(saocom_tinitaly_diff)))),\n",
    "    'min_diff': float(np.min(saocom_tinitaly_diff)),\n",
    "    'max_diff': float(np.max(saocom_tinitaly_diff)),\n",
    "    'correlation': float(np.corrcoef(saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'].values,\n",
    "                                     saocom_tinitaly_valid['tinitaly_height'].values)[0, 1])\n",
    "}\n",
    "\n",
    "saocom_tinitaly_tolerance = float(saocom_tinitaly_metrics['nmad'])\n",
    "saocom_tinitaly_higher_mask = saocom_tinitaly_diff > saocom_tinitaly_tolerance\n",
    "saocom_tinitaly_lower_mask = saocom_tinitaly_diff < -saocom_tinitaly_tolerance\n",
    "saocom_tinitaly_equal_mask = np.abs(saocom_tinitaly_diff) <= saocom_tinitaly_tolerance\n",
    "\n",
    "saocom_tinitaly_higher_count = np.sum(saocom_tinitaly_higher_mask)\n",
    "saocom_tinitaly_lower_count = np.sum(saocom_tinitaly_lower_mask)\n",
    "saocom_tinitaly_equal_count = np.sum(saocom_tinitaly_equal_mask)\n",
    "\n",
    "saocom_tinitaly_pct_higher = 100 * saocom_tinitaly_higher_count / len(saocom_tinitaly_diff)\n",
    "saocom_tinitaly_pct_lower = 100 * saocom_tinitaly_lower_count / len(saocom_tinitaly_diff)\n",
    "saocom_tinitaly_pct_equal = 100 * saocom_tinitaly_equal_count / len(saocom_tinitaly_diff)\n",
    "\n",
    "# =============================================================================\n",
    "# SAOCOM VS COPERNICUS COMPARISON\n",
    "# =============================================================================\n",
    "saocom_copernicus_mask = (\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'].notna()) &\n",
    "    (saocom_gdf['copernicus_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'] >= valid_elevation_range[0]) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'] <= valid_elevation_range[1]) &\n",
    "    (saocom_gdf['COHER'] >= 0.5)\n",
    ")\n",
    "saocom_copernicus_valid = saocom_gdf[saocom_copernicus_mask]\n",
    "\n",
    "saocom_copernicus_diff = (saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'] -\n",
    "                          saocom_copernicus_valid['copernicus_height']).values\n",
    "\n",
    "saocom_copernicus_metrics = {\n",
    "    'n_points': int(len(saocom_copernicus_diff)),\n",
    "    'mean_diff': float(np.mean(saocom_copernicus_diff)),\n",
    "    'median_diff': float(np.median(saocom_copernicus_diff)),\n",
    "    'std_diff': float(np.std(saocom_copernicus_diff)),\n",
    "    'rmse': float(np.sqrt(np.mean(saocom_copernicus_diff**2))),\n",
    "    'mae': float(np.mean(np.abs(saocom_copernicus_diff))),\n",
    "    'nmad': float(1.4826 * np.median(np.abs(saocom_copernicus_diff - np.median(saocom_copernicus_diff)))),\n",
    "    'min_diff': float(np.min(saocom_copernicus_diff)),\n",
    "    'max_diff': float(np.max(saocom_copernicus_diff)),\n",
    "    'correlation': float(np.corrcoef(saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'].values,\n",
    "                                     saocom_copernicus_valid['copernicus_height'].values)[0, 1])\n",
    "}\n",
    "\n",
    "saocom_copernicus_tolerance = float(saocom_copernicus_metrics['nmad'])\n",
    "saocom_copernicus_higher_mask = saocom_copernicus_diff > saocom_copernicus_tolerance\n",
    "saocom_copernicus_lower_mask = saocom_copernicus_diff < -saocom_copernicus_tolerance\n",
    "saocom_copernicus_equal_mask = np.abs(saocom_copernicus_diff) <= saocom_copernicus_tolerance\n",
    "\n",
    "saocom_copernicus_higher_count = int(np.sum(saocom_copernicus_higher_mask))\n",
    "saocom_copernicus_lower_count = int(np.sum(saocom_copernicus_lower_mask))\n",
    "saocom_copernicus_equal_count = int(np.sum(saocom_copernicus_equal_mask))\n",
    "\n",
    "saocom_copernicus_pct_higher = float(100 * saocom_copernicus_higher_count / len(saocom_copernicus_diff))\n",
    "saocom_copernicus_pct_lower = float(100 * saocom_copernicus_lower_count / len(saocom_copernicus_diff))\n",
    "saocom_copernicus_pct_equal = float(100 * saocom_copernicus_equal_count / len(saocom_copernicus_diff))\n",
    "\n"
   ],
   "id": "7e2a2b1d82f28030",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### 3d model\n"
   ],
   "id": "9df6e5752ca5ca64"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Use the cleaned dataset and outliers from Isolation Forest\n",
    "normal_sample_3d = saocom_gdf.sample(n=min(5000, len(saocom_gdf)), random_state=42)\n",
    "outlier_sample_3d = saocom_outliers.sample(n=min(500, len(saocom_outliers)), random_state=42) if len(saocom_outliers) > 0 else saocom_outliers\n",
    "\n",
    "# Create SAOCOM interpolated surface\n",
    "saocom_valid = saocom_gdf[saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()].copy()\n",
    "x_saocom = saocom_valid.geometry.x.values\n",
    "y_saocom = saocom_valid.geometry.y.values\n",
    "z_saocom = saocom_valid['HEIGHT_ABSOLUTE_TIN'].values\n",
    "\n",
    "# Create grid for surface\n",
    "xi = np.linspace(xmin_grid, xmax_grid, 100)\n",
    "yi = np.linspace(ymin_grid, ymax_grid, 100)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "# Interpolate SAOCOM surface\n",
    "zi_saocom = griddata((x_saocom, y_saocom), z_saocom, (xi_grid, yi_grid),\n",
    "                     method='linear', fill_value=np.nan)\n",
    "\n",
    "# Downsample TINITALY surface\n",
    "tinitaly_downsampled = tinitaly_10m[::10, ::10]\n",
    "x_tin = np.linspace(xmin_grid, xmax_grid, tinitaly_downsampled.shape[1])\n",
    "y_tin = np.linspace(ymax_grid, ymin_grid, tinitaly_downsampled.shape[0])\n",
    "x_tin_grid, y_tin_grid = np.meshgrid(x_tin, y_tin)\n",
    "tinitaly_downsampled = np.where(tinitaly_downsampled == NODATA, np.nan, tinitaly_downsampled)\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# TINITALY Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_tin_grid, y=y_tin_grid, z=tinitaly_downsampled,\n",
    "    colorscale='Earth', name='TINITALY DEM', showscale=True,\n",
    "    colorbar=dict(x=1.15, title='Elevation (m)'),\n",
    "    visible=True, opacity=0.8,\n",
    "    hovertemplate='X: %{x:.0f}<br>Y: %{y:.0f}<br>TINITALY: %{z:.1f}m<extra></extra>'\n",
    "))\n",
    "\n",
    "# SAOCOM Interpolated Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=xi_grid, y=yi_grid, z=zi_saocom,\n",
    "    colorscale='Viridis', name='SAOCOM Surface',\n",
    "    showscale=False, visible=False, opacity=0.7,\n",
    "    hovertemplate='X: %{x:.0f}<br>Y: %{y:.0f}<br>SAOCOM: %{z:.1f}m<extra></extra>'\n",
    "))\n",
    "\n",
    "# Normal SAOCOM Points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=normal_sample_3d.geometry.x, y=normal_sample_3d.geometry.y,\n",
    "    z=normal_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "    mode='markers', name='SAOCOM Points',\n",
    "    marker=dict(size=2, color=normal_sample_3d['diff_tinitaly'],\n",
    "                colorscale='RdBu_r', cmin=-10, cmax=10,\n",
    "                colorbar=dict(x=1.0, title='Residual (m)', len=0.5, y=0.25),\n",
    "                showscale=True, line=dict(width=0)),\n",
    "    text=[f\"Residual: {r:+.2f}m<br>Height: {h:.1f}m<br>Coherence: {c:.2f}\"\n",
    "          for r, h, c in zip(normal_sample_3d['diff_tinitaly'],\n",
    "                            normal_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "                            normal_sample_3d['COHER'])],\n",
    "    hovertemplate='%{text}<extra></extra>', visible=True\n",
    "))\n",
    "\n",
    "# Outlier Points\n",
    "if len(outlier_sample_3d) > 0:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=outlier_sample_3d.geometry.x, y=outlier_sample_3d.geometry.y,\n",
    "        z=outlier_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "        mode='markers', name='Outliers',\n",
    "        marker=dict(size=6, color='red', symbol='diamond',\n",
    "                   line=dict(color='black', width=1)),\n",
    "        text=[f\"<b>OUTLIER</b><br>Residual: {r:+.2f}m<br>Height: {h:.1f}m<br>Coherence: {c:.2f}\"\n",
    "              for r, h, c in zip(outlier_sample_3d['diff_tinitaly'],\n",
    "                                outlier_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "                                outlier_sample_3d['COHER'])],\n",
    "        hovertemplate='%{text}<extra></extra>', visible=True\n",
    "    ))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\", direction=\"down\", x=0.02, xanchor=\"left\",\n",
    "             y=0.98, yanchor=\"top\",\n",
    "             buttons=[\n",
    "                 dict(label=\"All\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, True, True, True]}]),\n",
    "                 dict(label=\"Surfaces Only\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, True, False, False]}]),\n",
    "                 dict(label=\"Points Only\", method=\"update\",\n",
    "                      args=[{\"visible\": [False, False, True, True]}]),\n",
    "                 dict(label=\"TINITALY + Points\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, False, True, True]}]),\n",
    "                 dict(label=\"SAOCOM Surface + Outliers\", method=\"update\",\n",
    "                      args=[{\"visible\": [False, True, False, True]}]),\n",
    "             ]),\n",
    "        dict(type=\"buttons\", direction=\"right\", x=0.02, xanchor=\"left\",\n",
    "             y=0.02, yanchor=\"bottom\",\n",
    "             buttons=[\n",
    "                 dict(label=\"Toggle TINITALY\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [0]]),\n",
    "                 dict(label=\"Toggle SAOCOM Surface\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [1]]),\n",
    "                 dict(label=\"Toggle Points\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [2]]),\n",
    "                 dict(label=\"Toggle Outliers\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [3]]),\n",
    "             ])\n",
    "    ],\n",
    "    scene=dict(xaxis_title='UTM Easting (m)', yaxis_title='UTM Northing (m)',\n",
    "               zaxis_title='Elevation (m)', aspectmode='manual',\n",
    "               aspectratio=dict(x=1, y=1, z=0.3),\n",
    "               camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))),\n",
    "    title=dict(text='3D SAOCOM vs TINITALY Analysis<br><sub>Top: Presets | Bottom: Toggle layers</sub>',\n",
    "               x=0.5, xanchor='center'),\n",
    "    width=1400, height=900, showlegend=True,\n",
    "    legend=dict(x=0.02, y=0.5),\n",
    "    paper_bgcolor='white', plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.write_html(RESULTS_DIR / 'saocom_3d_interactive.html')\n",
    "print(f\"Saved: {RESULTS_DIR / 'saocom_3d_interactive.html'}\")\n",
    "fig.show()"
   ],
   "id": "46df93334469b7ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Note: This script assumes the following variables are pre-defined from previous cells:\n",
    "# saocom_gdf, COHERENCE_THRESHOLD, hull_mask, hull_gdf, grid_height, grid_width,\n",
    "# target_transform, xmin_grid, xmax_grid, ymin_grid, ymax_grid,\n",
    "# saocom_tinitaly_metrics, saocom_copernicus_metrics, RESULTS_DIR\n",
    "\n",
    "def create_difference_grid(gdf, height_col, ref_col, grid_shape, transform, hull_mask):\n",
    "    \"\"\"Grids point data differences onto a raster grid using nearest neighbor interpolation.\"\"\"\n",
    "    query_str = f\"`{height_col}`.notna() & `{ref_col}`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "    valid_points = gdf.query(query_str).copy()\n",
    "    valid_points['diff'] = valid_points[height_col] - valid_points[ref_col]\n",
    "\n",
    "    if valid_points.empty:\n",
    "        return np.full(grid_shape, np.nan), valid_points\n",
    "\n",
    "    # Create grid coordinates for interpolation\n",
    "    grid_height, grid_width = grid_shape\n",
    "    x_coords = np.linspace(transform.c, transform.c + transform.a * grid_width, grid_width)\n",
    "    y_coords = np.linspace(transform.f, transform.f + transform.e * grid_height, grid_height)\n",
    "    xi_grid, yi_grid = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "    # Interpolate and mask the grid\n",
    "    diff_grid = griddata(\n",
    "        (valid_points.geometry.x, valid_points.geometry.y),\n",
    "        valid_points['diff'],\n",
    "        (xi_grid, yi_grid),\n",
    "        method='nearest'\n",
    "    )\n",
    "    diff_grid[~hull_mask] = np.nan\n",
    "    return diff_grid, valid_points\n",
    "\n",
    "def plot_panel(ax, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "    \"\"\"Helper function to plot a single map panel.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    cmap.set_bad(color='white', alpha=0)\n",
    "    extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "    im = ax.imshow(data, cmap=cmap, origin='upper', extent=extent, vmin=vmin, vmax=vmax)\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('UTM Easting (m)')\n",
    "    ax.set_ylabel('UTM Northing (m)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "    if stats_text:\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# --- Main Execution ---\n",
    "print(\"Gridding SAOCOM differences (using cleaned data)...\")\n",
    "diff_grid_tin, points_tin = create_difference_grid(saocom_gdf, 'HEIGHT_ABSOLUTE_TIN', 'tinitaly_height', (grid_height, grid_width), target_transform, hull_mask)\n",
    "diff_grid_cop, points_cop = create_difference_grid(saocom_gdf, 'HEIGHT_ABSOLUTE_COP', 'copernicus_height', (grid_height, grid_width), target_transform, hull_mask)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14), facecolor='white')\n",
    "fig.suptitle('SAOCOM vs. Reference DEMs - Gridded Difference Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plotting parameters\n",
    "v_tin = np.nanpercentile(np.abs(points_tin['diff']), 98)\n",
    "v_cop = np.nanpercentile(np.abs(points_cop['diff']), 98)\n",
    "stats_tin = f\"n = {len(points_tin):,}\\nMean = {points_tin['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_tin['diff']**2)):.2f} m\"\n",
    "stats_cop = f\"n = {len(points_cop):,}\\nMean = {points_cop['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_cop['diff']**2)):.2f} m\"\n",
    "\n",
    "# Row 1: SAOCOM vs TINITALY\n",
    "plot_panel(axes[0, 0], diff_grid_tin, 'SAOCOM - TINITALY\\nFull Difference', plt.cm.coolwarm, -v_tin, v_tin, stats_tin)\n",
    "plot_panel(axes[0, 1], np.where(diff_grid_tin > 0, diff_grid_tin, np.nan), 'SAOCOM > TINITALY', plt.cm.Reds, 0, v_tin)\n",
    "plot_panel(axes[0, 2], np.where(diff_grid_tin < 0, diff_grid_tin, np.nan), 'TINITALY > SAOCOM', plt.cm.Blues_r, -v_tin, 0)\n",
    "\n",
    "# Row 2: SAOCOM vs Copernicus\n",
    "plot_panel(axes[1, 0], diff_grid_cop, 'SAOCOM - Copernicus\\nFull Difference', plt.cm.coolwarm, -v_cop, v_cop, stats_cop)\n",
    "plot_panel(axes[1, 1], np.where(diff_grid_cop > 0, diff_grid_cop, np.nan), 'SAOCOM > Copernicus', plt.cm.Reds, 0, v_cop)\n",
    "plot_panel(axes[1, 2], np.where(diff_grid_cop < 0, diff_grid_cop, np.nan), 'Copernicus > SAOCOM', plt.cm.Blues_r, -v_cop, 0)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_gridded_comparison.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "a4c76d477db25c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Note: This script assumes the following variables are pre-defined from previous cells:\n",
    "# saocom_gdf, COHERENCE_THRESHOLD, hull_gdf, saocom_tinitaly_metrics,\n",
    "# saocom_copernicus_metrics, RESULTS_DIR, xmin_grid, xmax_grid, ymin_grid, ymax_grid\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function for plotting points (Unchanged)\n",
    "# =============================================================================\n",
    "def plot_points_panel(ax, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "    \"\"\"Helper function to plot a single map panel using a scatter plot.\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    im = ax.scatter(data.geometry.x, data.geometry.y, c=data['diff'],\n",
    "                    s=1, alpha=0.7, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('UTM Easting (m)')\n",
    "    ax.set_ylabel('UTM Northing (m)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "    if stats_text:\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# =============================================================================\n",
    "# Data preparation (Unchanged)\n",
    "# =============================================================================\n",
    "print(\"Filtering SAOCOM differences for plotting...\")\n",
    "\n",
    "query_str_tin = f\"`HEIGHT_ABSOLUTE_TIN`.notna() & `tinitaly_height`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "points_tin = saocom_gdf.query(query_str_tin).copy()\n",
    "points_tin['diff'] = points_tin['HEIGHT_ABSOLUTE_TIN'] - points_tin['tinitaly_height']\n",
    "\n",
    "query_str_cop = f\"`HEIGHT_ABSOLUTE_COP`.notna() & `copernicus_height`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "points_cop = saocom_gdf.query(query_str_cop).copy()\n",
    "points_cop['diff'] = points_cop['HEIGHT_ABSOLUTE_COP'] - points_cop['copernicus_height']\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "# =============================================================================\n",
    "# MODIFIED: Change subplot layout from (2, 3) to (3, 2) and adjust figsize\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 20), facecolor='white')\n",
    "fig.suptitle('SAOCOM vs. Reference DEMs - Point-Based Difference Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plotting parameters (Unchanged)\n",
    "v_tin = np.nanpercentile(np.abs(points_tin['diff']), 98)\n",
    "v_cop = np.nanpercentile(np.abs(points_cop['diff']), 98)\n",
    "stats_tin = f\"n = {len(points_tin):,}\\nMean = {points_tin['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_tin['diff']**2)):.2f} m\"\n",
    "stats_cop = f\"n = {len(points_cop):,}\\nMean = {points_cop['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_cop['diff']**2)):.2f} m\"\n",
    "\n",
    "# =============================================================================\n",
    "# MODIFIED: Update axes indexing for the new 3x2 layout\n",
    "# =============================================================================\n",
    "# Row 1: Full Difference Maps\n",
    "plot_points_panel(axes[0, 0], points_tin, 'SAOCOM - TINITALY\\nFull Difference', plt.cm.coolwarm, -v_tin, v_tin, stats_tin)\n",
    "plot_points_panel(axes[0, 1], points_cop, 'SAOCOM - Copernicus\\nFull Difference', plt.cm.coolwarm, -v_cop, v_cop, stats_cop)\n",
    "\n",
    "# Row 2: SAOCOM > Reference DEM\n",
    "plot_points_panel(axes[1, 0], points_tin[points_tin['diff'] > 0], 'SAOCOM > TINITALY', plt.cm.Reds, 0, v_tin)\n",
    "plot_points_panel(axes[1, 1], points_cop[points_cop['diff'] > 0], 'SAOCOM > Copernicus', plt.cm.Reds, 0, v_cop)\n",
    "\n",
    "# Row 3: Reference DEM > SAOCOM\n",
    "plot_points_panel(axes[2, 0], points_tin[points_tin['diff'] < 0], 'TINITALY > SAOCOM', plt.cm.Blues_r, -v_tin, 0)\n",
    "plot_points_panel(axes[2, 1], points_cop[points_cop['diff'] < 0], 'Copernicus > SAOCOM', plt.cm.Blues_r, -v_cop, 0)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_point_comparison_3x2.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "8547be97b46bc14e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edited Histograms\n",
    "\n"
   ],
   "id": "2552d2c8e2f0af1b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_distribution(ax, diff_series, title, metrics):\n",
    "    \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    ax.hist(diff_series, bins=20, alpha=0.75, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "    ax.axvline(metrics['mean_diff'], color='green', linestyle='-', label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "\n",
    "    stats_text = (f\"n = {metrics['n_points']:,}\\n\"\n",
    "                  f\"RMSE = {metrics['rmse']:.2f} m\\n\"\n",
    "                  f\"NMAD = {metrics['nmad']:.2f} m\\n\"\n",
    "                  f\"Std Dev = {metrics['std_diff']:.2f} m\")\n",
    "\n",
    "    ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Elevation Difference (m)', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "fig.suptitle('Residual Distributions (Cleaned Data)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Use the 'diff' column from the points DataFrames created in the previous cell\n",
    "plot_distribution(axes[0], points_tin['diff'], 'SAOCOM - TINITALY', saocom_tinitaly_metrics)\n",
    "plot_distribution(axes[1], points_cop['diff'], 'SAOCOM - Copernicus', saocom_copernicus_metrics)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_residual_distributions.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "35a39cdcef9b39c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_scatter_comparison(ax, x_data, y_data, x_label, y_label, title, stats):\n",
    "    \"\"\"\n",
    "    Creates a simple 1:1 scatter plot to compare two sets of height data.\n",
    "    \"\"\"\n",
    "    ax.set_facecolor('white') # Set background to white\n",
    "\n",
    "    # Plot the individual data points\n",
    "    ax.scatter(x_data, y_data, s=1, alpha=0.3, c='steelblue', label='Data Points')\n",
    "\n",
    "    # Determine plot limits and draw the 1:1 line\n",
    "    lims = [\n",
    "        np.min([x_data.min(), y_data.min()]),\n",
    "        np.max([x_data.max(), y_data.max()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'r--', linewidth=2, label='1:1 Line', zorder=10)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    # Add statistics box\n",
    "    stats_text = (f\"n = {stats.get('n_points', stats.get('n_pixels')):,}\\n\"\n",
    "                  f\"Bias = {stats['mean_diff']:.2f} m\\n\"\n",
    "                  f\"RMSE = {stats['rmse']:.2f} m\\n\"\n",
    "                  f\"Corr (r) = {stats['correlation']:.3f}\")\n",
    "\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', color='black', # Text color to black\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7, edgecolor='black'))\n",
    "\n",
    "    # Style the plot\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12, color='black')\n",
    "    ax.set_xlabel(x_label, fontsize=11, color='black')\n",
    "    ax.set_ylabel(y_label, fontsize=11, color='black')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    # Style ticks and spines\n",
    "    ax.tick_params(colors='black')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison Scatter Plots (Cleaned Data)', fontsize=16, fontweight='bold', color='black')\n",
    "\n",
    "# Note: Assumes variables from previous cells are available\n",
    "# (points_tin, points_cop, valid_copernicus, valid_tinitaly, and all metrics dicts)\n",
    "\n",
    "plot_scatter_comparison(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "                        'TINITALY Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs TINITALY', saocom_tinitaly_metrics)\n",
    "\n",
    "plot_scatter_comparison(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "                        'Copernicus Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs Copernicus', saocom_copernicus_metrics)\n",
    "\n",
    "plot_scatter_comparison(axes[2], valid_copernicus, valid_tinitaly,\n",
    "                        'Copernicus Height (m)', 'TINITALY Height (m)', 'TINITALY vs Copernicus', ref_metrics)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_scatter_comparisons.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "ad0592af1ecb781c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Plots Color\n"
   ],
   "id": "fba9c88aaa617de3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison - High-Contrast Hexbin Density Plots', fontsize=16, fontweight='bold')\n",
    "\n",
    "def plot_hexbin(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Helper function to create a hexbin plot with improved contrast.\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    # Create the hexbin plot\n",
    "    # CHANGE 1: Switched to 'inferno' colormap for a high-contrast, \"hotter\" look.\n",
    "    # Other good options are 'plasma' or 'magma'.\n",
    "    hb = ax.hexbin(x_data, y_data, gridsize=150, cmap='inferno',\n",
    "                   norm=colors.LogNorm(), mincnt=1) # Log scale is essential\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(hb, ax=ax, label='Point Count')\n",
    "\n",
    "    # CHANGE 2: Switched 1:1 line to red for better visibility against the colormap.\n",
    "    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "    ax.plot(lims, lims, 'r--', linewidth=2, label='1:1 line', alpha=0.9)\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel(y_label, fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "# This is an alternative function you can use instead of plot_hexbin for a different style.\n",
    "def plot_hist2d(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Alternative helper function to create a 2D histogram (square bins).\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    # Create the 2D histogram\n",
    "    # Bins determines the resolution. Cmin=1 ensures empty bins are not colored.\n",
    "    h = ax.hist2d(x_data, y_data, bins=150, cmap='inferno',\n",
    "                  norm=colors.LogNorm(), cmin=1)\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(h[3], ax=ax, label='Point Count')\n",
    "\n",
    "    # Add 1:1 line\n",
    "    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "    ax.plot(lims, lims, 'w--', linewidth=1.5, label='1:1 line', alpha=0.7) # White line works well here\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel(y_label, fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "# Plot 1: SAOCOM vs TINITALY\n",
    "plot_hexbin(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "            'TINITALY Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs TINITALY')\n",
    "\n",
    "# Plot 2: SAOCOM vs Copernicus\n",
    "plot_hexbin(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "            'Copernicus Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs Copernicus')\n",
    "\n",
    "# Plot 3: TINITALY vs Copernicus\n",
    "plot_hexbin(axes[2], valid_copernicus, valid_tinitaly,\n",
    "            'Copernicus Height (m)', 'TINITALY Height (m)', 'TINITALY vs Copernicus')\n",
    "\n",
    "# To use the 2D histogram instead, you would replace the calls above with:\n",
    "# plot_hist2d(axes[0], ...)\n",
    "# plot_hist2d(axes[1], ...)\n",
    "# plot_hist2d(axes[2], ...)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_hexbin_comparisons_high_contrast.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "2f58890e63e14cc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison - Bland-Altman Density Plots', fontsize=16, fontweight='bold')\n",
    "\n",
    "def plot_bland_altman(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Helper function to create a Bland-Altman hexbin plot.\"\"\"\n",
    "    # --- Data Transformation ---\n",
    "    # Calculate the average and difference\n",
    "    average = (x_data + y_data) / 2\n",
    "    difference = y_data - x_data\n",
    "\n",
    "    # Calculate key statistics for the plot\n",
    "    mean_diff = np.mean(difference)\n",
    "    std_diff = np.std(difference)\n",
    "    limit_of_agreement = 1.96 * std_diff\n",
    "\n",
    "    ax.set_facecolor('gainsboro')\n",
    "    # Create the hexbin plot using the transformed data\n",
    "    hb = ax.hexbin(average, difference, gridsize=150, cmap='viridis',\n",
    "                   norm=colors.LogNorm(), mincnt=1)\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(hb, ax=ax, label='Point Count')\n",
    "\n",
    "    # --- Add Statistical Lines ---\n",
    "    # Line of perfect agreement (zero difference)\n",
    "    ax.axhline(0, color='white', linestyle='--', linewidth=1.5, label='Zero (Perfect Agreement)')\n",
    "    # Mean difference line\n",
    "    ax.axhline(mean_diff, color='red', linestyle='-', linewidth=2, label=f'Mean Diff: {mean_diff:.2f} m')\n",
    "    # Limits of agreement lines (+/- 1.96 * SD)\n",
    "    ax.axhline(mean_diff + limit_of_agreement, color='red', linestyle='--', linewidth=1.5, label=f'Limits of Agreement (±{limit_of_agreement:.2f} m)')\n",
    "    ax.axhline(mean_diff - limit_of_agreement, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    # Update axis labels for the new plot type\n",
    "    ax.set_xlabel(f'Average of ({x_label} and {y_label})', fontsize=11)\n",
    "    ax.set_ylabel(f'Difference ({y_label} - {x_label})', fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "\n",
    "# Plot 1: SAOCOM vs TINITALY\n",
    "plot_bland_altman(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "                  'SAOCOM', 'TINITALY', 'SAOCOM vs TINITALY')\n",
    "\n",
    "# Plot 2: SAOCOM vs Copernicus\n",
    "plot_bland_altman(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "                  'SAOCOM', 'Copernicus', 'SAOCOM vs Copernicus')\n",
    "\n",
    "# Plot 3: TINITALY vs Copernicus\n",
    "plot_bland_altman(axes[2], valid_copernicus, valid_tinitaly,\n",
    "                  'TINITALY', 'Copernicus', 'TINITALY vs Copernicus')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_bland_altman_comparisons.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "430440df9a6fb7a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAOCOM VS REFERENCE DEMs - GRIDDED COMPARISON ANALYSIS"
   ],
   "id": "76f9dfbdbc8aca15"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.interpolate import griddata\n",
    "# from scipy import stats\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 1. GRIDDED DEM COMPARISON\n",
    "# # =============================================================================\n",
    "#\n",
    "# def process_dem_comparison(gdf, height_col, ref_col, grid_shape, transform, hull_mask, metrics):\n",
    "#     \"\"\"Grids SAOCOM point differences and classifies them against a tolerance.\"\"\"\n",
    "#     # Filter for valid, coherent points and calculate difference\n",
    "#     valid_mask = gdf[height_col].notna() & gdf[ref_col].notna() & (gdf['COHER'] >= COHERENCE_THRESHOLD)\n",
    "#     points = gdf[valid_mask].copy()\n",
    "#     points['diff'] = points[height_col] - points[ref_col]\n",
    "#\n",
    "#     # Interpolate difference onto a grid\n",
    "#     grid_height, grid_width = grid_shape\n",
    "#     xi, yi = np.meshgrid(\n",
    "#         np.linspace(transform.c, transform.c + transform.a * grid_width, grid_width),\n",
    "#         np.linspace(transform.f, transform.f + transform.e * grid_height, grid_height)\n",
    "#     )\n",
    "#     diff_grid = griddata(\n",
    "#         (points.geometry.x, points.geometry.y), points['diff'],\n",
    "#         (xi, yi), method='nearest'\n",
    "#     )\n",
    "#     diff_grid[~hull_mask] = np.nan # Apply hull mask\n",
    "#\n",
    "#     # Classify differences based on NMAD tolerance\n",
    "#     tolerance = metrics['nmad']\n",
    "#     with np.errstate(invalid='ignore'): # Ignore warnings from comparing with NaN\n",
    "#         higher_mask = diff_grid > tolerance\n",
    "#         lower_mask = diff_grid < -tolerance\n",
    "#\n",
    "#     # Generate statistics\n",
    "#     n_valid = np.count_nonzero(~np.isnan(diff_grid))\n",
    "#     stats_dict = {\n",
    "#         'n_total': n_valid,\n",
    "#         'n_higher': np.sum(higher_mask), 'pct_higher': 100 * np.sum(higher_mask) / n_valid,\n",
    "#         'n_lower': np.sum(lower_mask), 'pct_lower': 100 * np.sum(lower_mask) / n_valid,\n",
    "#     }\n",
    "#     return diff_grid, higher_mask, lower_mask, stats_dict, points\n",
    "#\n",
    "# def plot_gridded_comparison(axes, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "#     \"\"\"Helper function to plot a single difference map.\"\"\"\n",
    "#     ax = axes\n",
    "#     ax.set_facecolor('white')\n",
    "#     cmap.set_bad(color='white', alpha=0)\n",
    "#     im = ax.imshow(data, cmap=cmap, origin='upper', extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid], vmin=vmin, vmax=vmax)\n",
    "#     hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "#     plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "#     ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "#     ax.set_xlabel('UTM Easting (m)')\n",
    "#     ax.set_ylabel('UTM Northing (m)')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "#     if stats_text:\n",
    "#         ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9, va='top',\n",
    "#                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "# # --- Main Plotting Logic for Gridded Comparison ---\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(20, 14), facecolor='white')\n",
    "#\n",
    "# # Define datasets to compare\n",
    "# comparisons = [\n",
    "#     {'name': 'TINITALY', 'h_col': 'HEIGHT_ABSOLUTE_TIN', 'r_col': 'tinitaly_height', 'metrics': saocom_tinitaly_metrics},\n",
    "#     {'name': 'Copernicus', 'h_col': 'HEIGHT_ABSOLUTE_COP', 'r_col': 'copernicus_height', 'metrics': saocom_copernicus_metrics}\n",
    "# ]\n",
    "#\n",
    "# for i, p in enumerate(comparisons):\n",
    "#     diff_grid, higher, lower, stats, points = process_dem_comparison(\n",
    "#         saocom_gdf, p['h_col'], p['r_col'], (grid_height, grid_width), target_transform, hull_mask, p['metrics']\n",
    "#     )\n",
    "#\n",
    "#     # Plot 1: Full Difference\n",
    "#     diff_limit = np.percentile(np.abs(points['diff']), 95)\n",
    "#     stats1 = f\"Points: {stats['n_total']:,}\\nMean: {p['metrics']['mean_diff']:+.2f}m\\nRMSE: {p['metrics']['rmse']:.2f}m\\nNMAD: {p['metrics']['nmad']:.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 0], diff_grid, f\"SAOCOM - {p['name']}\\nFull Difference\", plt.cm.coolwarm.copy(), -diff_limit, diff_limit, stats1)\n",
    "#\n",
    "#     # Plot 2: SAOCOM Higher\n",
    "#     higher_grid = np.where(higher, diff_grid, np.nan)\n",
    "#     stats2 = f\"Points: {stats['n_higher']:,}\\nMean: {np.nanmean(higher_grid):.2f}m\\nMax: {np.nanmax(higher_grid):.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 1], higher_grid, f\"SAOCOM > {p['name']}\\n({stats['pct_higher']:.1f}%)\", plt.cm.YlOrRd.copy(), 0, np.nanmax(higher_grid), stats2)\n",
    "#\n",
    "#     # Plot 3: SAOCOM Lower\n",
    "#     lower_grid = np.where(lower, diff_grid, np.nan)\n",
    "#     stats3 = f\"Points: {stats['n_lower']:,}\\nMean: {np.nanmean(lower_grid):.2f}m\\nMin: {np.nanmin(lower_grid):.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 2], lower_grid, f\"{p['name']} > SAOCOM\\n({stats['pct_lower']:.1f}%)\", plt.cm.Blues_r.copy(), np.nanmin(lower_grid), 0, stats3)\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_comparison_directional.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 2. RESIDUAL DISTRIBUTION HISTOGRAMS\n",
    "# # =============================================================================\n",
    "#\n",
    "# def plot_residual_histogram(ax, diff_series, metrics, tolerance, title):\n",
    "#     \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "#     ax.hist(diff_series, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "#     ax.axvline(0, color='red', ls='--', lw=2, label='Zero')\n",
    "#     ax.axvline(metrics['mean_diff'], color='green', ls='-', lw=2, label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "#     ax.axvline(tolerance, color='orange', ls='--', lw=1.5, label=f\"±NMAD: {tolerance:.2f}m\")\n",
    "#     ax.axvline(-tolerance, color='orange', ls='--', lw=1.5)\n",
    "#\n",
    "#     stats_text = f\"n = {metrics['n_points']:,}\\nRMSE = {metrics['rmse']:.2f}m\\nNMAD = {metrics['nmad']:.2f}m\\nStd Dev = {metrics['std_diff']:.2f}m\"\n",
    "#     ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=9, va='top', ha='right',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "#     ax.set(xlabel='Elevation Difference (m)', ylabel='Frequency (Log Scale)',\n",
    "#            title=title, yscale='log')\n",
    "#     ax.legend(loc='upper right', fontsize=10)\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "# plot_residual_histogram(axes[0], saocom_tinitaly_diff, saocom_tinitaly_metrics, saocom_tinitaly_tolerance, 'SAOCOM - TINITALY Distribution')\n",
    "# plot_residual_histogram(axes[1], saocom_copernicus_diff, saocom_copernicus_metrics, saocom_copernicus_tolerance, 'SAOCOM - Copernicus Distribution')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_residual_distributions.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 3. ENSEMBLE OUTLIER DETECTION\n",
    "# # =============================================================================\n",
    "#\n",
    "# # Filter for valid heights and run detection methods\n",
    "# valid_saocom = saocom_gdf[saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()].copy()\n",
    "# heights = valid_saocom['HEIGHT_ABSOLUTE_TIN']\n",
    "#\n",
    "# # Method 1: IQR (3x multiplier for extreme outliers)\n",
    "# q1, q3 = heights.quantile(0.25), heights.quantile(0.75)\n",
    "# iqr = q3 - q1\n",
    "# outliers_iqr = (heights < (q1 - 3 * iqr)) | (heights > (q3 + 3 * iqr))\n",
    "#\n",
    "# # Method 2: Z-score\n",
    "# outliers_zscore = np.abs(stats.zscore(heights)) > 3\n",
    "#\n",
    "# # Method 3: Modified Z-score (NMAD-based)\n",
    "# median_abs_dev = np.median(np.abs(heights - heights.median()))\n",
    "# mod_z_scores = 0.6745 * (heights - heights.median()) / median_abs_dev\n",
    "# outliers_nmad = np.abs(mod_z_scores) > 3.5\n",
    "#\n",
    "# # Combine methods: outlier if flagged by at least 2\n",
    "# is_outlier = np.sum([outliers_iqr, outliers_zscore, outliers_nmad], axis=0) >= 2\n",
    "# valid_saocom['is_outlier'] = is_outlier\n",
    "# normal_points = valid_saocom[~is_outlier]\n",
    "# outlier_points = valid_saocom[is_outlier]\n",
    "#\n",
    "# print(f\"Ensemble outlier detection complete. Found {len(outlier_points)} outliers.\")\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 4. OUTLIER VISUALIZATION & ANALYSIS\n",
    "# # =============================================================================\n",
    "#\n",
    "# fig = plt.figure(figsize=(18, 16), facecolor='white')\n",
    "# gs = fig.add_gridspec(2, 2)\n",
    "#\n",
    "# # Plot 1: Spatial Distribution\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# normal_points.plot(ax=ax1, markersize=0.5, color='#2E86AB', alpha=0.4, label=f'Normal ({len(normal_points):,})')\n",
    "# if not outlier_points.empty:\n",
    "#     outlier_points.plot(ax=ax1, markersize=8, color='#E63946', alpha=0.9, ec='black', lw=0.3, label=f'Outliers ({len(outlier_points):,})')\n",
    "# hull_gdf.boundary.plot(ax=ax1, color='black', lw=2, ls='--')\n",
    "# ax1.set(title='SAOCOM Height Outliers - Spatial Distribution', xlabel='UTM Easting (m)', ylabel='UTM Northing (m)')\n",
    "# ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Plot 2: Height Distribution\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# ax2.hist(normal_points['HEIGHT_ABSOLUTE_TIN'], bins=50, alpha=0.6, color='#2E86AB', label='Normal')\n",
    "# if not outlier_points.empty:\n",
    "#     ax2.hist(outlier_points['HEIGHT_ABSOLUTE_TIN'], bins=20, alpha=0.8, color='#E63946', label='Outliers')\n",
    "# ax2.axvline(q1 - 3 * iqr, color='orange', ls='--', label=f'IQR Bound')\n",
    "# ax2.axvline(q3 + 3 * iqr, color='orange', ls='--')\n",
    "# ax2.set(title='Height Distribution with Outlier Thresholds', xlabel='Height (m)', ylabel='Frequency')\n",
    "# ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Plot 3: Box Plot\n",
    "# ax3 = fig.add_subplot(gs[1, 0])\n",
    "# box_data = [normal_points['HEIGHT_ABSOLUTE_TIN'].dropna()]\n",
    "# if not outlier_points.empty:\n",
    "#     box_data.append(outlier_points['HEIGHT_ABSOLUTE_TIN'].dropna())\n",
    "# bp = ax3.boxplot(box_data, patch_artist=True, showmeans=True, meanline=True,\n",
    "#                  labels=['Normal', 'Outliers'] if not outlier_points.empty else ['Normal'])\n",
    "# colors = ['#2E86AB', '#E63946']\n",
    "# for patch, color in zip(bp['boxes'], colors):\n",
    "#     patch.set_facecolor(color)\n",
    "# ax3.set(title='Height Distribution Comparison', ylabel='Height (m)')\n",
    "# ax3.grid(True, axis='y', alpha=0.3)\n",
    "#\n",
    "# # Plot 4: Summary Text\n",
    "# ax4 = fig.add_subplot(gs[1, 1])\n",
    "# ax4.axis('off')\n",
    "# summary_text = f\"\"\"OUTLIER ANALYSIS SUMMARY\n",
    "# -----------------------------------\n",
    "# Flagged by IQR Method: {np.sum(outliers_iqr):,}\n",
    "# Flagged by Z-score: {np.sum(outliers_zscore):,}\n",
    "# Flagged by Mod. Z-score: {np.sum(outliers_nmad):,}\n",
    "# -----------------------------------\n",
    "# Final Outliers (≥2 methods): {len(outlier_points):,} ({len(outlier_points)/len(valid_saocom):.2%})\n",
    "# Normal Points: {len(normal_points):,}\n",
    "# -----------------------------------\n",
    "# Normal Mean Height: {normal_points['HEIGHT_ABSOLUTE_TIN'].mean():.2f} m\n",
    "# Outlier Mean Height: {outlier_points['HEIGHT_ABSOLUTE_TIN'].mean():.2f} m\n",
    "# \"\"\"\n",
    "# ax4.text(0.05, 0.5, summary_text, va='center', fontfamily='monospace',\n",
    "#          bbox=dict(boxstyle='round', facecolor='white', ec='black'))\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_height_outliers_ensemble.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 5. SCATTER PLOT COMPARISONS\n",
    "# # =============================================================================\n",
    "#\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(18, 16), facecolor='white')\n",
    "# axes[1, 1].axis('off') # Hide unused subplot\n",
    "#\n",
    "# # Define scatter plot configurations\n",
    "# scatter_plots = [\n",
    "#     {'ax': axes[0, 0], 'x': saocom_tinitaly_valid['tinitaly_height'], 'y': saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'],\n",
    "#      'title': 'SAOCOM vs TINITALY', 'xlabel': 'TINITALY Height (m)', 'metrics': saocom_tinitaly_metrics},\n",
    "#     {'ax': axes[0, 1], 'x': saocom_copernicus_valid['copernicus_height'], 'y': saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'],\n",
    "#      'title': 'SAOCOM vs Copernicus', 'xlabel': 'Copernicus Height (m)', 'metrics': saocom_copernicus_metrics},\n",
    "#     {'ax': axes[1, 0], 'x': valid_copernicus, 'y': valid_tinitaly,\n",
    "#      'title': 'TINITALY vs Copernicus', 'xlabel': 'Copernicus Height (m)', 'ylabel': 'TINITALY Height (m)', 'metrics': ref_metrics},\n",
    "# ]\n",
    "#\n",
    "# for p in scatter_plots:\n",
    "#     ax = p['ax']\n",
    "#     ax.scatter(p['x'], p['y'], s=1, alpha=0.3, c='steelblue', ec='none')\n",
    "#     min_val, max_val = min(p['x'].min(), p['y'].min()), max(p['x'].max(), p['y'].max())\n",
    "#     ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='1:1 line')\n",
    "#\n",
    "#     stats_text = (f\"n = {p['metrics'].get('n_points', p['metrics'].get('n_pixels')):,}\\n\"\n",
    "#                   f\"Bias = {p['metrics']['mean_diff']:.2f}m\\nRMSE = {p['metrics']['rmse']:.2f}m\\n\"\n",
    "#                   f\"NMAD = {p['metrics']['nmad']:.2f}m\\nCorr (r) = {p['metrics']['correlation']:.3f}\")\n",
    "#\n",
    "#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9, va='top', fontfamily='monospace',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "#     ax.set(title=p['title'], xlabel=p['xlabel'], ylabel=p.get('ylabel', 'SAOCOM Height (m)'))\n",
    "#     ax.legend(); ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "f085d9c25aaf5f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOID ZONES vs LAND COVER ANALYSIS"
   ],
   "id": "c50172c64661ce9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# VOID ZONES vs LAND COVER ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CALCULATE VOID STATISTICS BY LAND COVER\n",
    "# =============================================================================\n",
    "void_lc_stats = []\n",
    "\n",
    "for lc_code in np.unique(corine_10m[corine_10m > 0]):\n",
    "    lc_mask = (corine_10m == lc_code) & study_area_mask\n",
    "\n",
    "    total_lc_cells = np.sum(lc_mask)\n",
    "    void_lc_cells = np.sum(lc_mask & void_mask)\n",
    "\n",
    "    if total_lc_cells == 0:\n",
    "        continue\n",
    "\n",
    "    pct_lc_is_void = 100 * void_lc_cells / total_lc_cells\n",
    "    pct_of_total_voids = 100 * void_lc_cells / np.sum(void_mask)\n",
    "\n",
    "    void_lc_stats.append({\n",
    "        'LC_Code': lc_code,\n",
    "        'LC_Name': CORINE_CLASSES.get(lc_code, f'Unknown_{lc_code}'),\n",
    "        'Total_Cells': total_lc_cells,\n",
    "        'Void_Cells': void_lc_cells,\n",
    "        'Area_km2': total_lc_cells * (GRID_SIZE**2) / 1e6,\n",
    "        'Void_Area_km2': void_lc_cells * (GRID_SIZE**2) / 1e6,\n",
    "        'Pct_LC_is_Void': pct_lc_is_void,\n",
    "        'Pct_of_Total_Voids': pct_of_total_voids\n",
    "    })\n",
    "\n",
    "void_lc_df = pd.DataFrame(void_lc_stats).sort_values('Pct_LC_is_Void', ascending=False)\n",
    "\n",
    "# Display table\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(\"VOID ZONES BY LAND COVER CLASS\")\n",
    "print(f\"{'='*120}\")\n",
    "print(void_lc_df[['LC_Code', 'LC_Name', 'Area_km2', 'Void_Area_km2', 'Pct_LC_is_Void', 'Pct_of_Total_Voids']].to_string(index=False))\n",
    "print(f\"{'='*120}\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MAP: VOID ZONES WITH LAND COVER OVERLAY\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Sentinel background\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.6)\n",
    "\n",
    "# Land cover in void zones only\n",
    "lc_in_voids = corine_10m.copy()\n",
    "lc_in_voids[~void_mask] = 0\n",
    "lc_display = np.ma.masked_where(lc_in_voids == 0, lc_in_voids)\n",
    "\n",
    "void_codes = np.unique(lc_display.compressed())\n",
    "\n",
    "if len(void_codes) > 0:\n",
    "    colors_list = [CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5)) for code in void_codes]\n",
    "    cmap = ListedColormap(colors_list)\n",
    "    norm = BoundaryNorm(boundaries=np.append(void_codes, void_codes[-1]+1) - 0.5,\n",
    "                        ncolors=len(void_codes))\n",
    "\n",
    "    im = ax.imshow(lc_display, cmap=cmap, norm=norm, origin='upper',\n",
    "                  extent=extent, alpha=0.7)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Statistics box\n",
    "void_area = np.sum(void_mask) * (GRID_SIZE**2) / 1e6\n",
    "total_area = np.sum(study_area_mask) * (GRID_SIZE**2) / 1e6\n",
    "pct_void = 100 * np.sum(void_mask) / np.sum(study_area_mask)\n",
    "\n",
    "stats_text = f\"\"\"Void Area: {void_area:.2f} km²\n",
    "Total Area: {total_area:.2f} km²\n",
    "Void %: {pct_void:.1f}%\n",
    "LC Classes: {len(void_codes)}\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "        alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Legend\n",
    "if len(void_codes) > 0:\n",
    "    legend_elements = [mpatches.Rectangle((0,0),1,1,\n",
    "                                         facecolor=CORINE_COLORS_MPL[code],\n",
    "                                         edgecolor='black', linewidth=0.5,\n",
    "                                         label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\")\n",
    "                      for code in sorted(void_codes)]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "             fontsize=9, frameon=True, fancybox=False, edgecolor='black',\n",
    "             title='Land Cover in Void Zones')\n",
    "\n",
    "ax.set_title('Land Cover Distribution in SAOCOM Void Zones',\n",
    "             fontweight='bold', fontsize=14, pad=15)\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "saocom_gdf.plot(ax=ax, markersize=1, color='black', alpha=0.8, label='SAOCOM Points')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'voids_by_landcover_map.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: voids_by_landcover_map.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. BAR CHART: WHICH LAND COVERS HAVE THE MOST VOIDS\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), facecolor='white')\n",
    "\n",
    "# Chart 1: % of each land cover that is void\n",
    "top_pct = void_lc_df.nlargest(15, 'Pct_LC_is_Void')\n",
    "bars1 = ax1.barh(range(len(top_pct)), top_pct['Pct_LC_is_Void'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_pct.iterrows()):\n",
    "    bars1[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars1[i].set_edgecolor('black')\n",
    "    bars1[i].set_linewidth(0.5)\n",
    "\n",
    "ax1.set_yticks(range(len(top_pct)))\n",
    "ax1.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_pct.iterrows()], fontsize=9)\n",
    "ax1.set_xlabel('% of Land Cover Class that is Void', fontsize=11)\n",
    "ax1.set_title('Land Covers with Highest Void Percentage\\n(Worst Coverage Performance)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax1.axvline(pct_void, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Overall Void Rate: {pct_void:.1f}%')\n",
    "ax1.legend()\n",
    "\n",
    "# Chart 2: Contribution to total voids\n",
    "top_contrib = void_lc_df.nlargest(15, 'Pct_of_Total_Voids')\n",
    "bars2 = ax2.barh(range(len(top_contrib)), top_contrib['Pct_of_Total_Voids'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_contrib.iterrows()):\n",
    "    bars2[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars2[i].set_edgecolor('black')\n",
    "    bars2[i].set_linewidth(0.5)\n",
    "\n",
    "ax2.set_yticks(range(len(top_contrib)))\n",
    "ax2.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_contrib.iterrows()], fontsize=9)\n",
    "ax2.set_xlabel('% of Total Void Area', fontsize=11)\n",
    "ax2.set_title('Land Covers Contributing Most to Total Voids\\n(Largest Void Areas)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'voids_by_landcover_charts.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: voids_by_landcover_charts.png\")\n",
    "print(\"\\nVoid analysis complete!\")"
   ],
   "id": "a19eb2bd9cea6a49",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOID ZONES vs LAND COVER - \"SWISS CHEESE\" VISUALIZATION"
   ],
   "id": "c38c0d45d061311f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # =============================================================================\n",
    "# # VOID ZONES vs LAND COVER - \"SWISS CHEESE\" VISUALIZATION\n",
    "# # =============================================================================\n",
    "#\n",
    "# # =============================================================================\n",
    "# # LAND COVER WITH VOIDS - OUTLINED POLYGONS VERSION\n",
    "# # =============================================================================\n",
    "#\n",
    "#\n",
    "#\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(16, 12), facecolor='white')\n",
    "# ax.set_facecolor('white')\n",
    "#\n",
    "# extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "#\n",
    "# # Get unique land cover classes\n",
    "# display_codes = np.unique(corine_10m[(corine_10m > 0) & ~void_mask])\n",
    "#\n",
    "# print(\"Vectorizing land cover polygons (this may take a moment)...\")\n",
    "# im = ax.imshow(corine_display, cmap=cmap, norm=norm, origin='upper', extent=extent, alpha = 0.2)\n",
    "#\n",
    "# # Process each land cover class\n",
    "# for lc_code in sorted(display_codes):\n",
    "#     # Create mask: this land cover AND has SAOCOM coverage (not void)\n",
    "#     lc_with_coverage = (corine_10m == lc_code) & (~void_mask)\n",
    "#\n",
    "#     # Vectorize to get boundaries\n",
    "#     mask_shapes = shapes(lc_with_coverage.astype(np.uint8),\n",
    "#                         mask=lc_with_coverage,\n",
    "#                         transform=target_transform)\n",
    "#\n",
    "#     # Convert to shapely polygons\n",
    "#     polys = [shape(geom) for geom, val in mask_shapes if val == 1]\n",
    "#\n",
    "#     # Get color for this land cover\n",
    "#     fill_color = CORINE_COLORS_MPL.get(lc_code, (0.5, 0.5, 0.5))\n",
    "#\n",
    "#     # Draw each polygon\n",
    "#     for poly in polys:\n",
    "#         if poly.is_valid:\n",
    "#             x, y = poly.exterior.xy\n",
    "#\n",
    "#             # Very faint fill\n",
    "#             ax.fill(x, y, color=fill_color, alpha=0.15, edgecolor='none', zorder=1)\n",
    "#\n",
    "#             # Colored outline\n",
    "#             ax.plot(x, y, color=fill_color, linewidth=1.5, alpha=0.9, zorder=2)\n",
    "#\n",
    "# # Study area boundary (on top)\n",
    "# hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--', zorder=3)\n",
    "#\n",
    "# # Statistics\n",
    "# void_area = np.sum(void_mask) * (GRID_SIZE**2) / 1e6\n",
    "# total_area = np.sum(study_area_mask) * (GRID_SIZE**2) / 1e6\n",
    "# pct_void = 100 * np.sum(void_mask) / np.sum(study_area_mask)\n",
    "#\n",
    "# stats_text = f\"\"\"Void Area: {void_area:.2f} km²\n",
    "# Coverage Area: {total_area - void_area:.2f} km²\n",
    "# Void %: {pct_void:.1f}%\n",
    "# Coverage %: {100 - pct_void:.1f}%\"\"\"\n",
    "#\n",
    "# ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=13,\n",
    "#         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "#         alpha=0.9, edgecolor='black'), zorder=4)\n",
    "# # Legend\n",
    "# legend_elements = []\n",
    "# for code in sorted(display_codes):\n",
    "#     color = CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5))\n",
    "#     legend_elements.append(mpatches.Rectangle((0,0),1,1,\n",
    "#                                              facecolor=color,\n",
    "#                                              edgecolor=color,\n",
    "#                                              alpha=0.3,\n",
    "#                                              linewidth=2,\n",
    "#                                              label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\"))\n",
    "#\n",
    "# legend_elements.append(mpatches.Rectangle((0,0),1,1,\n",
    "#                                          facecolor='white',\n",
    "#                                          edgecolor='gray',\n",
    "#                                          linewidth=1,\n",
    "#                                          label='VOID (No SAOCOM Data)'))\n",
    "#\n",
    "# ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "#          fontsize=13, frameon=True, fancybox=False, edgecolor='black',\n",
    "#          title='Land Cover Classes')\n",
    "#\n",
    "# ax.set_title('CORINE Land Cover with SAOCOM Void Zones\\n(White areas = No coverage)',\n",
    "#              fontweight='bold', fontsize=14, pad=15)\n",
    "# ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "# ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "# ax.set_xlim(extent[0], extent[1])\n",
    "# ax.set_ylim(extent[2], extent[3])\n",
    "# ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'landcover_with_voids_outlined.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "# plt.show()\n",
    "#\n",
    "# print(\"Saved: landcover_with_voids_outlined.png\")\n",
    "#\n",
    "# # # =============================================================================\n",
    "# # # 3. BAR CHART WITH REFERENCE LINES\n",
    "# # # =============================================================================\n",
    "# # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), facecolor='white')\n",
    "# #\n",
    "# # # Chart 1: % of each land cover that is void\n",
    "# # top_pct = void_lc_df.nlargest(15, 'Pct_LC_is_Void')\n",
    "# # bars1 = ax1.barh(range(len(top_pct)), top_pct['Pct_LC_is_Void'])\n",
    "# #\n",
    "# # for i, (_, row) in enumerate(top_pct.iterrows()):\n",
    "# #     bars1[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "# #     bars1[i].set_edgecolor('black')\n",
    "# #     bars1[i].set_linewidth(0.5)\n",
    "# #\n",
    "# # ax1.set_yticks(range(len(top_pct)))\n",
    "# # ax1.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "# #                       for _, row in top_pct.iterrows()], fontsize=9)\n",
    "# # ax1.set_xlabel('% of Land Cover Class that is Void', fontsize=11)\n",
    "# # ax1.set_title('Land Covers with Highest Void Percentage\\n(Worst Coverage Performance)',\n",
    "# #               fontweight='bold', fontsize=12)\n",
    "# # ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "# #\n",
    "# # # Add reference lines\n",
    "# # ax1.axvline(100, color='black', linestyle='-', linewidth=2, label='100% (Total Void)', zorder=3)\n",
    "# # for pct in [20, 40, 60, 80]:\n",
    "# #     ax1.axvline(pct, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, zorder=3)\n",
    "# #     ax1.text(pct, -0.5, f'{pct}%', ha='center', fontsize=9, color='gray')\n",
    "# #\n",
    "# # ax1.set_xlim(0, 105)\n",
    "# # # ax1.legend(loc='lower right')\n",
    "# #\n",
    "# # # Chart 2: Contribution to total voids\n",
    "# # top_contrib = void_lc_df.nlargest(15, 'Pct_of_Total_Voids')\n",
    "# # bars2 = ax2.barh(range(len(top_contrib)), top_contrib['Pct_of_Total_Voids'])\n",
    "# #\n",
    "# # for i, (_, row) in enumerate(top_contrib.iterrows()):\n",
    "# #     bars2[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "# #     bars2[i].set_edgecolor('black')\n",
    "# #     bars2[i].set_linewidth(0.5)\n",
    "# #\n",
    "# # ax2.set_yticks(range(len(top_contrib)))\n",
    "# # ax2.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "# #                       for _, row in top_contrib.iterrows()], fontsize=9)\n",
    "# # ax2.set_xlabel('% of Total Void Area', fontsize=11)\n",
    "# # ax2.set_title('Land Covers Contributing Most to Total Voids\\n(Largest Void Areas)',\n",
    "# #               fontweight='bold', fontsize=12)\n",
    "# # ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "# #\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig(RESULTS_DIR / 'voids_by_landcover_charts.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "# # plt.show()\n",
    "# #\n",
    "# # print(\"Saved: voids_by_landcover_charts.png\")\n",
    "# # print(\"\\nVoid analysis complete!\")"
   ],
   "id": "281aa27c1f3ef43f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDIVIDUAL LAND COVER MAPS WITH VOID VISUALIZATION"
   ],
   "id": "cee2fa921ad8f16e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # =============================================================================\n",
    "# # 1. PRE-CALCULATE ALL STATISTICS (DERIVED FROM \"SWISS CHEESE\" DATA)\n",
    "# # =============================================================================\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "#\n",
    "# print(\"Calculating statistics for all land cover classes...\")\n",
    "#\n",
    "# # Get unique classes present in the data\n",
    "# unique_classes = np.unique(corine_10m[corine_10m > 0])\n",
    "#\n",
    "# summary_data = []\n",
    "# for lc_code in sorted(unique_classes):\n",
    "#     # Create masks from the main \"swiss cheese\" arrays\n",
    "#     lc_mask = (corine_10m == lc_code)\n",
    "#     lc_total_pixels = np.sum(lc_mask)\n",
    "#\n",
    "#     if lc_total_pixels > 0:\n",
    "#         lc_void_pixels = np.sum(lc_mask & void_mask)\n",
    "#         lc_coverage_pixels = lc_total_pixels - lc_void_pixels\n",
    "#\n",
    "#         # Calculate statistics\n",
    "#         total_area_km2 = lc_total_pixels * (GRID_SIZE**2) / 1e6\n",
    "#         coverage_area_km2 = lc_coverage_pixels * (GRID_SIZE**2) / 1e6\n",
    "#         void_area_km2 = lc_void_pixels * (GRID_SIZE**2) / 1e6\n",
    "#\n",
    "#         pct_coverage = 100 * lc_coverage_pixels / lc_total_pixels\n",
    "#         pct_void = 100 * lc_void_pixels / lc_total_pixels\n",
    "#         pct_of_study_area = 100 * lc_total_pixels / np.sum(corine_10m > 0)\n",
    "#\n",
    "#         summary_data.append({\n",
    "#             'LC_Code': lc_code,\n",
    "#             'LC_Name': CORINE_CLASSES.get(lc_code, f'Class {lc_code}'),\n",
    "#             'Total_km2': total_area_km2,\n",
    "#             'Coverage_km2': coverage_area_km2,\n",
    "#             'Void_km2': void_area_km2,\n",
    "#             'Pct_Coverage': pct_coverage,\n",
    "#             'Pct_Void': pct_void,\n",
    "#             'Pct_of_Study_Area': pct_of_study_area\n",
    "#         })\n",
    "#\n",
    "# # Create the master DataFrame with all stats\n",
    "# stats_df = pd.DataFrame(summary_data)\n",
    "# stats_df = stats_df.sort_values(by='Pct_Void', ascending=False) # Sort by worst coverage\n",
    "#\n",
    "# print(\"✓ Statistics DataFrame created.\")\n",
    "# print(stats_df.to_string(index=False, float_format=\"%.2f\"))\n",
    "#\n",
    "# print(f\"\\nGenerating {len(stats_df)} land cover maps using pre-calculated stats...\")\n",
    "#\n",
    "# # Loop through the DataFrame, one row per land cover class\n",
    "# for index, row in stats_df.iterrows():\n",
    "#     lc_code = row['LC_Code']\n",
    "#     class_name = row['LC_Name']\n",
    "#\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(14, 10), facecolor='white')\n",
    "#     ax.set_facecolor('white')\n",
    "#\n",
    "#     # Display Sentinel RGB as background\n",
    "#     ax.imshow(sentinel_rgb_norm, extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid],\n",
    "#               origin='upper', alpha=0.4)\n",
    "#\n",
    "#     fill_color = tuple(c/255 for c in CORINE_COLORS.get(lc_code, (128, 128, 128)))\n",
    "#\n",
    "#     # --- Visualization (Masking and Vectorizing is still required here) ---\n",
    "#     lc_mask = (corine_10m == lc_code)\n",
    "#\n",
    "#     # 1. Draw COVERAGE areas (with data)\n",
    "#     lc_with_coverage = lc_mask & (~void_mask)\n",
    "#     if np.any(lc_with_coverage):\n",
    "#         coverage_shapes = shapes(lc_with_coverage.astype(np.uint8), mask=lc_with_coverage, transform=target_transform)\n",
    "#         for geom, val in coverage_shapes:\n",
    "#             if val == 1:\n",
    "#                 poly = shape(geom)\n",
    "#                 if poly.is_valid:\n",
    "#                     x, y = poly.exterior.xy\n",
    "#                     ax.fill(x, y, color=fill_color, alpha=0.35, edgecolor='none', hatch='///')\n",
    "#                     ax.plot(x, y, color='black', linewidth=2.0)\n",
    "#                     ax.plot(x, y, color=fill_color, linewidth=1.2)\n",
    "#\n",
    "#     # 2. Draw VOID areas (no data)\n",
    "#     lc_void = lc_mask & void_mask\n",
    "#     if np.any(lc_void):\n",
    "#         void_shapes = shapes(lc_void.astype(np.uint8), mask=lc_void, transform=target_transform)\n",
    "#         for geom, val in void_shapes:\n",
    "#             if val == 1:\n",
    "#                 poly = shape(geom)\n",
    "#                 if poly.is_valid:\n",
    "#                     x, y = poly.exterior.xy\n",
    "#                     ax.fill(x, y, color='white', alpha=0.8, edgecolor='none', hatch='....')\n",
    "#                     ax.plot(x, y, color='red', linewidth=1.5, linestyle='--')\n",
    "#                     ax.plot(x, y, color='gray', linewidth=0.8, linestyle='--')\n",
    "#\n",
    "#     hull_gdf.boundary.plot(ax=ax, color='black', linewidth=3, linestyle='-')\n",
    "#\n",
    "#     # --- Use Pre-Calculated Stats for Title and Text ---\n",
    "#     ax.set_title(\n",
    "#         f\"Land Cover: {class_name} (Code {lc_code})\\n\"\n",
    "#         f\"Total: {row['Total_km2']:.1f} km² ({row['Pct_of_Study_Area']:.1f}% of study area) | \"\n",
    "#         f\"Coverage: {row['Coverage_km2']:.1f} km² ({row['Pct_Coverage']:.1f}%) | \"\n",
    "#         f\"Void: {row['Void_km2']:.1f} km² ({row['Pct_Void']:.1f}%)\",\n",
    "#         fontweight='bold', fontsize=12, pad=15\n",
    "#     )\n",
    "#\n",
    "#     stats_text = (\n",
    "#         f\"Coverage: {row['Pct_Coverage']:.1f}%\\n\"\n",
    "#         f\"Void: {row['Pct_Void']:.1f}%\\n\"\n",
    "#         f\"Area w/ data: {row['Coverage_km2']:.1f} km²\\n\"\n",
    "#         f\"Area w/o data: {row['Void_km2']:.1f} km²\"\n",
    "#     )\n",
    "#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "#\n",
    "#     # --- Legend ---\n",
    "#     legend_elements = [\n",
    "#         Patch(facecolor=fill_color, edgecolor='black', linewidth=2, alpha=0.35, hatch='///', label=f'{class_name} (Coverage)'),\n",
    "#         Patch(facecolor='white', edgecolor='red', linewidth=1.5, alpha=0.8, hatch='....', linestyle='--', label=f'{class_name} (Void/No Data)'),\n",
    "#         Patch(facecolor='none', edgecolor='black', linewidth=3, label='Study Area Boundary')\n",
    "#     ]\n",
    "#     ax.legend(handles=legend_elements, loc='upper right', fontsize=10, frameon=True, fancybox=False, edgecolor='black', title='Legend')\n",
    "#\n",
    "#     ax.set_xlabel('UTM Easting (m)')\n",
    "#     ax.set_ylabel('UTM Northing (m)')\n",
    "#     ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "#     plt.tight_layout()\n",
    "#\n",
    "#     # --- Save File ---\n",
    "#     safe_name = class_name.replace(' ', '_').replace(',', '').replace('/', '_')\n",
    "#     filename = f'landcover_{lc_code}_{safe_name}_coverage_void.png'\n",
    "#     plt.savefig(RESULTS_DIR / filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "#\n",
    "#     print(f\"Saved: {filename}\")\n",
    "#\n",
    "# print(f\"\\n✓ Generated {len(stats_df)} land cover maps.\")\n",
    "# print(f\"All maps saved to: {RESULTS_DIR}\")"
   ],
   "id": "c804403b80d3dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land cover histograms"
   ],
   "id": "f1ce0a6ee257c362"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Re-define necessary variables and functions from your notebook\n",
    "# =============================================================================\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "NODATA = -9999\n",
    "CORINE_CLASSES = {\n",
    "    111: 'Continuous urban fabric', 112: 'Discontinuous urban fabric',\n",
    "    121: 'Industrial or commercial units', 122: 'Road and rail networks and associated land',\n",
    "    123: 'Port areas', 124: 'Airports', 131: 'Mineral extraction sites',\n",
    "    132: 'Dump sites', 133: 'Construction sites', 141: 'Green urban areas',\n",
    "    142: 'Sport and leisure facilities', 211: 'Non-irrigated arable land',\n",
    "    212: 'Permanently irrigated land', 213: 'Rice fields', 221: 'Vineyards',\n",
    "    222: 'Fruit trees and berry plantations', 223: 'Olive groves',\n",
    "    231: 'Pastures', 241: 'Annual crops associated with permanent crops',\n",
    "    242: 'Complex cultivation patterns', 243: 'Agriculture/natural vegetation mix',\n",
    "    244: 'Agro-forestry areas', 311: 'Broad-leaved forest',\n",
    "    312: 'Coniferous forest', 313: 'Mixed forest', 321: 'Natural grasslands',\n",
    "    322: 'Moors and heathland', 323: 'Sclerophyllous vegetation',\n",
    "    324: 'Transitional woodland-shrub', 331: 'Beaches, dunes, sands',\n",
    "    332: 'Bare rocks', 333: 'Sparsely vegetated areas', 334: 'Burnt areas',\n",
    "    335: 'Glaciers and perpetual snow', 411: 'Inland marshes',\n",
    "    412: 'Peat bogs', 421: 'Salt marshes', 422: 'Salines',\n",
    "    423: 'Intertidal flats', 511: 'Water courses', 512: 'Water bodies',\n",
    "    521: 'Coastal lagoons', 522: 'Estuaries', 523: 'Sea and ocean'\n",
    "}\n",
    "\n",
    "# Assuming 'corine_10m_masked.tif' is in the RESULTS_DIR from previous cells\n",
    "corine_masked_path = RESULTS_DIR / \"corine_10m_masked.tif\"\n",
    "with rasterio.open(corine_masked_path) as src:\n",
    "    corine_10m = src.read(1)\n",
    "    target_transform = src.transform\n",
    "    grid_height, grid_width = src.height, src.width\n",
    "\n",
    "# Helper function from your notebook\n",
    "def plot_distribution(ax, diff_series, title, metrics):\n",
    "    \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    ax.hist(diff_series, bins=20, alpha=0.75, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "    ax.axvline(metrics['mean_diff'], color='green', linestyle='-', label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "\n",
    "    stats_text = (f\"n = {metrics['n_points']:,}\\n\"\n",
    "                  f\"RMSE = {metrics['rmse']:.2f} m\\n\"\n",
    "                  f\"NMAD = {metrics['nmad']:.2f} m\\n\"\n",
    "                  f\"Std Dev = {metrics['std_diff']:.2f} m\")\n",
    "\n",
    "    ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Elevation Difference (m)', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Sample CORINE Land Cover at SAOCOM point locations\n",
    "# =============================================================================\n",
    "landcover_values = []\n",
    "for idx, row in saocom_gdf.iterrows():\n",
    "    row_idx, col_idx = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "    if 0 <= row_idx < grid_height and 0 <= col_idx < grid_width:\n",
    "        lc_val = corine_10m[row_idx, col_idx]\n",
    "        landcover_values.append(lc_val if lc_val != 0 else np.nan)\n",
    "    else:\n",
    "        landcover_values.append(np.nan)\n",
    "\n",
    "saocom_gdf['landcover'] = landcover_values\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Create points dataframes with landcover information\n",
    "# =============================================================================\n",
    "\n",
    "# SAOCOM - TINITALY\n",
    "points_tin = saocom_gdf[['HEIGHT_ABSOLUTE_TIN', 'tinitaly_height', 'landcover']].copy()\n",
    "points_tin.dropna(inplace=True)\n",
    "points_tin['diff'] = points_tin['HEIGHT_ABSOLUTE_TIN'] - points_tin['tinitaly_height']\n",
    "\n",
    "# SAOCOM - Copernicus\n",
    "points_cop = saocom_gdf[['HEIGHT_ABSOLUTE_COP', 'copernicus_height', 'landcover']].copy()\n",
    "points_cop.dropna(inplace=True)\n",
    "points_cop['diff'] = points_cop['HEIGHT_ABSOLUTE_COP'] - points_cop['copernicus_height']\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Group by landcover and calculate metrics\n",
    "# =============================================================================\n",
    "\n",
    "landcover_groups_tin = points_tin.groupby('landcover')\n",
    "landcover_groups_cop = points_cop.groupby('landcover')\n",
    "\n",
    "metrics_by_landcover = {}\n",
    "\n",
    "unique_landcovers = sorted(points_tin['landcover'].unique())\n",
    "\n",
    "for lc_code in unique_landcovers:\n",
    "    if np.isnan(lc_code):\n",
    "        continue\n",
    "    lc_name = CORINE_CLASSES.get(lc_code, f'Unknown ({lc_code})')\n",
    "    metrics_by_landcover[lc_name] = {}\n",
    "\n",
    "    # TINITALY metrics\n",
    "    if lc_code in landcover_groups_tin.groups:\n",
    "        group_tin = landcover_groups_tin.get_group(lc_code)\n",
    "        diff_tin = group_tin['diff']\n",
    "        metrics_by_landcover[lc_name]['tin'] = {\n",
    "            'n_points': len(diff_tin),\n",
    "            'rmse': np.sqrt(np.mean(diff_tin**2)),\n",
    "            'nmad': stats.median_abs_deviation(diff_tin, scale='normal'),\n",
    "            'mean_diff': np.mean(diff_tin),\n",
    "            'std_diff': np.std(diff_tin),\n",
    "            'diff_series': diff_tin\n",
    "        }\n",
    "\n",
    "    # Copernicus metrics\n",
    "    if lc_code in landcover_groups_cop.groups:\n",
    "        group_cop = landcover_groups_cop.get_group(lc_code)\n",
    "        diff_cop = group_cop['diff']\n",
    "        metrics_by_landcover[lc_name]['cop'] = {\n",
    "            'n_points': len(diff_cop),\n",
    "            'rmse': np.sqrt(np.mean(diff_cop**2)),\n",
    "            'nmad': stats.median_abs_deviation(diff_cop, scale='normal'),\n",
    "            'mean_diff': np.mean(diff_cop),\n",
    "            'std_diff': np.std(diff_cop),\n",
    "            'diff_series': diff_cop\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Generate and save histograms for each landcover\n",
    "# =============================================================================\n",
    "\n",
    "for lc_name, metrics in metrics_by_landcover.items():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "    fig.suptitle(f'Residual Distributions for Landcover: {lc_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    if 'tin' in metrics:\n",
    "        plot_distribution(axes[0], metrics['tin']['diff_series'], 'SAOCOM - TINITALY', metrics['tin'])\n",
    "    else:\n",
    "        axes[0].set_title('SAOCOM - TINITALY\\n(No Data)', fontweight='bold', fontsize=14)\n",
    "        axes[0].set_facecolor('lightgray')\n",
    "\n",
    "\n",
    "    if 'cop' in metrics:\n",
    "        plot_distribution(axes[1], metrics['cop']['diff_series'], 'SAOCOM - Copernicus', metrics['cop'])\n",
    "    else:\n",
    "        axes[1].set_title('SAOCOM - Copernicus\\n(No Data)', fontweight='bold', fontsize=14)\n",
    "        axes[1].set_facecolor('lightgray')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Sanitize filename\n",
    "    safe_lc_name = lc_name.replace('/', '_').replace(' ', '_').lower()\n",
    "    plt.savefig(RESULTS_DIR / f'saocom_residuals_{safe_lc_name}.png', dpi=300, facecolor='white')\n",
    "    plt.show()"
   ],
   "id": "9aac1325a781372d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Note: Assumes these variables exist from previous cells:\n",
    "# saocom_gdf, COHERENCE_THRESHOLD, hull_gdf, RESULTS_DIR, CORINE_CLASSES, CORINE_COLORS\n",
    "# sentinel_rgb_norm, xmin_grid, xmax_grid, ymin_grid, ymax_grid, corine_10m, target_transform\n",
    "\n",
    "# =============================================================================\n",
    "# Data Preparation\n",
    "# =============================================================================\n",
    "print(\"Filtering SAOCOM differences by land cover...\")\n",
    "\n",
    "# Filter for valid TINITALY comparisons\n",
    "query_str = f\"`HEIGHT_ABSOLUTE_TIN`.notna() & `tinitaly_height`.notna() & COHER >= @COHERENCE_THRESHOLD & `corine_code` > 0\"\n",
    "points_lc = saocom_gdf.query(query_str).copy()\n",
    "points_lc['diff'] = points_lc['HEIGHT_ABSOLUTE_TIN'] - points_lc['tinitaly_height']\n",
    "\n",
    "# Get unique land cover classes with sufficient data\n",
    "MIN_POINTS = 100\n",
    "lc_counts = points_lc['corine_code'].value_counts()\n",
    "valid_lcs = lc_counts[lc_counts >= MIN_POINTS].index.sort_values()\n",
    "\n",
    "print(f\"Found {len(valid_lcs)} land cover classes with >= {MIN_POINTS} points\")\n",
    "\n",
    "# Calculate global scale limits (98th percentile for consistency)\n",
    "v_global = np.nanpercentile(np.abs(points_lc['diff']), 98)\n",
    "\n",
    "# =============================================================================\n",
    "# Generate Maps for Each Land Cover\n",
    "# =============================================================================\n",
    "for lc_code in valid_lcs:\n",
    "    # Filter data for this land cover\n",
    "    lc_data = points_lc[points_lc['corine_code'] == lc_code].copy()\n",
    "    lc_name = CORINE_CLASSES.get(lc_code, f'Class {lc_code}')\n",
    "\n",
    "    # Calculate stats\n",
    "    n_points = len(lc_data)\n",
    "    mean_diff = lc_data['diff'].mean()\n",
    "    rmse = np.sqrt(np.mean(lc_data['diff']**2))\n",
    "    stats_text = f\"n = {n_points:,}\\nMean = {mean_diff:+.2f} m\\nRMSE = {rmse:.2f} m\"\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Display Sentinel RGB as background\n",
    "    ax.imshow(sentinel_rgb_norm, extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid],\n",
    "              origin='upper', alpha=0.5)\n",
    "\n",
    "    # Add land cover boundaries with solid fill\n",
    "    fill_color = tuple(c/255 for c in CORINE_COLORS.get(lc_code, (128, 128, 128)))\n",
    "    lc_mask = (corine_10m == lc_code)\n",
    "    mask_shapes = shapes(lc_mask.astype(np.uint8), mask=lc_mask, transform=target_transform)\n",
    "\n",
    "    for geom, val in mask_shapes:\n",
    "        if val == 1:\n",
    "            poly = shape(geom)\n",
    "            if poly.is_valid:\n",
    "                x, y = poly.exterior.xy\n",
    "                ax.fill(x, y, color='white', alpha=1, edgecolor='none')\n",
    "                ax.plot(x, y, color='black', linewidth=1.5, alpha=1)\n",
    "                ax.plot(x, y, color=fill_color, linewidth=0.5, alpha=1)\n",
    "\n",
    "    # Plot residual points\n",
    "    im = ax.scatter(lc_data.geometry.x, lc_data.geometry.y,\n",
    "                    c=lc_data['diff'], s=1, alpha=1,\n",
    "                    cmap='RdYlBu_r', vmin=-v_global, vmax=v_global)\n",
    "\n",
    "    # Add study area boundary\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_title(f'SAOCOM - TINITALY Residuals\\nLand Cover: {lc_name} (Code {lc_code})',\n",
    "                 fontweight='bold', fontsize=14, pad=15)\n",
    "    ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "    ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, label='Residual (m)', shrink=0.8)\n",
    "\n",
    "    # Stats box\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n",
    "            fontsize=10, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "    # Save and display\n",
    "    plt.tight_layout()\n",
    "    filename = f'residuals_lc_{lc_code:03d}_{lc_name.replace(\" \", \"_\").replace(\"/\", \"-\")}.png'\n",
    "    plt.savefig(RESULTS_DIR / filename, dpi=300, facecolor='white', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(valid_lcs)} residual maps by land cover\")"
   ],
   "id": "979e7221409ec71e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topo Maps"
   ],
   "id": "b03e18773b89d7da"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# TOPOGRAPHIC FACTORS ANALYSIS: SLOPE, ASPECT & ELEVATION (TINITALY vs COPERNICUS)\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, stats\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Calculating topographic derivatives from reference DEMs...\")\n",
    "\n",
    "# Calculate slope and aspect from TINITALY DEM (already loaded as tinitaly_10m)\n",
    "def calculate_terrain_derivatives(dem, cellsize=10):\n",
    "    \"\"\"Calculate slope and aspect from DEM using Horn's method\"\"\"\n",
    "    dem_clean = np.where(dem == NODATA, np.nan, dem)\n",
    "    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) / 8.0\n",
    "    kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]) / 8.0\n",
    "    dz_dx = ndimage.convolve(dem_clean, kernel_x) / cellsize\n",
    "    dz_dy = ndimage.convolve(dem_clean, kernel_y) / cellsize\n",
    "    slope = np.degrees(np.arctan(np.sqrt(dz_dx**2 + dz_dy**2)))\n",
    "    aspect = np.degrees(np.arctan2(-dz_dx, dz_dy))\n",
    "    aspect = np.where(aspect < 0, aspect + 360, aspect)\n",
    "    return slope, aspect\n",
    "\n",
    "# Calculate terrain derivatives\n",
    "slope_tin, aspect_tin = calculate_terrain_derivatives(tinitaly_10m, cellsize=10)\n",
    "slope_cop, aspect_cop = calculate_terrain_derivatives(copernicus_10m, cellsize=10)\n",
    "\n",
    "# Sample terrain derivatives at SAOCOM points\n",
    "xs, ys = saocom_gdf.geometry.x.values, saocom_gdf.geometry.y.values\n",
    "rows, cols = rowcol(target_transform, xs, ys)\n",
    "inb = (rows>=0) & (rows<grid_height) & (cols>=0) & (cols<grid_width)\n",
    "\n",
    "def sample_at_points(arr):\n",
    "    out = np.full(len(saocom_gdf), np.nan, dtype=np.float32)\n",
    "    out[inb] = arr[rows[inb], cols[inb]]\n",
    "    return out\n",
    "\n",
    "# Sample for both DEMs\n",
    "saocom_gdf['slope_tin'] = sample_at_points(slope_tin)\n",
    "saocom_gdf['aspect_tin'] = sample_at_points(aspect_tin)\n",
    "saocom_gdf['slope_cop'] = sample_at_points(slope_cop)\n",
    "saocom_gdf['aspect_cop'] = sample_at_points(aspect_cop)\n",
    "\n",
    "# Prepare analysis dataframes for both DEMs\n",
    "def prepare_analysis_df(dem_name):\n",
    "    if dem_name == 'TINITALY':\n",
    "        df = saocom_gdf[\n",
    "            (saocom_gdf['slope_tin'].notna()) &\n",
    "            (saocom_gdf['aspect_tin'].notna()) &\n",
    "            (saocom_gdf['diff_tinitaly'].notna()) &\n",
    "            (np.abs(saocom_gdf['diff_tinitaly']) < 50)\n",
    "        ].copy()\n",
    "        df['slope'] = df['slope_tin']\n",
    "        df['aspect'] = df['aspect_tin']\n",
    "        df['elevation'] = df['tinitaly_height']\n",
    "        df['residual'] = df['diff_tinitaly']\n",
    "    else:  # Copernicus\n",
    "        df = saocom_gdf[\n",
    "            (saocom_gdf['slope_cop'].notna()) &\n",
    "            (saocom_gdf['aspect_cop'].notna()) &\n",
    "            (saocom_gdf['diff_copernicus'].notna()) &\n",
    "            (np.abs(saocom_gdf['diff_copernicus']) < 50)\n",
    "        ].copy()\n",
    "        df['slope'] = df['slope_cop']\n",
    "        df['aspect'] = df['aspect_cop']\n",
    "        df['elevation'] = df['copernicus_height']\n",
    "        df['residual'] = df['diff_copernicus']\n",
    "\n",
    "    df['abs_residual'] = np.abs(df['residual'])\n",
    "    return df\n",
    "\n",
    "analysis_tin = prepare_analysis_df('TINITALY')\n",
    "analysis_cop = prepare_analysis_df('Copernicus')\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 1: SLOPE VS RESIDUAL ANALYSIS\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), facecolor='white')\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    slope_bins = np.arange(0, 61, 5)\n",
    "    slope_groups = pd.cut(analysis_df['slope'], slope_bins)\n",
    "    slope_stats = analysis_df.groupby(slope_groups).agg({\n",
    "        'abs_residual': ['mean', 'std', 'count'],\n",
    "        'COHER': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    x_pos = np.arange(len(slope_bins)-1)\n",
    "    means = [slope_stats['abs_residual']['mean'].iloc[i] if i < len(slope_stats) else np.nan\n",
    "             for i in range(len(x_pos))]\n",
    "    stds = [slope_stats['abs_residual']['std'].iloc[i] if i < len(slope_stats) else 0\n",
    "            for i in range(len(x_pos))]\n",
    "    counts = [slope_stats['abs_residual']['count'].iloc[i] if i < len(slope_stats) else 0\n",
    "              for i in range(len(x_pos))]\n",
    "\n",
    "    bars = ax.bar(x_pos, means, yerr=stds, capsize=4,\n",
    "                   color='#388E3C', edgecolor='black', linewidth=0.8,\n",
    "                   error_kw={'linewidth': 1, 'ecolor': 'black'})\n",
    "\n",
    "    # Add n counts on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "        # if count > 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + stds[i] + 0.5,\n",
    "               f'n={int(count)}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    ax.set_xlabel('Slope Range (degrees)', fontsize=11)\n",
    "    ax.set_ylabel('Mean Absolute Residual (m)', fontsize=11)\n",
    "    ax.set_title(f'InSAR Residual vs. Terrain Slope — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([f'{b}-{b+5}°' for b in slope_bins[:-1]], rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add trend line\n",
    "    valid_means = [m for m in means if not np.isnan(m)]\n",
    "    if len(valid_means) > 1:\n",
    "        z = np.polyfit(slope_bins[:len(valid_means)] + 2.5, valid_means, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(x_pos[:len(valid_means)], p(slope_bins[:len(valid_means)] + 2.5),\n",
    "                 'r--', alpha=0.7, linewidth=2,\n",
    "                 label=f'Trend: +{z[0]:.3f} m/degree')\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 2: ASPECT POLAR PLOT\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7), facecolor='white',\n",
    "                                subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    aspect_bins = np.arange(0, 361, 30)\n",
    "    aspect_groups = pd.cut(analysis_df['aspect'], aspect_bins)\n",
    "    aspect_stats = analysis_df.groupby(aspect_groups).agg({\n",
    "        'abs_residual': ['mean', 'count']\n",
    "    }).reset_index()\n",
    "\n",
    "    theta = np.radians(aspect_bins[:-1] + 15)\n",
    "    radii = [aspect_stats['abs_residual']['mean'].iloc[i] if i < len(aspect_stats) else 3\n",
    "             for i in range(len(theta))]\n",
    "    width = np.radians(30)\n",
    "\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.7, len(theta)))\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=0, color=colors,\n",
    "                   edgecolor='black', linewidth=0.8, alpha=0.8)\n",
    "\n",
    "    ax.set_theta_zero_location('N')\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_title(f'Residual by Aspect Direction — {dem_name}', fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_rlabel_position(45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_thetagrids([0, 90, 180, 270], ['N', 'E', 'S', 'W'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 3: ELEVATION VS PERFORMANCE\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), facecolor='white')\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    elev_bins = np.arange(0, 1001, 100)\n",
    "    elev_groups = pd.cut(analysis_df['elevation'], elev_bins)\n",
    "    elev_stats = analysis_df.groupby(elev_groups).agg({\n",
    "        'abs_residual': ['mean', 'std', 'count'],\n",
    "        'COHER': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    ax_twin = ax.twinx()\n",
    "    x_elev = np.arange(len(elev_bins)-1)\n",
    "    elev_error = [elev_stats['abs_residual']['mean'].iloc[i] if i < len(elev_stats) else np.nan\n",
    "                  for i in range(len(x_elev))]\n",
    "    elev_coh = [elev_stats['COHER']['mean'].iloc[i] if i < len(elev_stats) else np.nan\n",
    "                for i in range(len(x_elev))]\n",
    "    counts = [elev_stats['abs_residual']['count'].iloc[i] if i < len(elev_stats) else 0\n",
    "              for i in range(len(x_elev))]\n",
    "\n",
    "    line1 = ax.plot(x_elev, elev_error, 'o-', color='#1565C0', linewidth=2,\n",
    "                     markersize=6, label='Abs Residual')\n",
    "    line2 = ax_twin.plot(x_elev, elev_coh, 's-', color='#E65100', linewidth=2,\n",
    "                          markersize=5, label='Coherence')\n",
    "\n",
    "    # Add n counts\n",
    "    for i, (x, y, n) in enumerate(zip(x_elev, elev_error, counts)):\n",
    "        if not np.isnan(y) and n > 0:\n",
    "            ax.text(x, y + 0.3, f'n={int(n)}', ha='center', fontsize=12)\n",
    "\n",
    "    ax.set_xlabel('Elevation Range (m)', fontsize=11)\n",
    "    ax.set_ylabel('Mean Absolute Residual (m)', fontsize=11, color='#1565C0')\n",
    "    ax_twin.set_ylabel('Mean Coherence', fontsize=11, color='#E65100')\n",
    "    ax.set_title(f'Performance Across Elevation — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x_elev)\n",
    "    ax.set_xticklabels([f'{b}-{b+100}' for b in elev_bins[:-1]], rotation=45, ha='right')\n",
    "    ax.tick_params(axis='y', colors='#1565C0')\n",
    "    ax_twin.tick_params(axis='y', colors='#E65100')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 4: SLOPE-COHERENCE HEXBIN\n",
    "# =============================================================================\n",
    "# ROW 4: SLOPE-COHERENCE HEXBIN (discrete colors, white for empty)\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), facecolor='white')\n",
    "\n",
    "# Define discrete color bins\n",
    "count_bins = [0, 100, 500, 1000, 2000, 3000, 4000]\n",
    "colors = ['#FFFFCC', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#E31A1C']\n",
    "cmap_discrete = mcolors.ListedColormap(colors)\n",
    "norm = mcolors.BoundaryNorm(count_bins, cmap_discrete.N)\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    hexbin = ax.hexbin(analysis_df['slope'], analysis_df['COHER'],\n",
    "                         gridsize=25, cmap=cmap_discrete, norm=norm,\n",
    "                         edgecolors='black', linewidth=0.2,\n",
    "                         mincnt=1)  # Only draw hexes with at least 1 point\n",
    "    ax.set_xlabel('Slope (degrees)', fontsize=11)\n",
    "    ax.set_ylabel('Coherence', fontsize=11)\n",
    "    ax.set_title(f'Coherence vs. Slope Density — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Discrete colorbar\n",
    "    cbar = plt.colorbar(hexbin, ax=ax, label='Point Count', boundaries=count_bins, ticks=count_bins)\n",
    "    cbar.set_label('Point Count', fontsize=10)\n",
    "\n",
    "    # Add regression line\n",
    "    mask = ~np.isnan(analysis_df['slope']) & ~np.isnan(analysis_df['COHER'])\n",
    "    if mask.sum() > 10:\n",
    "        z = np.polyfit(analysis_df.loc[mask, 'slope'], analysis_df.loc[mask, 'COHER'], 2)\n",
    "        p = np.poly1d(z)\n",
    "        x_fit = np.linspace(0, analysis_df['slope'].max(), 100)\n",
    "        r2 = np.corrcoef(analysis_df.loc[mask, 'slope'], analysis_df.loc[mask, 'COHER'])[0,1]**2\n",
    "        ax.plot(x_fit, p(x_fit), 'b--', linewidth=2, alpha=0.7,\n",
    "                 label=f'R² = {r2:.3f}, n={mask.sum()}')\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 5: COMBINED TERRAIN DIFFICULTY\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), facecolor='white')\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    analysis_df['terrain_difficulty'] = (\n",
    "        analysis_df['slope'] / 30\n",
    "        )\n",
    "    difficulty_bins = [0, 0.3, 0.5, 0.7, 1.5]\n",
    "    difficulty_labels = ['Low', 'Moderate', 'High', 'Extreme']\n",
    "    analysis_df['difficulty_cat'] = pd.cut(analysis_df['terrain_difficulty'],\n",
    "                                            bins=difficulty_bins, labels=difficulty_labels)\n",
    "\n",
    "    terrain_stats = analysis_df.groupby('difficulty_cat').agg({\n",
    "        'abs_residual': ['mean', 'std', 'count'],\n",
    "        'COHER': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    categories = terrain_stats['difficulty_cat']\n",
    "    error_means = terrain_stats['abs_residual']['mean']\n",
    "    error_stds = terrain_stats['abs_residual']['std']\n",
    "\n",
    "    colors_terrain = ['#4CAF50', '#FFC107', '#FF9800', '#F44336']\n",
    "    bars = ax.bar(categories, error_means, yerr=error_stds, capsize=5,\n",
    "                   color=colors_terrain, edgecolor='black', linewidth=1,\n",
    "                   error_kw={'linewidth': 1, 'ecolor': 'black'})\n",
    "\n",
    "    ax.set_xlabel('Terrain Difficulty', fontsize=11)\n",
    "    ax.set_ylabel('Mean Absolute Residual (m)', fontsize=11)\n",
    "    ax.set_title(f'Combined Topographic Impact — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "\n",
    "    # Add sample counts\n",
    "    for i, (bar, count) in enumerate(zip(bars, terrain_stats['abs_residual']['count'])):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + error_stds[i] + 0.1,\n",
    "                 f'n={int(count):,}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 6: RESIDUAL DISTRIBUTION BY SLOPE CLASS\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), facecolor='white')\n",
    "\n",
    "slope_classes = ['Flat\\n(0-5°)', 'Gentle\\n(5-15°)', 'Moderate\\n(15-30°)', 'Steep\\n(>30°)']\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    slope_data = []\n",
    "    counts = []\n",
    "    for low, high in [(0, 5), (5, 15), (15, 30), (30, 90)]:\n",
    "        mask = (analysis_df['slope'] >= low) & (analysis_df['slope'] < high)\n",
    "        slope_data.append(analysis_df.loc[mask, 'abs_residual'].values)\n",
    "        counts.append(mask.sum())\n",
    "\n",
    "    bp = ax.boxplot(slope_data, labels=slope_classes, patch_artist=True,\n",
    "                     medianprops=dict(color='red', linewidth=2),\n",
    "                     boxprops=dict(facecolor='#81C784', edgecolor='black'),\n",
    "                     whiskerprops=dict(color='black'),\n",
    "                     capprops=dict(color='black'))\n",
    "\n",
    "    # Add n counts\n",
    "    for i, (pos, n) in enumerate(zip(range(1, len(slope_classes)+1), counts)):\n",
    "        ax.text(pos, ax.get_ylim()[1] * 0.95, f'n={n:,}',\n",
    "                ha='center', va='top', fontsize=12, bbox=dict(boxstyle='round',\n",
    "                facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_ylabel('Absolute Residual (m)', fontsize=11)\n",
    "    ax.set_title(f'Residual Distribution by Slope Class — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 7: ASPECT/SLOPE PERFORMANCE MATRIX\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    aspect_bins_matrix = np.arange(0, 361, 45)\n",
    "    slope_bins_matrix = np.arange(0, 41, 10)\n",
    "    performance_matrix = np.zeros((len(slope_bins_matrix)-1, len(aspect_bins_matrix)-1))\n",
    "\n",
    "    for i, (s_low, s_high) in enumerate(zip(slope_bins_matrix[:-1], slope_bins_matrix[1:])):\n",
    "        for j, (a_low, a_high) in enumerate(zip(aspect_bins_matrix[:-1], aspect_bins_matrix[1:])):\n",
    "            mask = (analysis_df['slope'] >= s_low) & (analysis_df['slope'] < s_high) & \\\n",
    "                   (analysis_df['aspect'] >= a_low) & (analysis_df['aspect'] < a_high)\n",
    "            if mask.sum() > 5:\n",
    "                performance_matrix[i, j] = analysis_df.loc[mask, 'COHER'].mean()\n",
    "\n",
    "    im = ax.imshow(performance_matrix, cmap='RdYlGn', aspect='auto',\n",
    "                    vmin=0.4, vmax=0.9, origin='lower')\n",
    "    ax.set_xticks(np.arange(len(aspect_bins_matrix)-1))\n",
    "    ax.set_yticks(np.arange(len(slope_bins_matrix)-1))\n",
    "    ax.set_xticklabels(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'])\n",
    "    ax.set_yticklabels([f'{s}-{s+10}°' for s in slope_bins_matrix[:-1]])\n",
    "    ax.set_xlabel('Aspect Direction', fontsize=11)\n",
    "    ax.set_ylabel('Slope Range', fontsize=11)\n",
    "    ax.set_title(f'Mean Coherence Matrix (Slope × Aspect) — {dem_name}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.colorbar(im, ax=ax, label='Mean Coherence', shrink=0.8)\n",
    "\n",
    "    # Add text annotations\n",
    "    for i in range(len(slope_bins_matrix)-1):\n",
    "        for j in range(len(aspect_bins_matrix)-1):\n",
    "            if performance_matrix[i, j] > 0:\n",
    "                text = ax.text(j, i, f'{performance_matrix[i, j]:.2f}',\n",
    "                               ha='center', va='center',\n",
    "                               color='black' if performance_matrix[i, j] > 0.65 else 'white',\n",
    "                               fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# ROW 8: SUMMARY STATISTICS (larger font, calculated findings)\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 10), facecolor='white')\n",
    "\n",
    "for ax, analysis_df, dem_name in [(ax1, analysis_tin, 'TINITALY'), (ax2, analysis_cop, 'Copernicus')]:\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    slope_corr = np.corrcoef(analysis_df['slope'], analysis_df['abs_residual'])[0, 1]\n",
    "\n",
    "    # Calculate aspect effects by quadrant\n",
    "    aspect_quadrants = {\n",
    "        'North (315-45°)': analysis_df[(analysis_df['aspect'] >= 315) | (analysis_df['aspect'] < 45)]['abs_residual'].mean(),\n",
    "        'East (45-135°)': analysis_df[(analysis_df['aspect'] >= 45) & (analysis_df['aspect'] < 135)]['abs_residual'].mean(),\n",
    "        'South (135-225°)': analysis_df[(analysis_df['aspect'] >= 135) & (analysis_df['aspect'] < 225)]['abs_residual'].mean(),\n",
    "        'West (225-315°)': analysis_df[(analysis_df['aspect'] >= 225) & (analysis_df['aspect'] < 315)]['abs_residual'].mean()\n",
    "    }\n",
    "\n",
    "    best_aspect = min(aspect_quadrants, key=aspect_quadrants.get)\n",
    "    worst_aspect = max(aspect_quadrants, key=aspect_quadrants.get)\n",
    "    aspect_diff = aspect_quadrants[worst_aspect] - aspect_quadrants[best_aspect]\n",
    "\n",
    "    # Calculate elevation correlation\n",
    "    elev_corr = np.corrcoef(analysis_df['elevation'], analysis_df['abs_residual'])[0, 1]\n",
    "    elev_trend = np.polyfit(analysis_df['elevation'], analysis_df['abs_residual'], 1)[0]\n",
    "\n",
    "    # Classify correlation strength\n",
    "    if abs(elev_corr) < 0.3:\n",
    "        elev_strength = \"Weak\"\n",
    "    elif abs(elev_corr) < 0.5:\n",
    "        elev_strength = \"Moderate\"\n",
    "    elif abs(elev_corr) < 0.7:\n",
    "        elev_strength = \"Strong\"\n",
    "    else:\n",
    "        elev_strength = \"Very Strong\"\n",
    "\n",
    "    # Coverage by slope\n",
    "    coverage_stats = []\n",
    "    for low, high in [(0, 15), (15, 30), (30, 90)]:\n",
    "        mask = (analysis_df['slope'] >= low) & (analysis_df['slope'] < high)\n",
    "        coh_high = (analysis_df.loc[mask, 'COHER'] >= 0.5).mean() * 100\n",
    "        coverage_stats.append((f\"{low}-{high}°\", coh_high))\n",
    "\n",
    "    summary_text = f\"\"\"TOPOGRAPHIC IMPACT ANALYSIS — {dem_name}\n",
    "{'='*42}\n",
    "\n",
    "Slope Effects:\n",
    "- Correlation with residual: r = {slope_corr:.3f}\n",
    "- Residual increase: +{np.polyfit(analysis_df['slope'], analysis_df['abs_residual'], 1)[0]:.3f} m/degree\n",
    "- Critical threshold: >30°\n",
    "\n",
    "Aspect Influence:\n",
    "- Best: {best_aspect}: {aspect_quadrants[best_aspect]:.2f} m\n",
    "- Worst: {worst_aspect}: {aspect_quadrants[worst_aspect]:.2f} m\n",
    "- Max difference: {aspect_diff:.2f} m\n",
    "\n",
    "Elevation Correlation:\n",
    "- Correlation: r = {elev_corr:.3f} ({elev_strength})\n",
    "- Trend: {elev_trend*100:.2f} m per 100m\n",
    "\n",
    "Data Coverage (γ ≥ 0.5):\"\"\"\n",
    "\n",
    "    for slope_range, coverage in coverage_stats:\n",
    "        summary_text += f\"\\n• Slope {slope_range}: {coverage:.1f}%\"\n",
    "\n",
    "    summary_text += f\"\"\"\n",
    "\n",
    "Points Analyzed: {len(analysis_df):,}\n",
    "Mean Slope: {analysis_df['slope'].mean():.1f}°\n",
    "Mean Coherence: {analysis_df['COHER'].mean():.3f}\n",
    "Mean Abs Residual: {analysis_df['abs_residual'].mean():.2f} m\n",
    "RMSE: {np.sqrt((analysis_df['residual']**2).mean()):.2f} m\n",
    "\"\"\"\n",
    "\n",
    "    ax.text(0.5, 0.5, summary_text, transform=ax.transAxes,\n",
    "             fontsize=12, verticalalignment='center', horizontalalignment='center',\n",
    "             fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='#F5F5F5', edgecolor='black',\n",
    "                      pad=5, linewidth=1.5))\n",
    "\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARATIVE STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTINITALY:\")\n",
    "print(f\"  Total Points: {len(analysis_tin):,}\")\n",
    "print(f\"  Mean Abs Residual: {analysis_tin['abs_residual'].mean():.2f} m\")\n",
    "print(f\"  RMSE: {np.sqrt((analysis_tin['residual']**2).mean()):.2f} m\")\n",
    "print(f\"  Mean Coherence: {analysis_tin['COHER'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nCopernicus:\")\n",
    "print(f\"  Total Points: {len(analysis_cop):,}\")\n",
    "print(f\"  Mean Abs Residual: {analysis_cop['abs_residual'].mean():.2f} m\")\n",
    "print(f\"  RMSE: {np.sqrt((analysis_cop['residual']**2).mean()):.2f} m\")\n",
    "print(f\"  Mean Coherence: {analysis_cop['COHER'].mean():.3f}\")"
   ],
   "id": "26f714133dc5d776",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# TOPOGRAPHIC INTERPRETATION & SPATIAL SUITABILITY MAPPING  (ONE-CELL, PER-DEM + SAOCOM)\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INTERPRETING TOPOGRAPHIC IMPACTS ON INSAR PERFORMANCE (DEM-specific)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Quick context recap\n",
    "print(\"\"\"\n",
    "• SLOPE: flat (0–5°) best; >30° risky (layover/foreshortening)\n",
    "• ASPECT: South-facing (~180°) generally more reliable than north-facing\n",
    "• ELEVATION: weak correlation; high-relief often lower coherence\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXPECTED UPSTREAM VARS:\n",
    "# target_transform, grid_height, grid_width, xmin_grid, xmax_grid, ymin_grid, ymax_grid\n",
    "# TARGET_CRS, RESULTS_DIR, hull_gdf, saocom_gdf (with x_utm, y_utm, COHER, and possibly diff_* / HEIGHT_* / *_height)\n",
    "# DEM arrays (any that exist):\n",
    "#   TINITALY:   slope_tin, aspect_tin, tinitaly_10m\n",
    "#   COPERNICUS: slope_copernicus|slope_cop, aspect_copernicus|aspect_cop, copernicus_10m\n",
    "# =============================================================================\n",
    "\n",
    "COHER_MIN = 0.0  # set to e.g. 0.4 if you want to filter low-coherence points\n",
    "\n",
    "def calculate_suitability_index(slope, aspect, elevation):\n",
    "    slope_score = np.where(slope <= 5, 1.0,\n",
    "                   np.where(slope <= 15, 0.8,\n",
    "                   np.where(slope <= 30, 0.5, 0.2)))\n",
    "    aspect_rad = np.radians(aspect)\n",
    "    aspect_score = 0.7 + 0.3 * np.cos(aspect_rad - np.radians(180))  # favor S-facing\n",
    "    elev_norm = np.clip((elevation - 100) / 900, 0, 1)\n",
    "    elev_score = 1.0 - 0.3 * elev_norm\n",
    "    return 0.6 * slope_score + 0.3 * aspect_score + 0.1 * elev_score\n",
    "\n",
    "def classify_terrain_suitability(suitability):\n",
    "    return np.where(suitability >= 0.8, 4,\n",
    "           np.where(suitability >= 0.65, 3,\n",
    "           np.where(suitability >= 0.5, 2,\n",
    "           np.where(suitability >= 0.35, 1, 0))))\n",
    "\n",
    "def build_dem_configs():\n",
    "    dems = []\n",
    "    # TINITALY\n",
    "    if all(k in globals() for k in (\"slope_tin\", \"aspect_tin\", \"tinitaly_10m\")):\n",
    "        dems.append(dict(\n",
    "            name=\"TINITALY\",\n",
    "            slope=globals()[\"slope_tin\"],\n",
    "            aspect=globals()[\"aspect_tin\"],\n",
    "            elev=globals()[\"tinitaly_10m\"],\n",
    "            # preferred residual columns for SAOCOM points:\n",
    "            diff_col=\"diff_tinitaly\",\n",
    "            # fallbacks if diff_col missing:\n",
    "            abs_col=\"HEIGHT_ABSOLUTE_TIN\",   # SAOCOM-estimated height\n",
    "            ref_col=\"tinitaly_height\"        # pre-sampled reference height at point (if exists)\n",
    "        ))\n",
    "    # COPERNICUS\n",
    "    cop_slope  = globals().get(\"slope_copernicus\", globals().get(\"slope_cop\", None))\n",
    "    cop_aspect = globals().get(\"aspect_copernicus\", globals().get(\"aspect_cop\", None))\n",
    "    cop_elev   = globals().get(\"copernicus_10m\", None)\n",
    "    if (cop_slope is not None) and (cop_aspect is not None) and (cop_elev is not None):\n",
    "        dems.append(dict(\n",
    "            name=\"COPERNICUS\",\n",
    "            slope=cop_slope,\n",
    "            aspect=cop_aspect,\n",
    "            elev=cop_elev,\n",
    "            diff_col=\"diff_copernicus\",\n",
    "            abs_col=\"HEIGHT_ABSOLUTE_COP\",\n",
    "            ref_col=\"copernicus_height\"\n",
    "        ))\n",
    "    return dems\n",
    "\n",
    "def saocom_prepare_for_dem(cfg, saocom_gdf, grid_valid, grid_height, grid_width, transform):\n",
    "    \"\"\"\n",
    "    Returns a filtered SAOCOM DataFrame (in-bounds, on valid pixels, optional coherence filter)\n",
    "    with a column 'err' = absolute residual for the DEM in cfg.\n",
    "    Tries, in order:\n",
    "      1) use cfg['diff_col'] if present\n",
    "      2) compute from abs_col - ref_col if both present\n",
    "      3) if ref_col missing, sample DEM grid at point pixel as reference\n",
    "      4) if abs_col missing, try a generic 'HEIGHT_ABSOLUTE'\n",
    "    \"\"\"\n",
    "    df = saocom_gdf.copy()\n",
    "\n",
    "    # Coherence filter (optional)\n",
    "    if COHER_MIN > 0 and \"COHER\" in df.columns:\n",
    "        df = df[df[\"COHER\"] >= COHER_MIN]\n",
    "\n",
    "    # pixel indices, in-bounds & on-valid\n",
    "    r, c = rowcol(transform, df['x_utm'].values, df['y_utm'].values)\n",
    "    r = np.asarray(r); c = np.asarray(c)\n",
    "    inb = (r >= 0) & (r < grid_height) & (c >= 0) & (c < grid_width)\n",
    "    df = df.iloc[np.where(inb)[0]].copy()\n",
    "    r = r[inb]; c = c[inb]\n",
    "    on_valid = grid_valid[r, c]\n",
    "    df = df.iloc[np.where(on_valid)[0]].copy()\n",
    "    r = r[on_valid]; c = c[on_valid]\n",
    "\n",
    "    # Compute / pick residuals\n",
    "    diff_col = cfg.get(\"diff_col\", None)\n",
    "    abs_col  = cfg.get(\"abs_col\", None)\n",
    "    ref_col  = cfg.get(\"ref_col\", None)\n",
    "\n",
    "    err = None\n",
    "    if diff_col and (diff_col in df.columns):\n",
    "        err = df[diff_col].to_numpy()\n",
    "    else:\n",
    "        # pick a SAOCOM absolute height column\n",
    "        if not abs_col or (abs_col not in df.columns):\n",
    "            # fallback generic\n",
    "            abs_col = \"HEIGHT_ABSOLUTE\" if \"HEIGHT_ABSOLUTE\" in df.columns else None\n",
    "        saocom_abs = df[abs_col].to_numpy() if abs_col and (abs_col in df.columns) else None\n",
    "\n",
    "        # pick / build reference height\n",
    "        if ref_col and (ref_col in df.columns):\n",
    "            ref = df[ref_col].to_numpy()\n",
    "        else:\n",
    "            # sample DEM grid as reference\n",
    "            ref = cfg[\"elev\"][r, c]\n",
    "\n",
    "        # form residual if possible\n",
    "        if saocom_abs is not None:\n",
    "            err = saocom_abs - ref  # signed residual\n",
    "\n",
    "    if err is None:\n",
    "        # no way to compute residual — mark as NaN; overlay will still plot\n",
    "        err = np.full(len(df), np.nan, dtype=float)\n",
    "\n",
    "    df[\"err\"] = err\n",
    "    df[\"row\"] = r\n",
    "    df[\"col\"] = c\n",
    "    return df\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build DEM list and run\n",
    "# -----------------------------------------------------------------------------\n",
    "dems = build_dem_configs()\n",
    "if not dems:\n",
    "    raise RuntimeError(\"No DEM rasters detected. Provide TINITALY and/or COPERNICUS arrays per header comments.\")\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "pixel_area_km2 = (10 * 10) / 1e6  # assuming 10 m pixels\n",
    "\n",
    "for cfg in dems:\n",
    "    dem_name = cfg[\"name\"]\n",
    "    slope, aspect, elev = cfg[\"slope\"], cfg[\"aspect\"], cfg[\"elev\"]\n",
    "\n",
    "    print(f\"\\nProcessing DEM: {dem_name}\")\n",
    "\n",
    "    grid_valid = np.isfinite(slope) & np.isfinite(aspect) & np.isfinite(elev)\n",
    "    suitability = calculate_suitability_index(slope, aspect, elev)\n",
    "    sclass = classify_terrain_suitability(suitability)\n",
    "\n",
    "    # Prepare SAOCOM for this DEM (filter + residual selection/compute)\n",
    "    saocom_dem = saocom_prepare_for_dem(\n",
    "        cfg, saocom_gdf, grid_valid, grid_height, grid_width, target_transform\n",
    "    )\n",
    "\n",
    "    # ---------------- FIGURE ----------------\n",
    "    fig = plt.figure(figsize=(20,16), facecolor='white')\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.25, wspace=0.2)\n",
    "\n",
    "    # 1) SLOPE\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    im1 = ax1.imshow(np.where(grid_valid, slope, np.nan), extent=extent, cmap='YlOrRd', vmin=0, vmax=45)\n",
    "    hull_gdf.boundary.plot(ax=ax1, color='black', linewidth=2)\n",
    "    ax1.set_title(f'Terrain Slope — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('UTM Easting (m)'); ax1.set_ylabel('UTM Northing (m)')\n",
    "    plt.colorbar(im1, ax=ax1, label='Slope (degrees)', shrink=0.8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    slope_disp = np.where(grid_valid, slope, np.nan)\n",
    "    ax1.text(0.02, 0.98,\n",
    "             f\"Mean: {np.nanmean(slope_disp):.1f}°\\n\"\n",
    "             f\"Max:  {np.nanmax(slope_disp):.1f}°\\n\"\n",
    "             f\">30°: {(np.nansum(slope_disp>30)/grid_valid.sum()*100):.1f}%\",\n",
    "             transform=ax1.transAxes, fontsize=9, va='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "    # 2) ASPECT (cyclical, colorblind-friendly)\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    im2 = ax2.imshow(np.where(grid_valid, aspect, np.nan), extent=extent, cmap=plt.cm.twilight, vmin=0, vmax=360)\n",
    "    hull_gdf.boundary.plot(ax=ax2, color='black', linewidth=2)\n",
    "    ax2.set_title(f'Terrain Aspect — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('UTM Easting (m)'); ax2.set_ylabel('UTM Northing (m)')\n",
    "    cbar2 = plt.colorbar(im2, ax=ax2, label='Aspect (degrees)', shrink=0.8)\n",
    "    cbar2.set_ticks([0,90,180,270,360]); cbar2.set_ticklabels(['N','E','S','W','N'])\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3) SUITABILITY INDEX\n",
    "    ax3 = fig.add_subplot(gs[0,2])\n",
    "# COLORBLIND-FRIENDLY: Blue (good) to Red (poor)\n",
    "    cmap_discrete = plt.matplotlib.colors.ListedColormap(['#D32F2F','#FF6F00','#FDD835','#66BB6A','#1976D2'])\n",
    "    norm = plt.matplotlib.colors.BoundaryNorm([-0.5,0.5,1.5,2.5,3.5,4.5], cmap_discrete.N)\n",
    "    im3 = ax3.imshow(np.where(grid_valid, suitability, np.nan), extent=extent, cmap=cmap_discrete, vmin=0.2, vmax=1.0)\n",
    "    hull_gdf.boundary.plot(ax=ax3, color='black', linewidth=2)\n",
    "    ax3.set_title(f'InSAR Suitability Index — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlabel('UTM Easting (m)'); ax3.set_ylabel('UTM Northing (m)')\n",
    "    plt.colorbar(im3, ax=ax3, label='Suitability (0=Poor, 1=Excellent)', shrink=0.8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4) SUITABILITY CLASS + SAOCOM error overlay\n",
    "\n",
    "    # 4) SUITABILITY CLASS + SAOCOM error overlay\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[1,:2])\n",
    "    cmap_discrete = plt.matplotlib.colors.ListedColormap(['#8B0000','#FF6B6B','#FFD93D','#95E77E','#2E7D32'])\n",
    "    norm = plt.matplotlib.colors.BoundaryNorm([-0.5,0.5,1.5,2.5,3.5,4.5], cmap_discrete.N)\n",
    "    im4 = ax4.imshow(np.where(grid_valid, sclass, np.nan), extent=extent, cmap=cmap_discrete, norm=norm)\n",
    "    hull_gdf.boundary.plot(ax=ax4, color='black', linewidth=2.5)\n",
    "\n",
    "    # color by absolute residual if available, else NaN-safe\n",
    "    scatter_vals = np.abs(saocom_dem[\"err\"].to_numpy())\n",
    "    scatter = ax4.scatter(saocom_dem['x_utm'], saocom_dem['y_utm'],\n",
    "                          c=scatter_vals, s=2, cmap='plasma',\n",
    "                          vmin=0, vmax=10, alpha=0.6, edgecolors='none')\n",
    "    ax4.set_title(f'Suitability Classes with SAOCOM Error Overlay — {dem_name}', fontsize=13, fontweight='bold')\n",
    "    ax4.set_xlabel('UTM Easting (m)'); ax4.set_ylabel('UTM Northing (m)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    # Legend positioned outside the plot area\n",
    "    ax4.legend(handles=[\n",
    "        Patch(facecolor='#2E7D32', label='Excellent (Slope<5°, Favorable)'),\n",
    "        Patch(facecolor='#95E77E', label='Good (5–15°)'),\n",
    "        Patch(facecolor='#FFD93D', label='Moderate (15–30°)'),\n",
    "        Patch(facecolor='#FF6B6B', label='Poor (30–45°)'),\n",
    "        Patch(facecolor='#8B0000', label='Unsuitable (>45°, layover/shadow)')],\n",
    "        loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=9, frameon=True)\n",
    "\n",
    "    plt.colorbar(scatter, ax=ax4, label='|Residual| (m)', shrink=0.4,\n",
    "                 orientation='horizontal', pad=0.08)\n",
    "\n",
    "    # 5) CRITICAL ZONES\n",
    "    ax5 = fig.add_subplot(gs[1,2])\n",
    "    critical = grid_valid & ((slope > 30) | ((slope > 15) & ((aspect < 45) | (aspect > 315))))\n",
    "    im5 = ax5.imshow(np.where(grid_valid, critical.astype(float), np.nan), extent=extent, cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "    hull_gdf.boundary.plot(ax=ax5, color='black', linewidth=2)\n",
    "    ax5.set_title(f'Critical Zones (High Error Risk) — {dem_name}', fontsize=12, fontweight='bold')\n",
    "    ax5.set_xlabel('UTM Easting (m)'); ax5.set_ylabel('UTM Northing (m)')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    total_area = grid_valid.sum() * pixel_area_km2\n",
    "    critical_area = np.nansum(critical) * pixel_area_km2\n",
    "    ax5.text(0.02, 0.98, f\"Critical: {critical_area:.1f} km²\\n({critical_area/total_area*100:.1f}% of area)\",\n",
    "             transform=ax5.transAxes, fontsize=10, va='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.9))\n",
    "\n",
    "    # 6) STATS TABLE (uses filtered SAOCOM for this DEM)\n",
    "    ax6 = fig.add_subplot(gs[2,:]); ax6.axis('off')\n",
    "\n",
    "    # map filtered SAOCOM to the suitability class grid\n",
    "    r_v = saocom_dem[\"row\"].to_numpy(dtype=int)\n",
    "    c_v = saocom_dem[\"col\"].to_numpy(dtype=int)\n",
    "    saocom_classes = sclass[r_v, c_v]\n",
    "\n",
    "    stats = []\n",
    "    class_names = ['Unsuitable','Poor','Moderate','Good','Excellent']\n",
    "    for i in range(5):\n",
    "        cmask = (sclass == i) & grid_valid\n",
    "        area_km2 = cmask.sum() * pixel_area_km2\n",
    "        area_pct = (cmask.sum() / grid_valid.sum() * 100.0) if grid_valid.any() else 0.0\n",
    "\n",
    "        pts_mask = (saocom_classes == i)\n",
    "        if np.any(pts_mask):\n",
    "            pts = saocom_dem.loc[pts_mask]\n",
    "            mean_error = np.nanmean(np.abs(pts[\"err\"]))\n",
    "            mean_coh = np.nanmean(pts[\"COHER\"]) if \"COHER\" in pts.columns else np.nan\n",
    "            n_points = len(pts)\n",
    "        else:\n",
    "            mean_error = np.nan; mean_coh = np.nan; n_points = 0\n",
    "\n",
    "        stats.append([class_names[i], area_km2, area_pct, n_points, mean_error, mean_coh])\n",
    "\n",
    "    df = pd.DataFrame(stats, columns=['Suitability','Area (km²)','Area (%)','SAOCOM Points','Mean Error (m)','Mean Coherence'])\n",
    "    table_text = f\"TERRAIN SUITABILITY STATISTICS — {dem_name}\\n\" + \"=\"*80 + \"\\n\"\n",
    "    table_text += f\"{'Class':<15} {'Area (km²)':>12} {'Area (%)':>10} {'Points':>10} {'Error (m)':>12} {'Coherence':>10}\\n\"\n",
    "    table_text += \"-\"*80 + \"\\n\"\n",
    "    for _, row in df.iterrows():\n",
    "        table_text += f\"{row['Suitability']:<15} {row['Area (km²)']:>12.1f} {row['Area (%)']:>10.1f} {row['SAOCOM Points']:>10.0f} \"\n",
    "        if not np.isnan(row['Mean Error (m)']):\n",
    "            table_text += f\"{row['Mean Error (m)']:>12.2f} {row['Mean Coherence']:>10.3f}\\n\"\n",
    "        else:\n",
    "            table_text += f\"{'N/A':>12} {'N/A':>10}\\n\"\n",
    "    table_text += \"=\"*80 + f\"\\nTotal Area: {total_area:.1f} km²\\n\"\n",
    "    table_text += f\"Total SAOCOM Points (used): {len(saocom_dem):,}\\n\"\n",
    "    if COHER_MIN > 0: table_text += f\"Coherence filter: COHER ≥ {COHER_MIN}\\n\"\n",
    "\n",
    "    ax6.text(0.05, 0.95, table_text, transform=ax6.transAxes,\n",
    "             fontsize=10, va='top', fontfamily='monospace')\n",
    "\n",
    "    plt.suptitle(f'Topographic Suitability Assessment for InSAR — DEM: {dem_name}',\n",
    "                 fontsize=15, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---------------- SAVE RASTERS ----------------\n",
    "    print(f\"Saving suitability rasters for DEM: {dem_name} ...\")\n",
    "    profile = dict(driver='GTiff', height=grid_height, width=grid_width, count=1,\n",
    "                   crs=TARGET_CRS, transform=target_transform)\n",
    "\n",
    "    out_class = RESULTS_DIR / f\"insar_terrain_suitability_{dem_name.lower()}.tif\"\n",
    "    prof_cls = profile.copy(); prof_cls.update(dtype='uint8', nodata=255)\n",
    "    with rasterio.open(out_class, 'w', **prof_cls) as dst:\n",
    "        dst.write(np.where(grid_valid, sclass, 255).astype(np.uint8), 1)\n",
    "        dst.set_band_description(1, f'InSAR Terrain Suitability (0–4) — {dem_name}')\n",
    "    print(f\"  ✓ {out_class}\")\n",
    "\n",
    "    out_index = RESULTS_DIR / f\"insar_suitability_index_{dem_name.lower()}.tif\"\n",
    "    prof_idx = profile.copy(); prof_idx.update(dtype='float32', nodata=-9999)\n",
    "    with rasterio.open(out_index, 'w', **prof_idx) as dst:\n",
    "        dst.write(np.where(grid_valid, suitability, -9999).astype(np.float32), 1)\n",
    "        dst.set_band_description(1, f'InSAR Suitability Index (0–1) — {dem_name}')\n",
    "    print(f\"  ✓ {out_index}\")\n",
    "\n",
    "print(\"\\nDone. DEM-specific figures/rasters created and SAOCOM residuals handled per DEM.\")\n"
   ],
   "id": "69b0fd80e2bc4ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    ""
   ],
   "id": "b28a2da1a4161c62",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
