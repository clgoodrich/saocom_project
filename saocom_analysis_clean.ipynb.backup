{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAOCOM InSAR Height Validation Against Reference DEMs\n",
    "\n",
    "**Author:** SAOCOM Analysis Team  \n",
    "**Purpose:** Validate SAOCOM satellite InSAR-derived heights against high-quality reference DEMs\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a complete workflow for validating SAOCOM InSAR height measurements against two reference Digital Elevation Models (DEMs):\n",
    "- **TINItaly DEM** (10m resolution, high accuracy)\n",
    "- **Copernicus DEM** (30m resolution, global coverage)\n",
    "\n",
    "### Analysis Steps:\n",
    "1. Load and preprocess SAOCOM point cloud data\n",
    "2. Resample reference DEMs to common resolution (10m)\n",
    "3. Sample reference DEM heights at SAOCOM point locations\n",
    "4. Calibrate SAOCOM relative heights to absolute heights\n",
    "5. Detect and remove outliers using machine learning\n",
    "6. Perform statistical analysis of height differences\n",
    "7. Analyze performance by land cover type\n",
    "8. Generate comprehensive visualizations\n",
    "\n",
    "### Key Concepts:\n",
    "- **InSAR Heights**: SAOCOM provides *relative* heights that require calibration to a reference\n",
    "- **Coherence**: Quality metric for InSAR measurements (0-1, higher is better)\n",
    "- **NMAD**: Normalized Median Absolute Deviation, a robust accuracy metric\n",
    "- **Outliers**: Anomalous measurements detected using Isolation Forest algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T18:11:18.618583Z",
     "start_time": "2025-10-29T18:11:18.295058Z"
    }
   },
   "source": [
    "# Standard library\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Geospatial\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds, rowcol\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom modules from src/\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "from utils import read_raster_meta, load_dem_array\n",
    "from preprocessing import (\n",
    "    resample_to_10m,\n",
    "    mask_and_write,\n",
    "    sample_raster_at_points,\n",
    "    create_difference_grid,\n",
    "    calculate_terrain_derivatives\n",
    ")\n",
    "from calibration import calibrate_heights\n",
    "from outlier_detection import (\n",
    "    remove_isolated_knn,\n",
    "    score_outliers_isolation_forest,\n",
    "    filter_by_score_iqr,\n",
    "    visualize_outlier_results\n",
    ")\n",
    "from statistics_prog import (\n",
    "    nmad,\n",
    "    calculate_height_stats,\n",
    "    generate_height_statistics_summary\n",
    ")\n",
    "from landcover import get_clc_level1\n",
    "from visualization import (\n",
    "    plot_raster_with_stats,\n",
    "    plot_distribution_histogram,\n",
    "    plot_scatter_comparison,\n",
    "    plot_bland_altman\n",
    ")\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules imported successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Base directories\n",
    "DATA_DIR = Path('./data')\n",
    "RESULTS_DIR = Path('./results')\n",
    "IMAGES_DIR = Path('./images')\n",
    "\n",
    "# Create output directories if needed\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "IMAGES_DIR.mkdir(exist_ok=True)\n",
    "# Analysis parameters\n",
    "COHERENCE_THRESHOLD = 0.3   # Minimum coherence for valid data\n",
    "NODATA = -9999              # Nodata value for output rasters\n",
    "GRID_SIZE = 10              # Grid cell size in meters\n",
    "TARGET_CRS = 'EPSG:32632'   # UTM Zone 32N for Italy\n",
    "# Input data paths\n",
    "\n",
    "file_discovery = {\n",
    "    'saocom': (\"saocom_csv\", \"*.csv\"),\n",
    "    'tinitaly': (\"tinitaly\", \"*.tif\"),\n",
    "    'copernicus': (\"copernicus\", \"*.tif\"),\n",
    "    'corine': (\"ground_cover\", \"*.tif\"),\n",
    "    'sentinel': (\"sentinel_data\", \"*.tif\")\n",
    "}\n",
    "for key, (subdir, pattern) in file_discovery.items():\n",
    "    print(key)\n",
    "    files = list((DATA_DIR / subdir).glob(pattern))\n",
    "    if key.lower() == 'saocom':\n",
    "        globals()['SAOCOM_CSV'] = files[0] if files else None\n",
    "    elif key.lower() == 'corine':\n",
    "        globals()['CORINE_LC'] = files[0] if files else None\n",
    "        CORINE_DBF = f\"\"\"{files[0]}.vat.dbf\"\"\"\n",
    "    elif key.lower() == 'tinitaly':\n",
    "        globals()['TINITALY_DEM'] = files[0] if files else None\n",
    "    elif key.lower() == 'copernicus':\n",
    "        globals()['COPERNICUS_DEM'] = files[0] if files else None\n",
    "    elif key.lower() == 'sentinel':\n",
    "        globals()['SENTINEL_PATH'] = files[0] if files else None\n",
    "\n",
    "\n",
    "# SAOCOM_CSV = DATA_DIR / 'saocom_csv' / 'verona_fullGraph_weighted_Tcoh07_edited.csv'\n",
    "# TINITALY_DEM = DATA_DIR / 'tinitaly' / 'tinitaly_crop.tif'\n",
    "# COPERNICUS_DEM = DATA_DIR / 'copernicus.tif'\n",
    "# CORINE_LC = DATA_DIR / 'corine_clip.tif'\n",
    "# SENTINEL_PATH = DATA_DIR / 'sentinel_data' / 'Sentinel2Views_Clip.tif'\n",
    "# Output paths\n",
    "TINITALY_10M = RESULTS_DIR / 'tinitaly_10m.tif'\n",
    "COPERNICUS_10M = RESULTS_DIR / 'copernicus_10m.tif'\n",
    "SAOCOM_CLEANED_SHP = RESULTS_DIR / 'saocom_cleaned.shp'\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.absolute()}\")\n",
    "print(f\"Results directory: {RESULTS_DIR.absolute()}\")\n",
    "print(f\"SAOCOM CSV: {SAOCOM_CSV.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load SAOCOM Data\n",
    "\n",
    "SAOCOM data comes as a CSV with point coordinates and InSAR-derived heights. Key columns:\n",
    "- `HEIGHT_RELATIVE`: Relative height from InSAR (requires calibration)\n",
    "- `COHER`: Temporal coherence (quality metric, 0-1)\n",
    "- `EASTING`, `NORTHING`: UTM coordinates (EPSG:32632 for Italy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load SAOCOM CSV\n",
    "saocom_df = pd.read_csv(SAOCOM_CSV)\n",
    "print(f\"Loaded {len(saocom_df):,} SAOCOM points\")\n",
    "print(f\"Columns: {list(saocom_df.columns)}\")\n",
    "print(f\"First few rows:\")\n",
    "print(saocom_df.head())\n",
    "# Use LAT2/LON2 preferentially, fall back to LAT/LON\n",
    "# Convert from geographic (lat/lon) to UTM Zone 32N\n",
    "lat_col = 'LAT2' if 'LAT2' in saocom_df.columns else 'LAT'\n",
    "lon_col = 'LON2' if 'LON2' in saocom_df.columns else 'LON'\n",
    "print(f\"Using coordinate columns: {lat_col}, {lon_col}\")\n",
    "# Create geometry from lat/lon (EPSG:4326)\n",
    "geometry = [Point(xy) for xy in zip(saocom_df[lon_col], saocom_df[lat_col])]\n",
    "saocom_gdf = gpd.GeoDataFrame(saocom_df, geometry=geometry, crs='EPSG:4326')\n",
    "# Convert to UTM Zone 32N for Italy\n",
    "saocom_gdf = saocom_gdf.to_crs('EPSG:32632')\n",
    "# Rename HEIGHT column to HEIGHT_RELATIVE for consistency\n",
    "if 'HEIGHT' in saocom_gdf.columns and 'HEIGHT_RELATIVE' not in saocom_gdf.columns:\n",
    "    saocom_gdf['HEIGHT_RELATIVE'] = saocom_gdf['HEIGHT']\n",
    "print(f\"GeoDataFrame created\")\n",
    "print(f\"  Original CRS: EPSG:4326 (WGS84)\")\n",
    "print(f\"  Converted to: {saocom_gdf.crs}\")\n",
    "print(f\"  Bounds: {saocom_gdf.total_bounds}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Spatially Isolated Points\n",
    "\n",
    "Isolated points far from other measurements may be erroneous. We use k-nearest neighbors to identify and remove them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Remove isolated points using KNN\n",
    "print(\"Removing spatially isolated points...\")\n",
    "saocom_gdf = remove_isolated_knn(saocom_gdf, k=100, distance_threshold=1000)\n",
    "\n",
    "print(f\"\\nAfter spatial filtering: {len(saocom_gdf):,} points\")\n",
    "\n",
    "# Quick visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "saocom_gdf.plot(ax=ax, markersize=1, color='blue', alpha=0.5)\n",
    "ax.set_title('SAOCOM Point Cloud (after spatial filtering)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Easting (m)')\n",
    "ax.set_ylabel('Northing (m)')\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load and Resample Reference DEMs\n",
    "\n",
    "We need to resample both reference DEMs to a common 10m resolution to match SAOCOM's spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define target grid parameters (10m resolution)\n",
    "bounds = saocom_gdf.total_bounds  # [minx, miny, maxx, maxy]\n",
    "RESOLUTION = 10.0  # meters\n",
    "\n",
    "# Calculate grid dimensions\n",
    "grid_width = int((bounds[2] - bounds[0]) / RESOLUTION)\n",
    "grid_height = int((bounds[3] - bounds[1]) / RESOLUTION)\n",
    "\n",
    "# Create affine transform for 10m grid\n",
    "target_transform = from_bounds(\n",
    "    bounds[0], bounds[1], bounds[2], bounds[3],\n",
    "    grid_width, grid_height\n",
    ")\n",
    "target_crs = saocom_gdf.crs\n",
    "\n",
    "print(f\"Target grid: {grid_width} x {grid_height} pixels at {RESOLUTION}m resolution\")\n",
    "print(f\"Grid bounds: {bounds}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample TINItaly DEM (10m → 10m)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TINItaly is already 10m, but we resample to align grids\n",
    "print(\"Resampling TINItaly DEM...\")\n",
    "tinitaly_10m, _ = resample_to_10m(\n",
    "    src_path=TINITALY_DEM,\n",
    "    output_path=TINITALY_10M,\n",
    "    target_transform=target_transform,\n",
    "    target_crs=target_crs,\n",
    "    grid_height=grid_height,\n",
    "    grid_width=grid_width\n",
    ")\n",
    "\n",
    "print(f\"TINItaly resampled: {tinitaly_10m.shape}\")\n",
    "print(f\"Saved to: {TINITALY_10M}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Copernicus DEM (30m → 10m)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Copernicus needs upsampling from 30m to 10m\n",
    "print(\"Resampling Copernicus DEM...\")\n",
    "copernicus_10m, _ = resample_to_10m(\n",
    "    src_path=COPERNICUS_DEM,\n",
    "    output_path=COPERNICUS_10M,\n",
    "    target_transform=target_transform,\n",
    "    target_crs=target_crs,\n",
    "    grid_height=grid_height,\n",
    "    grid_width=grid_width\n",
    ")\n",
    "\n",
    "print(f\"Copernicus resampled: {copernicus_10m.shape}\")\n",
    "print(f\"Saved to: {COPERNICUS_10M}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Sample DEMs at SAOCOM Point Locations\n",
    "\n",
    "Extract reference DEM heights at each SAOCOM measurement point for comparison."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert point coordinates to raster row/col indices\n",
    "rows, cols = rowcol(\n",
    "    target_transform,\n",
    "    saocom_gdf.geometry.x,\n",
    "    saocom_gdf.geometry.y\n",
    ")\n",
    "rows = np.array(rows, dtype=int)\n",
    "cols = np.array(cols, dtype=int)\n",
    "\n",
    "# Check which points are within grid bounds\n",
    "inbounds = (\n",
    "    (rows >= 0) & (rows < grid_height) &\n",
    "    (cols >= 0) & (cols < grid_width)\n",
    ")\n",
    "\n",
    "print(f\"Points within grid bounds: {inbounds.sum():,} / {len(saocom_gdf):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sample TINItaly at SAOCOM points\n",
    "saocom_gdf['tinitaly_height'] = sample_raster_at_points(\n",
    "    tinitaly_10m, rows, cols, inbounds, nodata=-9999\n",
    ")\n",
    "\n",
    "# Sample Copernicus at SAOCOM points\n",
    "saocom_gdf['copernicus_height'] = sample_raster_at_points(\n",
    "    copernicus_10m, rows, cols, inbounds, nodata=-9999\n",
    ")\n",
    "\n",
    "# Check sampling success\n",
    "n_tinitaly = saocom_gdf['tinitaly_height'].notna().sum()\n",
    "n_copernicus = saocom_gdf['copernicus_height'].notna().sum()\n",
    "\n",
    "print(f\"\\nSuccessfully sampled:\")\n",
    "print(f\"  TINItaly: {n_tinitaly:,} points\")\n",
    "print(f\"  Copernicus: {n_copernicus:,} points\")\n",
    "\n",
    "# Preview sampled data\n",
    "print(\"\\nSample data:\")\n",
    "print(saocom_gdf[['HEIGHT_RELATIVE', 'tinitaly_height', 'copernicus_height', 'COHER']].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Calibrate SAOCOM Heights\n",
    "\n",
    "SAOCOM InSAR provides **relative** heights, not absolute elevations. We calibrate to reference DEMs using high-coherence points to estimate the vertical offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate to TINItaly"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calibrate using high-coherence points (COHER >= 0.8)\n",
    "print(\"Calibrating SAOCOM heights to TINItaly...\")\n",
    "offset_tin, rmse_tin, n_tin = calibrate_heights(\n",
    "    saocom_gdf,\n",
    "    ref_col='tinitaly_height',\n",
    "    out_col='HEIGHT_ABSOLUTE_TIN',\n",
    "    coherence_threshold=0.8\n",
    ")\n",
    "\n",
    "print(f\"\\nCalibration Results (TINItaly):\")\n",
    "print(f\"  Offset applied: {offset_tin:.2f} m\")\n",
    "print(f\"  RMSE: {rmse_tin:.2f} m\")\n",
    "print(f\"  Calibration points: {n_tin:,}\")\n",
    "\n",
    "# Calculate residuals (difference after calibration)\n",
    "saocom_gdf['diff_tinitaly'] = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate to Copernicus"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Calibrating SAOCOM heights to Copernicus...\")\n",
    "offset_cop, rmse_cop, n_cop = calibrate_heights(\n",
    "    saocom_gdf,\n",
    "    ref_col='copernicus_height',\n",
    "    out_col='HEIGHT_ABSOLUTE_COP',\n",
    "    coherence_threshold=0.8\n",
    ")\n",
    "\n",
    "print(f\"\\nCalibration Results (Copernicus):\")\n",
    "print(f\"  Offset applied: {offset_cop:.2f} m\")\n",
    "print(f\"  RMSE: {rmse_cop:.2f} m\")\n",
    "print(f\"  Calibration points: {n_cop:,}\")\n",
    "\n",
    "# Calculate residuals\n",
    "saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Outlier Detection\n",
    "\n",
    "Use **Isolation Forest** machine learning algorithm to detect spatial and statistical anomalies in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Score outliers using TINItaly residuals (more accurate reference)\n",
    "print(\"Detecting outliers using Isolation Forest...\")\n",
    "saocom_scored = score_outliers_isolation_forest(\n",
    "    saocom_gdf,\n",
    "    residual_col='diff_tinitaly',\n",
    "    contamination=0.05,  # Expect ~5% outliers\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Outlier scores computed for {len(saocom_scored):,} points\")\n",
    "print(f\"Score range: [{saocom_scored['outlier_score'].min():.3f}, {saocom_scored['outlier_score'].max():.3f}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter outliers using IQR method\n",
    "saocom_cleaned, outliers = filter_by_score_iqr(\n",
    "    saocom_scored,\n",
    "    iqr_multiplier=1  # More permissive than default (1.0)\n",
    ")\n",
    "\n",
    "print(f\"\\nOutlier Detection Results:\")\n",
    "print(f\"  Original points: {len(saocom_gdf):,}\")\n",
    "print(f\"  Outliers detected: {len(outliers):,} ({100*len(outliers)/len(saocom_gdf):.1f}%)\")\n",
    "print(f\"  Cleaned dataset: {len(saocom_cleaned):,} points\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Outlier Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate outlier visualization\n",
    "visualize_outlier_results(\n",
    "    gdf_original=saocom_gdf,\n",
    "    gdf_cleaned=saocom_cleaned,\n",
    "    outliers=outliers,\n",
    "    residual_col='diff_tinitaly',\n",
    "    results_dir=RESULTS_DIR\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Statistical Analysis\n",
    "\n",
    "Compute comprehensive statistics comparing SAOCOM to both reference DEMs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate complete statistical summary\n",
    "generate_height_statistics_summary(saocom_cleaned, gdf_name=\"SAOCOM (Cleaned)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NMAD (Robust Accuracy Metric)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NMAD for TINItaly comparison\n",
    "residuals_tin = saocom_cleaned['diff_tinitaly'].dropna()\n",
    "nmad_tin = nmad(residuals_tin)\n",
    "\n",
    "# NMAD for Copernicus comparison\n",
    "residuals_cop = saocom_cleaned['diff_copernicus'].dropna()\n",
    "nmad_cop = nmad(residuals_cop)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ROBUST ACCURACY METRICS (NMAD)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SAOCOM vs TINItaly:    NMAD = {nmad_tin:.2f} m  (n={len(residuals_tin):,})\")\n",
    "print(f\"SAOCOM vs Copernicus:  NMAD = {nmad_cop:.2f} m  (n={len(residuals_cop):,})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# NMAD is preferred over RMSE for height accuracy as it's less sensitive to outliers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create distribution comparison plots\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# TINItaly residuals\nmetrics_tin = {\n    'n_points': len(residuals_tin),\n    'mean_diff': residuals_tin.mean(),\n    'rmse': np.sqrt((residuals_tin**2).mean()),\n    'nmad': nmad_tin,\n    'std_diff': residuals_tin.std()\n}\nplot_distribution_histogram(axes[0], residuals_tin, 'SAOCOM - TINItaly', metrics_tin)\n\n# Copernicus residuals\nmetrics_cop = {\n    'n_points': len(residuals_cop),\n    'mean_diff': residuals_cop.mean(),\n    'rmse': np.sqrt((residuals_cop**2).mean()),\n    'nmad': nmad_cop,\n    'std_diff': residuals_cop.std()\n}\nplot_distribution_histogram(axes[1], residuals_cop, 'SAOCOM - Copernicus', metrics_cop)\n\n# Add grid to all axes\nif isinstance(ax, np.ndarray):\n    for a in ax.flat:\n        a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\nelse:\n    ax.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'residual_distributions.png', dpi=300, bbox_inches='tight')\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Terrain Analysis\n",
    "\n",
    "Calculate slope and aspect from reference DEMs to understand how terrain affects InSAR accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate slope and aspect from TINItaly\n",
    "print(\"Calculating terrain derivatives from TINItaly...\")\n",
    "slope_tin, aspect_tin = calculate_terrain_derivatives(\n",
    "    tinitaly_10m,\n",
    "    cellsize=10,\n",
    "    nodata=-9999\n",
    ")\n",
    "\n",
    "print(f\"Slope range: [{np.nanmin(slope_tin):.1f}°, {np.nanmax(slope_tin):.1f}°]\")\n",
    "print(f\"Mean slope: {np.nanmean(slope_tin):.1f}°\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sample slope and aspect at SAOCOM cleaned points\n",
    "# IMPORTANT: Must recalculate row/col indices for cleaned dataset\n",
    "rows_clean, cols_clean = rowcol(    target_transform,    saocom_cleaned.geometry.x,    saocom_cleaned.geometry.y)\n",
    "rows_clean = np.array(rows_clean, dtype=int)\n",
    "cols_clean = np.array(cols_clean, dtype=int)\n",
    "# Check bounds for cleaned dataset\n",
    "inbounds_clean = (    (rows_clean >= 0) & (rows_clean < grid_height) &    (cols_clean >= 0) & (cols_clean < grid_width))\n",
    "# Sample terrain derivatives\n",
    "saocom_cleaned['slope_tin'] = sample_raster_at_points(    slope_tin, rows_clean, cols_clean, inbounds_clean, nodata=-9999)\n",
    "saocom_cleaned['aspect_tin'] = sample_raster_at_points(    aspect_tin, rows_clean, cols_clean, inbounds_clean, nodata=-9999)\n",
    "print(f\"Sampled terrain derivatives for {saocom_cleaned['slope_tin'].notna().sum():,} points\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Accuracy vs Slope"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bin residuals by slope categories\n",
    "slope_bins = [0, 5, 15, 30, 90]\n",
    "slope_labels = ['Flat (0-5°)', 'Gentle (5-15°)', 'Moderate (15-30°)', 'Steep (>30°)']\n",
    "\n",
    "saocom_cleaned['slope_category'] = pd.cut(\n",
    "    saocom_cleaned['slope_tin'],\n",
    "    bins=slope_bins,\n",
    "    labels=slope_labels\n",
    ")\n",
    "\n",
    "# Calculate NMAD by slope category\n",
    "slope_stats = saocom_cleaned.groupby('slope_category')['diff_tinitaly'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('std', 'std'),\n",
    "    ('nmad', lambda x: nmad(x.dropna()))\n",
    "]).round(2)\n",
    "\n",
    "print(\"\\nAccuracy by Slope Category:\")\n",
    "print(slope_stats)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Land Cover Analysis\n",
    "\n",
    "Sample CORINE Land Cover to understand how different surface types affect InSAR accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load and sample land cover\n",
    "print(\"Loading CORINE Land Cover...\")\n",
    "with rasterio.open(CORINE_LC) as src:\n",
    "    corine_data = src.read(1)\n",
    "    corine_transform = src.transform\n",
    "    corine_crs = src.crs\n",
    "\n",
    "# Load CORINE lookup table to get LABEL3\n",
    "# CORINE_DBF = DATA_DIR / 'corine_clip.tif.vat.dbf'\n",
    "from dbfread import DBF\n",
    "dbf_table = DBF(str(CORINE_DBF), load=True)\n",
    "lookup_df = pd.DataFrame(iter(dbf_table))\n",
    "\n",
    "# Create mappings: Value -> CODE_18 and CODE_18 -> LABEL3\n",
    "value_to_code = dict(zip(lookup_df['Value'], lookup_df['CODE_18']))\n",
    "code_to_label3 = dict(zip(lookup_df['CODE_18'].astype(float).astype(int), lookup_df['LABEL3']))\n",
    "print(code_to_label3)\n",
    "print(f\"Loaded {len(code_to_label3)} CORINE land cover classes\")\n",
    "\n",
    "# Reproject SAOCOM points if needed\n",
    "if saocom_cleaned.crs != corine_crs:\n",
    "    saocom_lc = saocom_cleaned.to_crs(corine_crs)\n",
    "else:\n",
    "    saocom_lc = saocom_cleaned\n",
    "\n",
    "# Sample land cover codes\n",
    "lc_rows, lc_cols = rowcol(\n",
    "    corine_transform,\n",
    "    saocom_lc.geometry.x,\n",
    "    saocom_lc.geometry.y\n",
    ")\n",
    "lc_rows = np.array(lc_rows, dtype=int)\n",
    "lc_cols = np.array(lc_cols, dtype=int)\n",
    "\n",
    "# Check bounds\n",
    "lc_inbounds = (\n",
    "    (lc_rows >= 0) & (lc_rows < corine_data.shape[0]) &\n",
    "    (lc_cols >= 0) & (lc_cols < corine_data.shape[1])\n",
    ")\n",
    "\n",
    "# Extract raw values from raster\n",
    "lc_values = np.full(len(saocom_lc), np.nan)\n",
    "lc_values[lc_inbounds] = corine_data[lc_rows[lc_inbounds], lc_cols[lc_inbounds]]\n",
    "\n",
    "# Map: Value -> CODE_18\n",
    "lc_codes = np.array([value_to_code.get(int(v), 0) if pd.notna(v) else 0 for v in lc_values])\n",
    "\n",
    "# Store both the code and the LABEL3 description\n",
    "saocom_cleaned['corine_code'] = lc_codes.astype(float).astype(int)\n",
    "print(saocom_cleaned)\n",
    "# print([saocom_cleaned['corine_code'].iloc[0]])\n",
    "saocom_cleaned['land_cover'] = saocom_cleaned['corine_code'].apply(\n",
    "    lambda x: code_to_label3.get(int(x), 'Unknown') if pd.notna(x) and x > 0 else 'Unknown'\n",
    ")\n",
    "\n",
    "# Also add Level 1 categories for broader analysis\n",
    "saocom_cleaned['land_cover_level1'] = saocom_cleaned['corine_code'].apply(\n",
    "    lambda x: get_clc_level1(int(x)) if pd.notna(x) and x > 0 else 'Unknown'\n",
    ")\n",
    "\n",
    "print(f\"Land cover sampled for {saocom_cleaned['land_cover'].notna().sum():,} points\")\n",
    "print(f\"\\nLand cover distribution (Level 1 categories):\")\n",
    "print(saocom_cleaned['land_cover_level1'].value_counts())\n",
    "print(f\"\\nMost common Level 3 classes:\")\n",
    "print(saocom_cleaned['land_cover'].value_counts().head(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy by Land Cover Type"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate statistics by land cover\n",
    "lc_stats = saocom_cleaned.groupby('land_cover')['diff_tinitaly'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('std', 'std'),\n",
    "    ('nmad', lambda x: nmad(x.dropna()))\n",
    "]).round(2)\n",
    "\n",
    "print(\"\\nAccuracy by Land Cover Type:\")\n",
    "print(lc_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "lc_stats['nmad'].plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_title('SAOCOM Accuracy (NMAD) by Land Cover Type', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Land Cover Category', fontsize=12)\n",
    "ax.set_ylabel('NMAD (m)', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'accuracy_by_landcover.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Land Cover Spatial Map\n\nVisualize the spatial distribution of SAOCOM points by land cover type."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create land cover map with SAOCOM points\nprint(\"Creating land cover spatial map...\")\n\nfrom matplotlib.patches import Rectangle\nfrom matplotlib_scalebar.scalebar import ScaleBar\nimport matplotlib.patches as mpatches\n\n# Get most common land cover classes for legend\ntop_lc = saocom_cleaned['land_cover'].value_counts().head(10)\n\n# Create color map for land cover types\nlc_colors = plt.cm.tab20(np.linspace(0, 1, len(top_lc)))\nlc_color_map = dict(zip(top_lc.index, lc_colors))\n\nfig, ax = plt.subplots(figsize=(16, 14))\n\n# Plot points by land cover\nfor lc_type in top_lc.index:\n    lc_subset = saocom_cleaned[saocom_cleaned['land_cover'] == lc_type]\n    ax.scatter(lc_subset.geometry.x, lc_subset.geometry.y,\n               c=[lc_color_map[lc_type]], s=5, alpha=0.6, label=lc_type)\n\n# Add bounding box\nbounds = saocom_cleaned.total_bounds\nrect = Rectangle((bounds[0], bounds[1]),\n                 bounds[2] - bounds[0],\n                 bounds[3] - bounds[1],\n                 linewidth=3, edgecolor='red', facecolor='none',\n                 label='Study Area')\nax.add_patch(rect)\n\n# Add map elements\nax.set_xlabel('UTM Easting (m)', fontsize=12, fontweight='bold')\nax.set_ylabel('UTM Northing (m)', fontsize=12, fontweight='bold')\n\n# Add hull bounding box\nhull = saocom_cleaned.geometry.unary_union.convex_hull\nhull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\nhull_gdf.boundary.plot(ax=ax, color='red', linewidth=2, linestyle='--', label='Study Area Hull')\n\nax.set_title('SAOCOM Points by Land Cover Type (Top 10 Classes)',\n             fontsize=14, fontweight='bold')\nax.grid(True, alpha=0.3, linestyle='--')\n# Set proper bounds with margin\nbounds = saocom_cleaned.total_bounds\nmargin_x = (bounds[2] - bounds[0]) * 0.05\nmargin_y = (bounds[3] - bounds[1]) * 0.05\nax.set_xlim(bounds[0] - margin_x, bounds[2] + margin_x)\nax.set_ylim(bounds[1] - margin_y, bounds[3] + margin_y)\n\nax.set_aspect('equal')\n\n# Add scale bar\nscalebar = ScaleBar(1, 'm', length_fraction=0.25, location='lower right',\n                    box_alpha=0.7, scale_loc='top')\nax.add_artist(scalebar)\n\n# Add north arrow\nax.annotate('N', xy=(0.95, 0.95), xycoords='axes fraction',\n            fontsize=20, fontweight='bold', ha='center', va='center')\nax.annotate('↑', xy=(0.95, 0.92), xycoords='axes fraction',\n            fontsize=30, ha='center', va='center')\n\n# Legend outside plot area\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9, framealpha=0.9,\n          markerscale=3)  # Make legend markers 3x larger\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'land_cover_map.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"[OK] Saved land_cover_map.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Individual Land Cover Maps with Sentinel-2 Background\n\nGenerate detailed maps for each major land cover type showing:\n- Sentinel-2 RGB imagery as background\n- Points for that specific land cover type\n- Bounding box with white fill showing extent\n- All standard map elements (scale bar, north arrow, grid)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create individual land cover maps with Sentinel-2 background\n",
    "print(\"Creating individual land cover maps with Sentinel-2 background...\")\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "# Load Sentinel-2 imagery\n",
    "\n",
    "\n",
    "print(f\"Loading Sentinel-2 imagery from {SENTINEL_PATH}...\")\n",
    "with rasterio.open(SENTINEL_PATH) as src:\n",
    "    sentinel_data = src.read()  # Read all bands\n",
    "    sentinel_bounds = src.bounds\n",
    "    sentinel_crs = src.crs\n",
    "    sentinel_transform = src.transform\n",
    "\n",
    "    # Get RGB bands (assuming bands 1,2,3 are RGB or need to pick specific bands)\n",
    "    # For Sentinel-2, often need to pick bands and scale\n",
    "    if src.count >= 3:\n",
    "        # Read first 3 bands as RGB\n",
    "        rgb = np.dstack([src.read(i) for i in range(1, 4)])\n",
    "\n",
    "        # Normalize to 0-1 range for display\n",
    "        rgb_normalized = np.zeros_like(rgb, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            band = rgb[:, :, i]\n",
    "            # Clip to reasonable percentiles to avoid extreme values\n",
    "            p2, p98 = np.percentile(band[band > 0], [2, 98])\n",
    "            rgb_normalized[:, :, i] = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "\n",
    "print(f\"Sentinel-2 image loaded: {rgb.shape[0]} x {rgb.shape[1]} pixels\")\n",
    "print(f\"Bounds: {sentinel_bounds}\")\n",
    "\n",
    "# Reproject Sentinel-2 extent to match SAOCOM data CRS (EPSG:32632)\n",
    "from rasterio.warp import transform_bounds\n",
    "sentinel_extent_utm = transform_bounds(sentinel_crs, 'EPSG:32632',\n",
    "                                       sentinel_bounds.left, sentinel_bounds.bottom,\n",
    "                                       sentinel_bounds.right, sentinel_bounds.top)\n",
    "\n",
    "# Calculate extent for imshow in UTM coordinates\n",
    "sentinel_extent = [\n",
    "    sentinel_extent_utm[0],  # left\n",
    "    sentinel_extent_utm[2],  # right\n",
    "    sentinel_extent_utm[1],  # bottom\n",
    "    sentinel_extent_utm[3]   # top\n",
    "]\n",
    "\n",
    "print(f\"Sentinel-2 extent (original CRS): {sentinel_bounds}\")\n",
    "print(f\"Sentinel-2 extent (UTM 32N): {sentinel_extent}\")\n",
    "\n",
    "# Get top land cover types (minimum 500 points for meaningful visualization)\n",
    "lc_counts = saocom_cleaned['land_cover'].value_counts()\n",
    "top_lc_types = lc_counts[lc_counts >= 500].head(8).index\n",
    "\n",
    "print(f\"\\nCreating maps for {len(top_lc_types)} land cover types with >= 500 points:\")\n",
    "for lc_type in top_lc_types:\n",
    "    print(f\"  - {lc_type}: {lc_counts[lc_type]:,} points\")\n",
    "\n",
    "# Create individual map for each land cover type\n",
    "for idx, lc_type in enumerate(top_lc_types):\n",
    "    print(f\"\\nCreating map {idx+1}/{len(top_lc_types)}: {lc_type}\")\n",
    "\n",
    "    # Filter points for this land cover type\n",
    "    lc_subset = saocom_cleaned[saocom_cleaned['land_cover'] == lc_type].copy()\n",
    "\n",
    "    # Get bounding box for this land cover type\n",
    "    lc_bounds = lc_subset.total_bounds\n",
    "\n",
    "    # Add margin\n",
    "    margin_x = (lc_bounds[2] - lc_bounds[0]) * 0.15\n",
    "    margin_y = (lc_bounds[3] - lc_bounds[1]) * 0.15\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "    # Display Sentinel-2 as background\n",
    "    ax.imshow(rgb_normalized, extent=sentinel_extent, origin='upper', zorder=0)\n",
    "\n",
    "    # Add white-filled bounding box for this land cover type\n",
    "    bbox_rect = Rectangle(\n",
    "        (lc_bounds[0], lc_bounds[1]),\n",
    "        lc_bounds[2] - lc_bounds[0],\n",
    "        lc_bounds[3] - lc_bounds[1],\n",
    "        linewidth=3,\n",
    "        edgecolor='red',\n",
    "        facecolor='white',\n",
    "        alpha=0.4,\n",
    "        zorder=1,\n",
    "        label=f'{lc_type} Extent'\n",
    "    )\n",
    "    ax.add_patch(bbox_rect)\n",
    "\n",
    "    # Plot points for this land cover type\n",
    "    ax.scatter(\n",
    "        lc_subset.geometry.x,\n",
    "        lc_subset.geometry.y,\n",
    "        c='blue',\n",
    "        s=20,\n",
    "        alpha=0.7,\n",
    "        edgecolors='white',\n",
    "        linewidth=0.5,\n",
    "        zorder=2,\n",
    "        label=f'{lc_type} Points (n={len(lc_subset):,})'\n",
    "    )\n",
    "\n",
    "    # Add hull boundary for ALL SAOCOM data (for context)\n",
    "    hull = saocom_cleaned.geometry.unary_union.convex_hull\n",
    "    hull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\n",
    "    hull_gdf.boundary.plot(\n",
    "        ax=ax,\n",
    "        color='yellow',\n",
    "        linewidth=2,\n",
    "        linestyle='--',\n",
    "        label='Full Study Area',\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "    # Set map extent to land cover bounding box with margin\n",
    "    ax.set_xlim(lc_bounds[0] - margin_x, lc_bounds[2] + margin_x)\n",
    "    ax.set_ylim(lc_bounds[1] - margin_y, lc_bounds[3] + margin_y)\n",
    "\n",
    "    # Map elements\n",
    "    ax.set_xlabel('UTM Easting (m)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('UTM Northing (m)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Land Cover: {lc_type}\\n({len(lc_subset):,} SAOCOM points)',\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.5, linestyle='--', color='white', linewidth=1.5)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Add scale bar\n",
    "    scalebar = ScaleBar(1, 'm', length_fraction=0.25, location='lower right',\n",
    "                        box_alpha=0.8, scale_loc='top', color='black',\n",
    "                        box_color='white')\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    # Add north arrow\n",
    "    ax.annotate('N', xy=(0.95, 0.95), xycoords='axes fraction',\n",
    "                fontsize=20, fontweight='bold', ha='center', va='center',\n",
    "                bbox=dict(boxstyle='circle', facecolor='white', edgecolor='black', linewidth=2))\n",
    "    ax.annotate('↑', xy=(0.95, 0.92), xycoords='axes fraction',\n",
    "                fontsize=30, ha='center', va='center')\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(loc='upper left', fontsize=10, framealpha=0.9,\n",
    "              edgecolor='black', facecolor='white')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save with safe filename (replace spaces/slashes)\n",
    "    safe_filename = lc_type.replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "    plt.savefig(IMAGES_DIR / f'land_cover_{safe_filename}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"  [OK] Saved land_cover_{safe_filename}.png\")\n",
    "\n",
    "print(f\"\\n[OK] Created {len(top_lc_types)} individual land cover maps with Sentinel-2 background\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Land Cover Distribution Histograms\n\nDetailed distribution of SAOCOM points across land cover classes at different hierarchical levels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Land cover histograms at different levels\nprint(\"Creating land cover histograms...\")\n\nfig, axes = plt.subplots(2, 1, figsize=(16, 12))\n\n# Level 1 (broad categories)\nlc_level1_counts = saocom_cleaned['land_cover_level1'].value_counts()\naxes[0].barh(range(len(lc_level1_counts)), lc_level1_counts.values, color='steelblue', edgecolor='black')\naxes[0].set_yticks(range(len(lc_level1_counts)))\naxes[0].set_yticklabels(lc_level1_counts.index)\naxes[0].set_xlabel('Number of Points', fontsize=12, fontweight='bold')\naxes[0].set_title('Land Cover Distribution - Level 1 (Broad Categories)',\n                  fontsize=13, fontweight='bold')\naxes[0].grid(axis='x', alpha=0.3)\n\n# Add percentage labels\ntotal = lc_level1_counts.sum()\nfor i, v in enumerate(lc_level1_counts.values):\n    pct = 100 * v / total\n    axes[0].text(v, i, f'  {v:,} ({pct:.1f}%)', va='center', fontweight='bold')\n\n# Level 3 (detailed classes) - top 15\nlc_level3_counts = saocom_cleaned['land_cover'].value_counts().head(15)\naxes[1].barh(range(len(lc_level3_counts)), lc_level3_counts.values, color='coral', edgecolor='black')\naxes[1].set_yticks(range(len(lc_level3_counts)))\naxes[1].set_yticklabels(lc_level3_counts.index)\naxes[1].set_xlabel('Number of Points', fontsize=12, fontweight='bold')\naxes[1].set_title('Land Cover Distribution - Level 3 (Top 15 Detailed Classes)',\n                  fontsize=13, fontweight='bold')\naxes[1].grid(axis='x', alpha=0.3)\n\n# Add count labels\nfor i, v in enumerate(lc_level3_counts.values):\n    axes[1].text(v, i, f'  {v:,}', va='center', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'land_cover_histograms.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"[OK] Saved land_cover_histograms.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 SAOCOM Accuracy by Detailed Land Cover Classes\n\nAnalyze how InSAR accuracy varies across specific land cover types (Level 3)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Accuracy metrics by detailed land cover classes\nprint(\"Analyzing accuracy by detailed land cover classes...\")\n\n# Calculate statistics for classes with sufficient points\nMIN_POINTS = 100\nlc_detailed_stats = saocom_cleaned.groupby('land_cover').agg(\n    count=('diff_tinitaly', 'count'),\n    mean=('diff_tinitaly', 'mean'),\n    std=('diff_tinitaly', 'std'),\n    nmad=('diff_tinitaly', lambda x: nmad(x.dropna()))\n).reset_index()\n\n# Filter to classes with enough points\nlc_detailed_stats = lc_detailed_stats[lc_detailed_stats['count'] >= MIN_POINTS].copy()\nlc_detailed_stats = lc_detailed_stats.sort_values('nmad')\n\nprint(f\"\\nAccuracy by Land Cover (classes with >= {MIN_POINTS} points):\")\nprint(lc_detailed_stats.to_string(index=False))\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# NMAD by land cover\naxes[0].barh(range(len(lc_detailed_stats)), lc_detailed_stats['nmad'],\n             color='steelblue', edgecolor='black')\naxes[0].set_yticks(range(len(lc_detailed_stats)))\naxes[0].set_yticklabels(lc_detailed_stats['land_cover'], fontsize=9)\naxes[0].set_xlabel('NMAD (m)', fontsize=12, fontweight='bold')\naxes[0].set_title('InSAR Accuracy (NMAD) by Land Cover Type',\n                  fontsize=13, fontweight='bold')\naxes[0].axvline(x=nmad_tin, color='red', linestyle='--', linewidth=2,\n                label=f'Overall NMAD = {nmad_tin:.2f} m')\naxes[0].grid(axis='x', alpha=0.3)\naxes[0].legend()\n\n# Add NMAD values\nfor i, v in enumerate(lc_detailed_stats['nmad']):\n    axes[0].text(v, i, f'  {v:.2f}', va='center', fontweight='bold')\n\n# Point count by land cover\naxes[1].barh(range(len(lc_detailed_stats)), lc_detailed_stats['count'],\n             color='coral', edgecolor='black')\naxes[1].set_yticks(range(len(lc_detailed_stats)))\naxes[1].set_yticklabels(lc_detailed_stats['land_cover'], fontsize=9)\naxes[1].set_xlabel('Number of Points', fontsize=12, fontweight='bold')\naxes[1].set_title('Sample Size by Land Cover Type',\n                  fontsize=13, fontweight='bold')\naxes[1].grid(axis='x', alpha=0.3)\n\n# Add count labels\nfor i, v in enumerate(lc_detailed_stats['count']):\n    axes[1].text(v, i, f'  {v:,}', va='center', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'accuracy_by_detailed_land_cover.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"[OK] Saved accuracy_by_detailed_land_cover.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Land Cover vs Terrain Characteristics\n\nExplore the relationship between land cover types and terrain characteristics (slope)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Land cover vs slope analysis\nprint(\"Analyzing land cover vs terrain slope...\")\n\n# Get top land cover classes\ntop_lc_classes = saocom_cleaned['land_cover'].value_counts().head(8).index\n\n# Filter data\nlc_slope_data = saocom_cleaned[saocom_cleaned['land_cover'].isin(top_lc_classes)].copy()\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# Violin plot: Slope distribution by land cover\nplot_data_violin = [lc_slope_data[lc_slope_data['land_cover'] == lc]['slope_tin'].dropna().values\n                    for lc in top_lc_classes]\n\nparts = axes[0].violinplot(plot_data_violin, positions=range(len(top_lc_classes)),\n                           showmeans=True, showmedians=True, widths=0.7)\n\n# Color the violin plots\nfor pc, color in zip(parts['bodies'], plt.cm.Set3(np.linspace(0, 1, len(top_lc_classes)))):\n    pc.set_facecolor(color)\n    pc.set_alpha(0.7)\n\naxes[0].set_xticks(range(len(top_lc_classes)))\naxes[0].set_xticklabels(top_lc_classes, rotation=45, ha='right', fontsize=9)\naxes[0].set_ylabel('Slope (degrees)', fontsize=12, fontweight='bold')\naxes[0].set_title('Terrain Slope Distribution by Land Cover',\n                  fontsize=13, fontweight='bold')\naxes[0].grid(axis='y', alpha=0.3)\n\n# Box plot: Residuals by land cover\nplot_data_box = [lc_slope_data[lc_slope_data['land_cover'] == lc]['diff_tinitaly'].dropna().values\n                for lc in top_lc_classes]\n\nbp = axes[1].boxplot(plot_data_box, labels=top_lc_classes, patch_artist=True,\n                      showfliers=False)\n\n# Color the box plots\nfor patch, color in zip(bp['boxes'], plt.cm.Set3(np.linspace(0, 1, len(top_lc_classes)))):\n    patch.set_facecolor(color)\n    patch.set_alpha(0.7)\n\naxes[1].set_xticklabels(top_lc_classes, rotation=45, ha='right', fontsize=9)\naxes[1].set_ylabel('Height Residual (m)', fontsize=12, fontweight='bold')\naxes[1].set_title('InSAR Residual Distribution by Land Cover',\n                  fontsize=13, fontweight='bold')\naxes[1].axhline(y=0, color='red', linestyle='--', linewidth=2, alpha=0.7)\naxes[1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'land_cover_vs_terrain.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"[OK] Saved land_cover_vs_terrain.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Advanced Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots: SAOCOM vs Reference DEMs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare data for scatter plots\nvalid_tin = saocom_cleaned[['HEIGHT_ABSOLUTE_TIN', 'tinitaly_height']].dropna()\nvalid_cop = saocom_cleaned[['HEIGHT_ABSOLUTE_COP', 'copernicus_height']].dropna()\n\n# Calculate statistics\nstats_tin_scatter = {\n    'n_points': len(valid_tin),\n    'mean_diff': (valid_tin['HEIGHT_ABSOLUTE_TIN'] - valid_tin['tinitaly_height']).mean(),\n    'rmse': np.sqrt(((valid_tin['HEIGHT_ABSOLUTE_TIN'] - valid_tin['tinitaly_height'])**2).mean()),\n    'correlation': np.corrcoef(valid_tin['HEIGHT_ABSOLUTE_TIN'], valid_tin['tinitaly_height'])[0, 1]\n}\n\nstats_cop_scatter = {\n    'n_points': len(valid_cop),\n    'mean_diff': (valid_cop['HEIGHT_ABSOLUTE_COP'] - valid_cop['copernicus_height']).mean(),\n    'rmse': np.sqrt(((valid_cop['HEIGHT_ABSOLUTE_COP'] - valid_cop['copernicus_height'])**2).mean()),\n    'correlation': np.corrcoef(valid_cop['HEIGHT_ABSOLUTE_COP'], valid_cop['copernicus_height'])[0, 1]\n}\n\n# Create scatter plots\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\nplot_scatter_comparison(\n    axes[0],\n    valid_tin['tinitaly_height'].values,\n    valid_tin['HEIGHT_ABSOLUTE_TIN'].values,\n    'TINItaly Height (m)',\n    'SAOCOM Height (m)',\n    'SAOCOM vs TINItaly',\n    stats_tin_scatter\n)\n\nplot_scatter_comparison(\n    axes[1],\n    valid_cop['copernicus_height'].values,\n    valid_cop['HEIGHT_ABSOLUTE_COP'].values,\n    'Copernicus Height (m)',\n    'SAOCOM Height (m)',\n    'SAOCOM vs Copernicus',\n    stats_cop_scatter\n)\n\n# Add grid to all axes\nif isinstance(ax, np.ndarray):\n    for a in ax.flat:\n        a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\nelse:\n    ax.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'scatter_comparisons.png', dpi=300, bbox_inches='tight')\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bland-Altman Plots"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bland-Altman analysis shows agreement between measurement methods\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\nplot_bland_altman(\n    axes[0],\n    valid_tin['tinitaly_height'].values,\n    valid_tin['HEIGHT_ABSOLUTE_TIN'].values,\n    'TINItaly',\n    'SAOCOM',\n    'Bland-Altman: SAOCOM vs TINItaly',\n    fig=fig\n)\n\nplot_bland_altman(\n    axes[1],\n    valid_cop['copernicus_height'].values,\n    valid_cop['HEIGHT_ABSOLUTE_COP'].values,\n    'Copernicus',\n    'SAOCOM',\n    'Bland-Altman: SAOCOM vs Copernicus',\n    fig=fig\n)\n\n# Add grid to all axes\nif isinstance(ax, np.ndarray):\n    for a in ax.flat:\n        a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\nelse:\n    ax.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'bland_altman.png', dpi=300, bbox_inches='tight')\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Distribution of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create spatial map of residuals\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# TINItaly residuals\nvalid_pts_tin = saocom_cleaned[saocom_cleaned['diff_tinitaly'].notna()]\nvmin, vmax = np.percentile(valid_pts_tin['diff_tinitaly'], [2, 98])\n\nsc1 = axes[0].scatter(\n    valid_pts_tin.geometry.x,\n    valid_pts_tin.geometry.y,\n    c=valid_pts_tin['diff_tinitaly'],\n    cmap='RdBu_r',\n    s=3,\n    vmin=vmin,\n    vmax=vmax,\n    alpha=0.7\n)\nplt.colorbar(sc1, ax=axes[0], label='Residual (m)')\n\n# Add hull bounding box\nhull = saocom_cleaned.geometry.unary_union.convex_hull\nhull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\nhull_gdf.boundary.plot(ax=axes[0], color='red', linewidth=2, linestyle='--', label='Study Area Hull')\n\naxes[0].set_title('SAOCOM - TINItaly Residuals', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Easting (m)')\naxes[0].set_ylabel('Northing (m)')\naxes[0].set_aspect('equal')\naxes[0].grid(alpha=0.3)\n\n# Copernicus residuals\nvalid_pts_cop = saocom_cleaned[saocom_cleaned['diff_copernicus'].notna()]\nvmin2, vmax2 = np.percentile(valid_pts_cop['diff_copernicus'], [2, 98])\n\nsc2 = axes[1].scatter(\n    valid_pts_cop.geometry.x,\n    valid_pts_cop.geometry.y,\n    c=valid_pts_cop['diff_copernicus'],\n    cmap='RdBu_r',\n    s=3,\n    vmin=vmin2,\n    vmax=vmax2,\n    alpha=0.7\n)\nplt.colorbar(sc2, ax=axes[1], label='Residual (m)')\naxes[1].set_title('SAOCOM - Copernicus Residuals', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Easting (m)')\naxes[1].set_ylabel('Northing (m)')\naxes[1].set_aspect('equal')\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'spatial_residuals.png', dpi=300, bbox_inches='tight')\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save cleaned dataset to shapefile\n",
    "saocom_cleaned.to_file(SAOCOM_CLEANED_SHP)\n",
    "print(f\"Cleaned SAOCOM data saved to: {SAOCOM_CLEANED_SHP}\")\n",
    "\n",
    "# Export summary statistics to CSV\n",
    "summary_stats = {\n",
    "    'Reference_DEM': ['TINItaly', 'Copernicus'],\n",
    "    'N_Points': [len(residuals_tin), len(residuals_cop)],\n",
    "    'Mean_Residual_m': [residuals_tin.mean(), residuals_cop.mean()],\n",
    "    'Std_Dev_m': [residuals_tin.std(), residuals_cop.std()],\n",
    "    'RMSE_m': [np.sqrt((residuals_tin**2).mean()), np.sqrt((residuals_cop**2).mean())],\n",
    "    'NMAD_m': [nmad_tin, nmad_cop],\n",
    "    'Min_m': [residuals_tin.min(), residuals_cop.min()],\n",
    "    'Max_m': [residuals_tin.max(), residuals_cop.max()]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv(RESULTS_DIR / 'validation_summary.csv', index=False)\n",
    "print(f\"Summary statistics saved to: {RESULTS_DIR / 'validation_summary.csv'}\")\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Conclusions\n",
    "\n",
    "This notebook demonstrated a complete workflow for validating SAOCOM InSAR heights against reference DEMs:\n",
    "\n",
    "### Key Findings:\n",
    "1. **SAOCOM requires calibration**: InSAR heights are relative and need reference DEM calibration\n",
    "2. **Accuracy varies by terrain**: Flat terrain shows better agreement than steep slopes\n",
    "3. **Land cover matters**: Accuracy differs across vegetation types and surface characteristics\n",
    "4. **Outlier detection improves results**: Machine learning helps identify anomalous measurements\n",
    "\n",
    "### Best Practices:\n",
    "- Always use high-coherence points (COHER >= 0.8) for calibration\n",
    "- Apply spatial filtering to remove isolated points\n",
    "- Use NMAD instead of RMSE for robust accuracy assessment\n",
    "- Consider terrain and land cover when interpreting results\n",
    "\n",
    "### Next Steps:\n",
    "- Temporal analysis: Compare multiple acquisition dates\n",
    "- Physical modeling: Incorporate atmospheric corrections\n",
    "- Machine learning: Predict accuracy from terrain/land cover features\n",
    "- Integration: Combine SAOCOM with other SAR sensors (Sentinel-1, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Additional Visualizations\n",
    "\n",
    "Comprehensive visualization suite from the original analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Spatial Coverage Map\n",
    "\n",
    "Verify that SAOCOM points fall within the reference DEM extent.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Spatial overlap visualization\nfrom matplotlib.patches import Rectangle\n\nfig, ax = plt.subplots(figsize=(12, 10))\n\n# TINITALY extent box\nwith rasterio.open(TINITALY_DEM) as src:\n    dem_bounds = src.bounds\n    # Reproject bounds to target CRS if needed\n    import rasterio.warp\n    dem_bounds_utm = rasterio.warp.transform_bounds(src.crs, TARGET_CRS, *dem_bounds)\n    \n    ax.add_patch(Rectangle(\n        (dem_bounds_utm[0], dem_bounds_utm[1]),\n        dem_bounds_utm[2] - dem_bounds_utm[0],\n        dem_bounds_utm[3] - dem_bounds_utm[1],\n        linewidth=3, edgecolor='blue', facecolor='none', label='TINItaly Extent'\n    ))\n\n# SAOCOM points\nsaocom_cleaned.plot(ax=ax, markersize=1, color='red', alpha=0.5, label='SAOCOM Points')\n\n# Study area hull\nfrom shapely.geometry import box\nhull = saocom_cleaned.geometry.unary_union.convex_hull\nhull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\nhull_gdf.boundary.plot(ax=ax, color='green', linewidth=2, linestyle='--', label='Study Area Hull')\n\nax.set_xlabel('UTM Easting (m)', fontsize=12)\nax.set_ylabel('UTM Northing (m)', fontsize=12)\nax.set_title('Spatial Coverage: SAOCOM vs TINItaly DEM', fontsize=14, fontweight='bold')\nax.legend(loc='best', fontsize=10)\nax.grid(True, alpha=0.3)\nax.set_aspect('equal')\n\n# Add scale bar\nfrom matplotlib_scalebar.scalebar import ScaleBar\nscalebar = ScaleBar(1, 'm', length_fraction=0.25, location='lower right',\n                    box_alpha=0.7, scale_loc='top')\nax.add_artist(scalebar)\n\n# Add north arrow\nax.annotate('N', xy=(0.95, 0.05), xycoords='axes fraction',\n            fontsize=20, fontweight='bold', ha='center', va='center',\n            bbox=dict(boxstyle='circle', facecolor='white', edgecolor='black', linewidth=2))\nax.annotate('↑', xy=(0.95, 0.02), xycoords='axes fraction',\n            fontsize=30, ha='center', va='center')\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'spatial_coverage.png', dpi=300, bbox_inches='tight')\nplt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Gridded Comparison Analysis\n",
    "\n",
    "Create gridded difference maps to show spatial patterns of height differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create gridded difference maps (simplified)\n",
    "print(\"Creating gridded difference maps...\")\n",
    "\n",
    "# Create simple gridded visualization using scatter plot rasterization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# TINItaly grid - create from point residuals\n",
    "valid_tin_pts = saocom_cleaned[saocom_cleaned['diff_tinitaly'].notna()]\n",
    "if len(valid_tin_pts) > 0:\n",
    "    vmin, vmax = np.percentile(valid_tin_pts['diff_tinitaly'], [2, 98])\n",
    "\n",
    "    # Create gridded view using hexbin\n",
    "    hb1 = axes[0].hexbin(\n",
    "        valid_tin_pts.geometry.x,\n",
    "        valid_tin_pts.geometry.y,\n",
    "        C=valid_tin_pts['diff_tinitaly'],\n",
    "        gridsize=100,\n",
    "        cmap='RdBu_r',\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        reduce_C_function=np.mean\n",
    "    )\n",
    "    plt.colorbar(hb1, ax=axes[0], label='Difference (m)')\n",
    "    \n",
    "# Add hull bounding box\n",
    "hull = saocom_cleaned.geometry.unary_union.convex_hull\n",
    "hull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\n",
    "hull_gdf.boundary.plot(ax=axes[0], color='red', linewidth=2, linestyle='--', label='Study Area Hull')\n",
    "\n",
    "axes[0].set_title('SAOCOM - TINItaly (Gridded)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Easting (m)')\n",
    "axes[0].set_ylabel('Northing (m)')\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Copernicus grid\n",
    "valid_cop_pts = saocom_cleaned[saocom_cleaned['diff_copernicus'].notna()]\n",
    "if len(valid_cop_pts) > 0:\n",
    "    vmin2, vmax2 = np.percentile(valid_cop_pts['diff_copernicus'], [2, 98])\n",
    "\n",
    "    hb2 = axes[1].hexbin(\n",
    "        valid_cop_pts.geometry.x,\n",
    "        valid_cop_pts.geometry.y,\n",
    "        C=valid_cop_pts['diff_copernicus'],\n",
    "        gridsize=100,\n",
    "        cmap='RdBu_r',\n",
    "        vmin=vmin2,\n",
    "        vmax=vmax2,\n",
    "        reduce_C_function=np.mean\n",
    "    )\n",
    "    plt.colorbar(hb2, ax=axes[1], label='Difference (m)')\n",
    "    axes[1].set_title('SAOCOM - Copernicus (Gridded)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Easting (m)')\n",
    "    axes[1].set_ylabel('Northing (m)')\n",
    "    axes[1].set_aspect('equal')\n",
    "\n",
    "# Add grid to all axes\n",
    "if isinstance(ax, np.ndarray):\n",
    "    for a in ax.flat:\n",
    "        a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n",
    "else:\n",
    "    ax.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'gridded_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Density Plots (Hexbin)\n",
    "\n",
    "Hexbin plots show the density of measurements, useful for identifying data clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Hexbin density plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# TINItaly hexbin\n",
    "valid_tin = saocom_cleaned[['HEIGHT_ABSOLUTE_TIN', 'tinitaly_height']].dropna()\n",
    "hb1 = axes[0].hexbin(\n",
    "    valid_tin['tinitaly_height'],\n",
    "    valid_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "    gridsize=50,\n",
    "    cmap='YlOrRd',\n",
    "    mincnt=1,\n",
    "    edgecolors='none'\n",
    ")\n",
    "plt.colorbar(hb1, ax=axes[0], label='Count')\n",
    "\n",
    "# 1:1 line\n",
    "lims = [min(valid_tin['tinitaly_height'].min(), valid_tin['HEIGHT_ABSOLUTE_TIN'].min()),\n",
    "        max(valid_tin['tinitaly_height'].max(), valid_tin['HEIGHT_ABSOLUTE_TIN'].max())]\n",
    "axes[0].plot(lims, lims, 'k--', alpha=0.5, linewidth=2, label='1:1 Line')\n",
    "\n",
    "axes[0].set_xlabel('TINItaly Height (m)', fontsize=12)\n",
    "axes[0].set_ylabel('SAOCOM Height (m)', fontsize=12)\n",
    "axes[0].set_title('Density: SAOCOM vs TINItaly', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Copernicus hexbin\n",
    "valid_cop = saocom_cleaned[['HEIGHT_ABSOLUTE_COP', 'copernicus_height']].dropna()\n",
    "hb2 = axes[1].hexbin(\n",
    "    valid_cop['copernicus_height'],\n",
    "    valid_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "    gridsize=50,\n",
    "    cmap='YlOrRd',\n",
    "    mincnt=1,\n",
    "    edgecolors='none'\n",
    ")\n",
    "plt.colorbar(hb2, ax=axes[1], label='Count')\n",
    "\n",
    "# 1:1 line\n",
    "lims2 = [min(valid_cop['copernicus_height'].min(), valid_cop['HEIGHT_ABSOLUTE_COP'].min()),\n",
    "         max(valid_cop['copernicus_height'].max(), valid_cop['HEIGHT_ABSOLUTE_COP'].max())]\n",
    "axes[1].plot(lims2, lims2, 'k--', alpha=0.5, linewidth=2, label='1:1 Line')\n",
    "\n",
    "axes[1].set_xlabel('Copernicus Height (m)', fontsize=12)\n",
    "axes[1].set_ylabel('SAOCOM Height (m)', fontsize=12)\n",
    "axes[1].set_title('Density: SAOCOM vs Copernicus', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'hexbin_density.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 2D Histograms\n",
    "\n",
    "Alternative visualization of measurement density.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2D histogram plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# TINItaly 2D histogram\n",
    "h1 = axes[0].hist2d(\n",
    "    valid_tin['tinitaly_height'],\n",
    "    valid_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "    bins=100,\n",
    "    cmap='viridis',\n",
    "    cmin=1\n",
    ")\n",
    "plt.colorbar(h1[3], ax=axes[0], label='Count')\n",
    "\n",
    "# 1:1 line\n",
    "axes[0].plot(lims, lims, 'r--', alpha=0.7, linewidth=2, label='1:1 Line')\n",
    "axes[0].set_xlabel('TINItaly Height (m)', fontsize=12)\n",
    "axes[0].set_ylabel('SAOCOM Height (m)', fontsize=12)\n",
    "axes[0].set_title('2D Histogram: SAOCOM vs TINItaly', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Copernicus 2D histogram\n",
    "h2 = axes[1].hist2d(\n",
    "    valid_cop['copernicus_height'],\n",
    "    valid_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "    bins=100,\n",
    "    cmap='viridis',\n",
    "    cmin=1\n",
    ")\n",
    "plt.colorbar(h2[3], ax=axes[1], label='Count')\n",
    "\n",
    "# 1:1 line\n",
    "axes[1].plot(lims2, lims2, 'r--', alpha=0.7, linewidth=2, label='1:1 Line')\n",
    "axes[1].set_xlabel('Copernicus Height (m)', fontsize=12)\n",
    "axes[1].set_ylabel('SAOCOM Height (m)', fontsize=12)\n",
    "axes[1].set_title('2D Histogram: SAOCOM vs Copernicus', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'hist2d_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5 Violin Plots - Accuracy by Slope Category\n",
    "\n",
    "Detailed performance breakdown showing full distribution of residuals for each terrain type.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Violin plot of residuals by slope category\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Prepare data for violin plot\n",
    "slope_data = saocom_cleaned[['slope_category', 'diff_tinitaly']].dropna()\n",
    "\n",
    "# Create violin plot\n",
    "parts = ax.violinplot(\n",
    "    [slope_data[slope_data['slope_category'] == cat]['diff_tinitaly'].values \n",
    "     for cat in slope_labels],\n",
    "    positions=range(len(slope_labels)),\n",
    "    showmeans=True,\n",
    "    showmedians=True,\n",
    "    widths=0.7\n",
    ")\n",
    "\n",
    "# Customize colors\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('steelblue')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax.set_xticks(range(len(slope_labels)))\n",
    "ax.set_xticklabels(slope_labels, rotation=0)\n",
    "ax.set_xlabel('Slope Category', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Residual (SAOCOM - TINItaly) [m]', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Residual Distribution by Slope Category', fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5, linewidth=2, label='Zero Error')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'violin_plot_slope.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistics by slope category:\")\n",
    "print(slope_stats)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Residuals vs Coherence\n",
    "\n",
    "Investigate the relationship between measurement quality (coherence) and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Binned analysis of residuals vs coherence\nprint(\"Creating binned coherence analysis...\")\n\nfrom scipy import stats\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\n\n# TINItaly residuals vs coherence (binned)\nvalid_data_tin = saocom_cleaned[['COHER', 'diff_tinitaly']].dropna()\n\n# Create bins of width 0.05\ncoherence_bins = np.arange(0, 1.05, 0.05)\nbin_centers = (coherence_bins[:-1] + coherence_bins[1:]) / 2\n\n# Bin the data\nvalid_data_tin['coher_bin'] = pd.cut(valid_data_tin['COHER'], bins=coherence_bins, labels=bin_centers)\n\n# Calculate statistics per bin\nbin_stats_tin = valid_data_tin.groupby('coher_bin', observed=True)['diff_tinitaly'].agg([\n    ('mean', 'mean'),\n    ('std', 'std'),\n    ('count', 'count'),\n    ('median', 'median')\n]).reset_index()\n\n# Filter bins with at least 10 points\nbin_stats_tin = bin_stats_tin[bin_stats_tin['count'] >= 10]\n\n# Plot\naxes[0].errorbar(bin_stats_tin['coher_bin'], bin_stats_tin['mean'],\n                 yerr=bin_stats_tin['std'], fmt='o-', capsize=5,\n                 markersize=8, linewidth=2, color='steelblue', label='Mean ± Std')\naxes[0].plot(bin_stats_tin['coher_bin'], bin_stats_tin['median'],\n             's--', markersize=6, linewidth=1.5, color='coral', label='Median')\naxes[0].axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=2)\n\naxes[0].set_xlabel('Coherence (binned, width=0.05)', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Height Residual (m)', fontsize=12, fontweight='bold')\naxes[0].set_title('SAOCOM - TINItaly: Residuals vs Coherence (Binned)',\n                  fontsize=13, fontweight='bold')\naxes[0].legend(loc='best', fontsize=10)\naxes[0].grid(True, alpha=0.3, linestyle='--')\n\n# Add sample size text\nfor idx, row in bin_stats_tin.iterrows():\n    if idx % 3 == 0:  # Show every 3rd label to avoid crowding\n        axes[0].text(row['coher_bin'], axes[0].get_ylim()[1] * 0.9,\n                     f\"n={int(row['count'])}\", fontsize=8, ha='center', alpha=0.7)\n\n# Copernicus residuals vs coherence (binned)\nvalid_data_cop = saocom_cleaned[['COHER', 'diff_copernicus']].dropna()\nvalid_data_cop['coher_bin'] = pd.cut(valid_data_cop['COHER'], bins=coherence_bins, labels=bin_centers)\n\nbin_stats_cop = valid_data_cop.groupby('coher_bin', observed=True)['diff_copernicus'].agg([\n    ('mean', 'mean'),\n    ('std', 'std'),\n    ('count', 'count'),\n    ('median', 'median')\n]).reset_index()\n\nbin_stats_cop = bin_stats_cop[bin_stats_cop['count'] >= 10]\n\naxes[1].errorbar(bin_stats_cop['coher_bin'], bin_stats_cop['mean'],\n                 yerr=bin_stats_cop['std'], fmt='o-', capsize=5,\n                 markersize=8, linewidth=2, color='steelblue', label='Mean ± Std')\naxes[1].plot(bin_stats_cop['coher_bin'], bin_stats_cop['median'],\n             's--', markersize=6, linewidth=1.5, color='coral', label='Median')\naxes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=2)\n\naxes[1].set_xlabel('Coherence (binned, width=0.05)', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Height Residual (m)', fontsize=12, fontweight='bold')\naxes[1].set_title('SAOCOM - Copernicus: Residuals vs Coherence (Binned)',\n                  fontsize=13, fontweight='bold')\naxes[1].legend(loc='best', fontsize=10)\naxes[1].grid(True, alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / 'residuals_vs_coherence.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"[OK] Saved binned coherence analysis\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.7 Terrain Slope Map\n",
    "\n",
    "Visualize the terrain slope across the study area.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display slope raster\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Calculate extent from transform\n",
    "extent = [\n",
    "    target_transform.c,  # left (min x)\n",
    "    target_transform.c + target_transform.a * grid_width,  # right (max x)\n",
    "    target_transform.f + target_transform.e * grid_height,  # bottom (min y)\n",
    "    target_transform.f  # top (max y)\n",
    "]\n",
    "\n",
    "# Plot slope\n",
    "slope_plot = ax.imshow(slope_tin, cmap=\"terrain\", vmin=0, vmax=45,\n",
    "                       extent=extent, origin=\"upper\")\n",
    "cbar = plt.colorbar(slope_plot, ax=ax, label=\"Slope (degrees)\")\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "ax.set_title(\"Terrain Slope from TINItaly DEM\", fontsize=14, fontweight=\"bold\")\n",
    "# Add map elements\n",
    "ax.set_xlabel(\"UTM Easting (m)\", fontsize=10)\n",
    "ax.set_ylabel(\"UTM Northing (m)\", fontsize=10)\n",
    "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax.grid(True, alpha=0.2, color=\"white\")\n",
    "\n",
    "# Add scale bar\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "scalebar = ScaleBar(10, \"m\", length_fraction=0.25, location=\"lower right\",\n",
    "                    box_alpha=0.7, scale_loc=\"top\")\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Add north arrow\n",
    "ax.annotate(\"N\", xy=(0.95, 0.95), xycoords=\"axes fraction\",\n",
    "            fontsize=20, fontweight=\"bold\", ha=\"center\", va=\"center\",\n",
    "            bbox=dict(boxstyle=\"circle\", facecolor=\"white\", edgecolor=\"black\", linewidth=2))\n",
    "ax.annotate(\"↑\", xy=(0.95, 0.92), xycoords=\"axes fraction\",\n",
    "            fontsize=30, ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / \"terrain_slope.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Slope statistics:\")\n",
    "print(f\"  Mean: {np.nanmean(slope_tin):.1f}°\")\n",
    "print(f\"  Median: {np.nanmedian(slope_tin):.1f}°\")\n",
    "print(f\"  Max: {np.nanmax(slope_tin):.1f}°\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.8 Reference DEM Comparison\n",
    "\n",
    "Direct comparison of TINItaly and Copernicus DEMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Reference DEM comparison\n",
    "print(\"Creating reference DEM comparison...\")\n",
    "\n",
    "# Calculate difference between reference DEMs\n",
    "dem_diff = tinitaly_10m - copernicus_10m\n",
    "dem_diff[tinitaly_10m == -9999] = np.nan\n",
    "dem_diff[copernicus_10m == -9999] = np.nan\n",
    "\n",
    "# Create multi-panel comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
    "\n",
    "# Calculate extent\n",
    "extent = [\n",
    "    target_transform.c,\n",
    "    target_transform.c + target_transform.a * grid_width,\n",
    "    target_transform.f + target_transform.e * grid_height,\n",
    "    target_transform.f\n",
    "]\n",
    "\n",
    "# TINItaly DEM\n",
    "tin_plot = tinitaly_10m.copy()\n",
    "tin_plot[tin_plot == -9999] = np.nan\n",
    "im1 = axes[0, 0].imshow(tin_plot, cmap=\"terrain\", extent=extent, origin=\"upper\")\n",
    "plt.colorbar(im1, ax=axes[0, 0], label=\"Elevation (m)\")\n",
    "axes[0, 0].set_title(\"TINItaly DEM (10m)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].set_xlabel(\"UTM Easting (m)\", fontsize=8)\n",
    "axes[0, 0].set_ylabel(\"UTM Northing (m)\", fontsize=8)\n",
    "axes[0, 0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "axes[0, 0].set_xticks([])\n",
    "axes[0, 0].set_yticks([])\n",
    "\n",
    "# Add scale bar\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "scalebar = ScaleBar(10, \"m\", length_fraction=0.25, location=\"lower right\",\n",
    "                    box_alpha=0.7, scale_loc=\"top\", font_properties={\"size\": 8})\n",
    "axes[0, 0].add_artist(scalebar)\n",
    "\n",
    "# Copernicus DEM\n",
    "cop_plot = copernicus_10m.copy()\n",
    "cop_plot[cop_plot == -9999] = np.nan\n",
    "im2 = axes[0, 1].imshow(cop_plot, cmap=\"terrain\", extent=extent, origin=\"upper\")\n",
    "plt.colorbar(im2, ax=axes[0, 1], label=\"Elevation (m)\")\n",
    "axes[0, 1].set_title(\"Copernicus DEM (10m)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "axes[0, 1].set_xticks([])\n",
    "axes[0, 1].set_yticks([])\n",
    "scalebar2 = ScaleBar(10, \"m\", length_fraction=0.25, location=\"lower right\",\n",
    "                     box_alpha=0.7, scale_loc=\"top\", font_properties={\"size\": 8})\n",
    "axes[0, 1].add_artist(scalebar2)\n",
    "\n",
    "# Difference map\n",
    "if not np.all(np.isnan(dem_diff)):\n",
    "    vmin, vmax = np.nanpercentile(dem_diff, [2, 98])\n",
    "    im3 = axes[1, 0].imshow(dem_diff, extent=extent, origin=\"upper\", cmap=\"RdBu_r\", vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(im3, ax=axes[1, 0], label=\"Difference (m)\")\n",
    "    axes[1, 0].set_title(\"TINItaly - Copernicus\", fontsize=14, fontweight=\"bold\")\n",
    "    axes[1, 0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "    axes[1, 0].set_xticks([])\n",
    "    axes[1, 0].set_yticks([])\n",
    "    scalebar3 = ScaleBar(10, \"m\", length_fraction=0.25, location=\"lower right\",\n",
    "                         box_alpha=0.7, scale_loc=\"top\", font_properties={\"size\": 8})\n",
    "    axes[1, 0].add_artist(scalebar3)\n",
    "\n",
    "# Statistics panel\n",
    "axes[1, 1].axis(\"off\")\n",
    "stats_text = f\"\"\"Reference DEM Comparison Statistics\n",
    "\n",
    "TINItaly:\n",
    "  Resolution: 10m (native)\n",
    "  Range: [{np.nanmin(tin_plot):.1f}, {np.nanmax(tin_plot):.1f}] m\n",
    "  Mean: {np.nanmean(tin_plot):.1f} m\n",
    "\n",
    "Copernicus:\n",
    "  Resolution: 30m → 10m (resampled)\n",
    "  Range: [{np.nanmin(cop_plot):.1f}, {np.nanmax(cop_plot):.1f}] m\n",
    "  Mean: {np.nanmean(cop_plot):.1f} m\n",
    "\n",
    "Difference (TINItaly - Copernicus):\n",
    "  Mean: {np.nanmean(dem_diff):.2f} m\n",
    "  Std: {np.nanstd(dem_diff):.2f} m\n",
    "  NMAD: {1.4826 * np.nanmedian(np.abs(dem_diff - np.nanmedian(dem_diff))):.2f} m\n",
    "  Range: [{np.nanmin(dem_diff):.2f}, {np.nanmax(dem_diff):.2f}] m\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.1, 0.5, stats_text, transform=axes[1, 1].transAxes,\n",
    "                fontsize=12, verticalalignment=\"center\", family=\"monospace\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
    "\n",
    "# Add grid to all axes\n",
    "for a in axes.flat:\n",
    "    a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / \"reference_dem_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.9 Coverage Grid and Void Zones\n",
    "\n",
    "Analyze spatial coverage and identify void zones (areas without measurements).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create SAOCOM coverage grid\n",
    "print(\"Creating coverage grid...\")\n",
    "\n",
    "# Initialize coverage grid\n",
    "coverage_grid = np.zeros((grid_height, grid_width), dtype=bool)\n",
    "\n",
    "# Mark cells with SAOCOM data\n",
    "for idx, row in saocom_cleaned.iterrows():\n",
    "    r, c = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "    r, c = int(r), int(c)\n",
    "    if 0 <= r < grid_height and 0 <= c < grid_width:\n",
    "        coverage_grid[r, c] = True\n",
    "\n",
    "# Calculate void zones\n",
    "total_cells = grid_height * grid_width\n",
    "covered_cells = coverage_grid.sum()\n",
    "void_cells = total_cells - covered_cells\n",
    "coverage_pct = 100 * covered_cells / total_cells\n",
    "\n",
    "print(f\"Coverage statistics:\")\n",
    "print(f\"  Total grid cells: {total_cells:,}\")\n",
    "print(f\"  Covered cells: {covered_cells:,}\")\n",
    "print(f\"  Void cells: {void_cells:,}\")\n",
    "print(f\"  Coverage: {coverage_pct:.1f}%\")\n",
    "\n",
    "# Visualize coverage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Calculate extent for raster displays\n",
    "extent = [\n",
    "    target_transform.c,\n",
    "    target_transform.c + target_transform.a * grid_width,\n",
    "    target_transform.f + target_transform.e * grid_height,\n",
    "    target_transform.f\n",
    "]\n",
    "\n",
    "# Coverage map\n",
    "axes[0].imshow(coverage_grid, cmap=\"binary\", interpolation=\"nearest\", extent=extent, origin=\"upper\")\n",
    "\n",
    "# Add hull bounding box\n",
    "hull = saocom_cleaned.geometry.unary_union.convex_hull\n",
    "hull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\n",
    "hull_gdf.boundary.plot(ax=axes[0], color=\"red\", linewidth=2, linestyle=\"--\", label=\"Study Area Hull\")\n",
    "\n",
    "axes[0].set_title(f\"SAOCOM Coverage Grid ({coverage_pct:.1f}% covered)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"UTM Easting (m)\", fontsize=10)\n",
    "axes[0].set_ylabel(\"UTM Northing (m)\", fontsize=10)\n",
    "axes[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "# Void zones overlay on slope\n",
    "void_mask = ~coverage_grid\n",
    "slope_with_voids = slope_tin.copy()\n",
    "slope_with_voids[void_mask] = np.nan\n",
    "\n",
    "im2 = axes[1].imshow(slope_tin, cmap=\"terrain\", alpha=0.7, extent=extent, origin=\"upper\")\n",
    "axes[1].imshow(void_mask, cmap=\"Reds\", alpha=0.3, extent=extent, origin=\"upper\")\n",
    "plt.colorbar(im2, ax=axes[1], label=\"Slope (degrees)\")\n",
    "axes[1].set_title(\"Void Zones (red) over Terrain Slope\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"UTM Easting (m)\", fontsize=10)\n",
    "axes[1].set_ylabel(\"UTM Northing (m)\", fontsize=10)\n",
    "axes[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "# Add scale bar to first axis\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "scalebar = ScaleBar(10, \"m\", length_fraction=0.25, location=\"lower right\",\n",
    "                    box_alpha=0.7, scale_loc=\"top\", font_properties={\"size\": 8})\n",
    "axes[0].add_artist(scalebar)\n",
    "\n",
    "# Add north arrow to first axis\n",
    "axes[0].annotate(\"N\", xy=(0.95, 0.95), xycoords=\"axes fraction\",\n",
    "            fontsize=16, fontweight=\"bold\", ha=\"center\", va=\"center\",\n",
    "            bbox=dict(boxstyle=\"circle\", facecolor=\"white\", edgecolor=\"black\", linewidth=2))\n",
    "axes[0].annotate(\"↑\", xy=(0.95, 0.92), xycoords=\"axes fraction\",\n",
    "            fontsize=24, ha=\"center\", va=\"center\")\n",
    "\n",
    "# Add grid to all axes\n",
    "for a in axes.flat:\n",
    "    a.grid(True, alpha=0.3, linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / \"coverage_and_voids.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.10 Residuals by Elevation Bins\n",
    "\n",
    "Investigate if accuracy varies with elevation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bin residuals by elevation\n",
    "height_bins = [0, 200, 400, 600, 800, 1000]\n",
    "height_labels = ['0-200m', '200-400m', '400-600m', '600-800m', '800-1000m']\n",
    "\n",
    "saocom_cleaned['height_category'] = pd.cut(\n",
    "    saocom_cleaned['tinitaly_height'],\n",
    "    bins=height_bins,\n",
    "    labels=height_labels\n",
    ")\n",
    "\n",
    "# Calculate statistics by height\n",
    "height_stats = saocom_cleaned.groupby('height_category')['diff_tinitaly'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('std', 'std'),\n",
    "    ('nmad', lambda x: nmad(x.dropna()))\n",
    "]).round(2)\n",
    "\n",
    "print(\"\\nAccuracy by elevation:\")\n",
    "print(height_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar plot of NMAD by elevation\n",
    "height_stats['nmad'].plot(kind='bar', ax=axes[0], color='coral', edgecolor='black')\n",
    "axes[0].set_title('NMAD by Elevation Range', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Elevation Range', fontsize=12)\n",
    "axes[0].set_ylabel('NMAD (m)', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Sample counts by elevation\n",
    "height_stats['count'].plot(kind='bar', ax=axes[1], color='skyblue', edgecolor='black')\n",
    "axes[1].set_title('Sample Count by Elevation Range', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Elevation Range', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / 'accuracy_by_elevation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.11 Summary Dashboard\n",
    "\n",
    "Comprehensive summary of all validation metrics in one figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create summary dashboard\nfig = plt.figure(figsize=(20, 12))\ngs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n# 1. Spatial distribution\nax1 = fig.add_subplot(gs[0, 0])\nsaocom_cleaned.plot(ax=ax1, markersize=0.5, color='blue', alpha=0.3)\n\n# Add hull bounding box\nhull = saocom_cleaned.geometry.unary_union.convex_hull\nhull_gdf = gpd.GeoDataFrame(geometry=[hull], crs=saocom_cleaned.crs)\nhull_gdf.boundary.plot(ax=ax1, color='red', linewidth=2, linestyle='--', label='Study Area Hull')\n\nax1.set_title('SAOCOM Point Distribution', fontweight='bold')\nax1.set_xlabel('Easting (m)')\nax1.set_ylabel('Northing (m)')\nax1.set_aspect('equal')\n\n# 2. Residual histogram (TINItaly)\nax2 = fig.add_subplot(gs[0, 1])\nax2.hist(residuals_tin, bins=100, color='steelblue', edgecolor='black', alpha=0.7)\nax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\nax2.set_title(f'Residuals (NMAD={nmad_tin:.2f}m)', fontweight='bold')\nax2.set_xlabel('SAOCOM - TINItaly (m)')\nax2.set_ylabel('Frequency')\nax2.grid(alpha=0.3)\n\n# 3. Accuracy by slope\nax3 = fig.add_subplot(gs[0, 2])\nslope_stats['nmad'].plot(kind='bar', ax=ax3, color='coral', edgecolor='black')\nax3.set_title('NMAD by Slope Category', fontweight='bold')\nax3.set_ylabel('NMAD (m)')\nax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')\nax3.grid(axis='y', alpha=0.3)\n\n# 4. Scatter plot\nax4 = fig.add_subplot(gs[1, 0])\nsample_size = min(10000, len(valid_tin))\nsample_indices = np.random.choice(len(valid_tin), sample_size, replace=False)\nax4.scatter(\n    valid_tin['tinitaly_height'].iloc[sample_indices],\n    valid_tin['HEIGHT_ABSOLUTE_TIN'].iloc[sample_indices],\n    s=1, alpha=0.3, color='blue'\n)\nlims = [valid_tin['tinitaly_height'].min(), valid_tin['tinitaly_height'].max()]\nax4.plot(lims, lims, 'r--', alpha=0.5, linewidth=2)\nax4.set_title('SAOCOM vs TINItaly', fontweight='bold')\nax4.set_xlabel('TINItaly Height (m)')\nax4.set_ylabel('SAOCOM Height (m)')\nax4.grid(alpha=0.3)\n\n# 5. Slope map\nax5 = fig.add_subplot(gs[1, 1])\n# Calculate extent for slope raster\nextent = [\n    target_transform.c,\n    target_transform.c + target_transform.a * grid_width,\n    target_transform.f + target_transform.e * grid_height,\n    target_transform.f\n]\n\nslope_plot = ax5.imshow(slope_tin, cmap='terrain', vmin=0, vmax=45, extent=extent, origin='upper')\nplt.colorbar(slope_plot, ax=ax5, label='Slope (°)', fraction=0.046)\nax5.set_title('Terrain Slope', fontweight='bold')\nax5.axis('off')\n\n# 6. Residuals spatial map\nax6 = fig.add_subplot(gs[1, 2])\nvalid_pts = saocom_cleaned[saocom_cleaned['diff_tinitaly'].notna()]\nsample_pts = valid_pts.sample(min(10000, len(valid_pts)))\nvmin, vmax = np.percentile(sample_pts['diff_tinitaly'], [2, 98])\nsc = ax6.scatter(\n    sample_pts.geometry.x,\n    sample_pts.geometry.y,\n    c=sample_pts['diff_tinitaly'],\n    cmap='RdBu_r',\n    s=1,\n    vmin=vmin,\n    vmax=vmax,\n    alpha=0.5\n)\nplt.colorbar(sc, ax=ax6, label='Residual (m)', fraction=0.046)\nax6.set_title('Spatial Residuals', fontweight='bold')\nax6.set_aspect('equal')\nax6.axis('off')\n\n# 7. Statistics text\nax7 = fig.add_subplot(gs[2, :])\nax7.axis('off')\n\nsummary_text = f\"\"\"\\nSAOCOM INSAR VALIDATION SUMMARY\n{\"=\"*80}\n\nDataset Statistics:\n  Total points: {len(saocom_gdf):,}\n  Outliers removed: {len(outliers):,} ({100*len(outliers)/len(saocom_gdf):.1f}%)\n  Clean dataset: {len(saocom_cleaned):,}\n\nValidation against TINItaly (10m resolution):\n  NMAD: {nmad_tin:.2f} m\n  RMSE: {np.sqrt((residuals_tin**2).mean()):.2f} m\n  Mean error: {residuals_tin.mean():.2f} m\n  Correlation: {np.corrcoef(valid_tin[\"HEIGHT_ABSOLUTE_TIN\"], valid_tin[\"tinitaly_height\"])[0,1]:.4f}\n\nValidation against Copernicus (30m resampled to 10m):\n  NMAD: {nmad_cop:.2f} m\n  RMSE: {np.sqrt((residuals_cop**2).mean()):.2f} m\n  Mean error: {residuals_cop.mean():.2f} m\n  Correlation: {np.corrcoef(valid_cop[\"HEIGHT_ABSOLUTE_COP\"], valid_cop[\"copernicus_height\"])[0,1]:.4f}\n\nPerformance by Terrain:\n  Flat (0-5°):        NMAD = {slope_stats.loc[\"Flat (0-5°)\", \"nmad\"]:.2f} m  (n={int(slope_stats.loc[\"Flat (0-5°)\", \"count\"]):,})\n  Gentle (5-15°):     NMAD = {slope_stats.loc[\"Gentle (5-15°)\", \"nmad\"]:.2f} m  (n={int(slope_stats.loc[\"Gentle (5-15°)\", \"count\"]):,})\n  Moderate (15-30°):  NMAD = {slope_stats.loc[\"Moderate (15-30°)\", \"nmad\"]:.2f} m  (n={int(slope_stats.loc[\"Moderate (15-30°)\", \"count\"]):,})\n  Steep (>30°):       NMAD = {slope_stats.loc[\"Steep (>30°)\", \"nmad\"]:.2f} m  (n={int(slope_stats.loc[\"Steep (>30°)\", \"count\"]):,})\n\"\"\"\n\nax7.text(0.05, 0.5, summary_text, transform=ax7.transAxes,\n         fontsize=11, verticalalignment='center', family='monospace',\n         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n\nfig.suptitle('SAOCOM InSAR Height Validation - Complete Summary',\n             fontsize=16, fontweight='bold', y=0.98)\n\nplt.savefig(IMAGES_DIR / 'summary_dashboard.png', dpi=300, bbox_inches='tight')\nplt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
