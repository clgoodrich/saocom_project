{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "# !pip install geopandas rasterio shapely scipy scikit-learn scikit-image seaborn matplotlib_scalebar",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Environment location:\", os.path.dirname(sys.executable))"
   ],
   "id": "8cd00d9620efd105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup",
   "id": "816e84f8aa0bc9db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from unittest.mock import sentinel\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Geospatial libraries\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, calculate_default_transform\n",
    "from rasterio.transform import from_bounds, rowcol\n",
    "from rasterio.mask import mask\n",
    "from rasterio import features\n",
    "from shapely.geometry import Point, box, shape  # Add 'shape' here\n",
    "# Analysis libraries\n",
    "from rasterio.features import shapes\n",
    "import matplotlib.patches as mpatches\n",
    "# Visualization libraries\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn as sns\n",
    "# Data I/O\n",
    "from dbfread import DBF\n",
    "\n",
    "# =============================================================================\n",
    "# PATHS AND DIRECTORIES\n",
    "# =============================================================================\n",
    "DATA_DIR = Path(\"data\")\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "print(DATA_DIR)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PROCESSING PARAMETERS\n",
    "# =============================================================================\n",
    "COHERENCE_THRESHOLD = 0.3\n",
    "NODATA = -9999\n",
    "GRID_SIZE = 10  # meters\n",
    "\n",
    "# =============================================================================\n",
    "# COORDINATE REFERENCE SYSTEM\n",
    "# =============================================================================\n",
    "TARGET_CRS = 'EPSG:32632'  # UTM 32N\n",
    "\n",
    "# =============================================================================\n",
    "# CORINE LAND COVER CLASSES\n",
    "# =============================================================================\n",
    "CORINE_CLASSES = {\n",
    "    111: 'Continuous urban fabric', 112: 'Discontinuous urban fabric',\n",
    "    121: 'Industrial or commercial units', 122: 'Road and rail networks and associated land',\n",
    "    123: 'Port areas', 124: 'Airports', 131: 'Mineral extraction sites',\n",
    "    132: 'Dump sites', 133: 'Construction sites', 141: 'Green urban areas',\n",
    "    142: 'Sport and leisure facilities', 211: 'Non-irrigated arable land',\n",
    "    212: 'Permanently irrigated land', 213: 'Rice fields', 221: 'Vineyards',\n",
    "    222: 'Fruit trees and berry plantations', 223: 'Olive groves',\n",
    "    231: 'Pastures', 241: 'Annual crops associated with permanent crops',\n",
    "    242: 'Complex cultivation patterns', 243: 'Agriculture/natural vegetation mix', # Note: The description for 21 has been expanded for clarity\n",
    "    244: 'Agro-forestry areas', 311: 'Broad-leaved forest',\n",
    "    312: 'Coniferous forest', 313: 'Mixed forest', 321: 'Natural grasslands',\n",
    "    322: 'Moors and heathland', 323: 'Sclerophyllous vegetation',\n",
    "    324: 'Transitional woodland-shrub', 331: 'Beaches, dunes, sands',\n",
    "    332: 'Bare rocks', 333: 'Sparsely vegetated areas', 334: 'Burnt areas',\n",
    "    335: 'Glaciers and perpetual snow', 411: 'Inland marshes',\n",
    "    412: 'Peat bogs', 421: 'Salt marshes', 422: 'Salines',\n",
    "    423: 'Intertidal flats', 511: 'Water courses', 512: 'Water bodies',\n",
    "    521: 'Coastal lagoons', 522: 'Estuaries', 523: 'Sea and ocean'\n",
    "}\n",
    "\n",
    "# Colorblind-friendly version (paste this AFTER the original CORINE_COLORS)\n",
    "CORINE_COLORS_COLORBLIND = {\n",
    "    # ARTIFICIAL SURFACES (1xx) - Purples/Magentas/Grays\n",
    "    111: (102, 0, 102),      # Dark purple - Continuous urban\n",
    "    112: (153, 51, 153),     # Medium purple - Discontinuous urban\n",
    "    121: (204, 102, 204),    # Light purple - Industrial\n",
    "    122: (80, 80, 80),       # Dark gray - Roads/rail\n",
    "    123: (120, 120, 120),    # Medium gray - Ports\n",
    "    124: (160, 160, 160),    # Light gray - Airports\n",
    "    131: (255, 0, 255),      # Bright magenta - Mineral extraction\n",
    "    132: (178, 34, 34),      # Dark red-brown - Dump sites\n",
    "    133: (255, 150, 180),    # Darker pink - Construction (was too light)\n",
    "    141: (120, 200, 120),    # Medium green - Green urban areas (darkened)\n",
    "    142: (100, 180, 100),    # Green - Sport/leisure (darkened)\n",
    "\n",
    "    # AGRICULTURAL (2xx) - Yellows/Oranges/Browns\n",
    "    211: (230, 230, 50),     # Strong yellow - Non-irrigated arable (darkened)\n",
    "    212: (235, 200, 0),      # Gold yellow - Permanently irrigated (darkened)\n",
    "    213: (220, 180, 0),      # Dark gold - Rice fields\n",
    "    221: (255, 140, 0),      # Dark orange - Vineyards\n",
    "    222: (255, 165, 79),     # Orange - Fruit trees\n",
    "    223: (204, 153, 0),      # Olive-brown - Olive groves\n",
    "    231: (210, 210, 80),     # Medium yellow - Pastures (MUCH darker)\n",
    "    241: (200, 170, 100),    # Tan - Annual crops w/ permanent (darkened)\n",
    "    242: (210, 160, 70),     # Brown - Complex cultivation (darkened)\n",
    "    243: (190, 150, 80),     # Medium brown - Agriculture w/ natural\n",
    "    244: (179, 143, 0),      # Dark yellow-brown - Agro-forestry\n",
    "\n",
    "    # FORESTS & SEMI-NATURAL (3xx) - Teals/Cyans/Dark colors\n",
    "    311: (0, 153, 102),      # Dark teal - Broad-leaved forest\n",
    "    312: (0, 102, 76),       # Very dark teal - Coniferous forest\n",
    "    313: (0, 128, 128),      # Medium teal - Mixed forest\n",
    "    321: (150, 220, 150),    # Light green - Natural grasslands (darkened)\n",
    "    322: (102, 204, 153),    # Mint - Moors and heathland\n",
    "    323: (130, 180, 130),    # Sage - Sclerophyllous vegetation (darkened)\n",
    "    324: (51, 153, 102),     # Medium green - Transitional woodland\n",
    "    331: (210, 180, 140),    # Tan - Beaches/dunes/sands (MUCH darker)\n",
    "    332: (140, 140, 140),    # Gray - Bare rocks (darkened)\n",
    "    333: (170, 170, 120),    # Khaki - Sparsely vegetated (darkened)\n",
    "    334: (40, 40, 40),       # Near black - Burnt areas\n",
    "    335: (180, 210, 230),    # Light blue - Glaciers/snow (darkened)\n",
    "\n",
    "    # WETLANDS (4xx) - Light blues/cyans\n",
    "    411: (120, 170, 230),    # Sky blue - Inland marshes (darkened)\n",
    "    412: (80, 140, 220),     # Medium blue - Peat bogs (darkened)\n",
    "    421: (150, 190, 240),    # Light blue - Salt marshes (darkened)\n",
    "    422: (140, 170, 210),    # Powder blue - Salines (darkened)\n",
    "    423: (100, 160, 210),    # Cyan - Intertidal flats (darkened)\n",
    "\n",
    "    # WATER BODIES (5xx) - Dark blues\n",
    "    511: (0, 102, 204),      # Dark blue - Water courses\n",
    "    512: (0, 76, 153),       # Very dark blue - Water bodies\n",
    "    521: (51, 102, 153),     # Medium dark blue - Coastal lagoons\n",
    "    522: (0, 51, 102),       # Navy - Estuaries\n",
    "    523: (0, 25, 76)         # Very dark navy - Sea and ocean\n",
    "}\n",
    "\n",
    "# Use the colorblind-friendly version\n",
    "CORINE_COLORS = CORINE_COLORS_COLORBLIND\n",
    "CORINE_COLORS_MPL = {k: (r/255, g/255, b/255) for k, (r, g, b) in CORINE_COLORS.items()}\n",
    "# =============================================================================\n",
    "# FILE DISCOVERY\n",
    "# =============================================================================\n",
    "# Automatically locate data files in subdirectories\n",
    "saocom_files = list((DATA_DIR / \"saocom_csv\").glob(\"*.csv\"))\n",
    "tinitaly_files = list((DATA_DIR / \"tinitaly\").glob(\"*.tif\"))\n",
    "copernicus_files = list((DATA_DIR / \"copernicus\").glob(\"*.tif\"))\n",
    "corine_files = list((DATA_DIR / \"ground_cover\").glob(\"*.tif\"))\n",
    "sentinel_files = list((DATA_DIR / \"sentinel_data\").glob(\"*.tif\"))\n",
    "\n",
    "# Select first match for each dataset\n",
    "saocom_path = saocom_files[0] if saocom_files else None\n",
    "tinitaly_path = tinitaly_files[0] if tinitaly_files else None\n",
    "copernicus_path = copernicus_files[0] if copernicus_files else None\n",
    "corine_path = corine_files[0] if corine_files else None\n",
    "sentinel_path = sentinel_files[0] if sentinel_files else None\n",
    "\n",
    "# Find the corresponding .vat.dbf file for the CORINE raster\n",
    "corine_dbf_path = None\n",
    "if corine_path:\n",
    "    corine_dbf_candidates = list((DATA_DIR / \"ground_cover\").glob(f\"{corine_path.name}.vat.dbf\"))\n",
    "    corine_dbf_path = corine_dbf_candidates[0] if corine_dbf_candidates else None\n",
    "\n"
   ],
   "id": "86d3c5cc48f5afdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "61c9d37ea014e0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# LOAD SAOCOM POINT DATA\n",
    "# =============================================================================\n",
    "# Read CSV and standardize columns\n",
    "df = pd.read_csv(saocom_path, sep=',')\n",
    "df.columns = ['ID', 'SVET', 'LVET', 'LAT', 'LAT2', 'LON', 'LON2', 'HEIGHT', 'HEIGHT_WRT_DEM', 'SIGMA_HEIGHT', 'COHER']\n",
    "\n",
    "# Convert to numeric and remove invalid points\n",
    "for col in ['LAT', 'LON','LAT2', 'LON2',  'HEIGHT', 'COHER']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.dropna(subset=['LAT', 'LON','LAT2', 'LON2', 'HEIGHT', 'COHER'])\n",
    "df = df[(df['LAT2'] != 0) & (df['LON2'] != 0)]\n",
    "df.rename(columns={\n",
    "    'LAT': 'LAT_old',\n",
    "    'LON': 'LON_old',\n",
    "    'LAT2': 'LAT',\n",
    "    'LON2': 'LON'\n",
    "}, inplace=True)\n",
    "# Apply coherence filter\n",
    "df_filtered = df[df['COHER'] >= COHERENCE_THRESHOLD]\n",
    "\n",
    "# Convert to GeoDataFrame and reproject to target CRS\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(df_filtered['LON'], df_filtered['LAT'])]\n",
    "saocom_gdf = gpd.GeoDataFrame(df_filtered, geometry=geometry, crs='EPSG:4326')\n",
    "saocom_gdf = saocom_gdf.to_crs(TARGET_CRS)\n",
    "saocom_gdf['x_utm'] = saocom_gdf.geometry.x\n",
    "saocom_gdf['y_utm'] = saocom_gdf.geometry.y\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD REFERENCE DEMS\n",
    "# =============================================================================\n",
    "# TINITALY\n",
    "with rasterio.open(tinitaly_path) as src:\n",
    "    tinitaly_crs = src.crs\n",
    "    tinitaly_res = src.res\n",
    "    tinitaly_bounds = src.bounds\n",
    "    tinitaly_nodata = src.nodata\n",
    "\n",
    "# Copernicus\n",
    "with rasterio.open(copernicus_path) as src:\n",
    "    copernicus_crs = src.crs\n",
    "    copernicus_res = src.res\n",
    "    copernicus_bounds = src.bounds\n",
    "    copernicus_nodata = src.nodata"
   ],
   "id": "6968c5b6b7f26923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HORIZONTAL DATUM VERIFICATION",
   "id": "8c02719332a8f08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def remove_isolated_knn(gdf, k=5, distance_threshold=100):\n",
    "    \"\"\"Remove points far from k nearest neighbors.\"\"\"\n",
    "    coords = np.array([[p.x, p.y] for p in gdf.geometry])\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "    distances, _ = nbrs.kneighbors(coords)\n",
    "\n",
    "    # Average distance to k nearest neighbors (exclude self at index 0)\n",
    "    avg_distances = distances[:, 1:].mean(axis=1)\n",
    "\n",
    "    mask = avg_distances < distance_threshold\n",
    "    return gdf[mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HORIZONTAL DATUM VERIFICATION\n",
    "# =============================================================================\n",
    "# Check if datasets need reprojection to target CRS\n",
    "tinitaly_needs_reproject = str(tinitaly_crs) != TARGET_CRS\n",
    "copernicus_needs_reproject = str(copernicus_crs) != TARGET_CRS\n",
    "# corine_needs_reproject = str(corine_crs) != TARGET_CRS\n",
    "\n",
    "# =============================================================================\n",
    "# VERTICAL DATUM VERIFICATION\n",
    "# =============================================================================\n",
    "# Extract vertical datum information from CRS WKT\n",
    "tinitaly_wkt = tinitaly_crs.to_wkt()\n",
    "copernicus_wkt = copernicus_crs.to_wkt()\n",
    "\n",
    "# Check for vertical datum identifiers\n",
    "tinitaly_vertical = 'EGM2008' in tinitaly_wkt or 'geoid' in tinitaly_wkt.lower()\n",
    "copernicus_vertical = 'EGM2008' in copernicus_wkt or 'geoid' in copernicus_wkt.lower()\n",
    "\n",
    "# Copernicus GLO-30 uses EGM2008 geoid (documented)\n",
    "# TINITALY typically uses WGS84 ellipsoid (documented)\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE STUDY AREA BOUNDS AND CONVEX HULL\n",
    "# =============================================================================\n",
    "study_bounds = saocom_gdf.total_bounds  # [xmin, ymin, xmax, ymax]\n",
    "study_area_poly = box(*study_bounds)\n",
    "study_area_gdf = gpd.GeoDataFrame([1], geometry=[study_area_poly], crs=TARGET_CRS)\n",
    "saocom_gdf = remove_isolated_knn(saocom_gdf, k=5, distance_threshold=100)\n",
    "# Create convex hull from SAOCOM points for masking\n",
    "data_hull = saocom_gdf.unary_union.convex_hull\n",
    "hull_gdf = gpd.GeoDataFrame(geometry=[data_hull], crs=TARGET_CRS)\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINE 10M GRID PARAMETERS\n",
    "# =============================================================================\n",
    "xmin_grid = np.floor(study_bounds[0] / GRID_SIZE) * GRID_SIZE\n",
    "ymin_grid = np.floor(study_bounds[1] / GRID_SIZE) * GRID_SIZE\n",
    "xmax_grid = np.ceil(study_bounds[2] / GRID_SIZE) * GRID_SIZE\n",
    "ymax_grid = np.ceil(study_bounds[3] / GRID_SIZE) * GRID_SIZE\n",
    "\n",
    "grid_width = int((xmax_grid - xmin_grid) / GRID_SIZE)\n",
    "grid_height = int((ymax_grid - ymin_grid) / GRID_SIZE)\n",
    "target_transform = from_bounds(xmin_grid, ymin_grid, xmax_grid, ymax_grid, grid_width, grid_height)\n",
    "\n",
    "# =============================================================================\n",
    "# STORE REFERENCE DATASET METADATA\n",
    "# =============================================================================\n",
    "reference_dems = {\n",
    "    'tinitaly_crop': {\n",
    "        'path': tinitaly_path,\n",
    "        'crs': tinitaly_crs,\n",
    "        'needs_reproject': tinitaly_needs_reproject,\n",
    "        'vertical_datum': 'WGS84 ellipsoid'\n",
    "    },\n",
    "    'copernicus': {\n",
    "        'path': copernicus_path,\n",
    "        'crs': copernicus_crs,\n",
    "        'needs_reproject': copernicus_needs_reproject,\n",
    "        'vertical_datum': 'EGM2008 geoid'\n",
    "    }\n",
    "}"
   ],
   "id": "b2950bf77e5862ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RESAMPLE TO 10M",
   "id": "53349768947cd60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# RESAMPLE TINITALY TO 10M\n",
    "# =============================================================================\n",
    "tinitaly_10m = np.full((grid_height, grid_width), NODATA, dtype=np.float32)\n",
    "\n",
    "with rasterio.open(tinitaly_path) as src:\n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=tinitaly_10m,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=TARGET_CRS,\n",
    "        resampling=Resampling.cubic,\n",
    "        src_nodata=src.nodata,\n",
    "        dst_nodata=NODATA\n",
    "    )\n",
    "\n",
    "# Save resampled TINITALY\n",
    "tinitaly_10m_path = RESULTS_DIR / \"tinitaly_10m.tif\"\n",
    "profile = {\n",
    "    'driver': 'GTiff', 'dtype': 'float32', 'width': grid_width, 'height': grid_height,\n",
    "    'count': 1, 'crs': TARGET_CRS, 'transform': target_transform,\n",
    "    'nodata': NODATA, 'compress': 'lzw'\n",
    "}\n",
    "with rasterio.open(tinitaly_10m_path, 'w', **profile) as dst:\n",
    "    dst.write(tinitaly_10m, 1)\n",
    "\n",
    "# =============================================================================\n",
    "# RESAMPLE COPERNICUS TO 10M\n",
    "# =============================================================================\n",
    "copernicus_10m = np.full((grid_height, grid_width), NODATA, dtype=np.float32)\n",
    "\n",
    "with rasterio.open(copernicus_path) as src:\n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=copernicus_10m,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=TARGET_CRS,\n",
    "        resampling=Resampling.cubic,\n",
    "        src_nodata=src.nodata,\n",
    "        dst_nodata=NODATA\n",
    "    )\n",
    "\n",
    "# Save resampled Copernicus\n",
    "copernicus_10m_path = RESULTS_DIR / \"copernicus_10m.tif\"\n",
    "with rasterio.open(copernicus_10m_path, 'w', **profile) as dst:\n",
    "    dst.write(copernicus_10m, 1)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATE REFERENCE DATASET PATHS\n",
    "# =============================================================================\n",
    "reference_dems['tinitaly_crop']['resampled_path'] = tinitaly_10m_path\n",
    "reference_dems['tinitaly_crop']['is_10m'] = True\n",
    "reference_dems['copernicus']['resampled_path'] = copernicus_10m_path\n",
    "reference_dems['copernicus']['is_10m'] = True"
   ],
   "id": "3894d56fa3b5acd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CREATE RASTERIZED MASK FROM SAOCOM CONVEX HULL",
   "id": "f05f4e85f1fc9ad9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# CREATE RASTERIZED MASK FROM SAOCOM CONVEX HULL\n",
    "# =============================================================================\n",
    "# Rasterize the convex hull polygon to match the 10m grid\n",
    "hull_mask = features.rasterize(\n",
    "    shapes=[data_hull],\n",
    "    out_shape=(grid_height, grid_width),\n",
    "    transform=target_transform,\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype=np.uint8\n",
    ") == 1  # Convert to boolean (True inside hull)\n",
    "\n",
    "# =============================================================================\n",
    "# MASK TINITALY\n",
    "# =============================================================================\n",
    "tinitaly_10m_masked = tinitaly_10m.copy()\n",
    "tinitaly_10m_masked[~hull_mask] = NODATA\n",
    "\n",
    "# Save masked TINITALY\n",
    "tinitaly_masked_path = RESULTS_DIR / \"tinitaly_10m_masked.tif\"\n",
    "with rasterio.open(tinitaly_masked_path, 'w', **profile) as dst:\n",
    "    dst.write(tinitaly_10m_masked, 1)\n",
    "\n",
    "# =============================================================================\n",
    "# MASK COPERNICUS\n",
    "# =============================================================================\n",
    "copernicus_10m_masked = copernicus_10m.copy()\n",
    "copernicus_10m_masked[~hull_mask] = NODATA\n",
    "\n",
    "# Save masked Copernicus\n",
    "copernicus_masked_path = RESULTS_DIR / \"copernicus_10m_masked.tif\"\n",
    "with rasterio.open(copernicus_masked_path, 'w', **profile) as dst:\n",
    "    dst.write(copernicus_10m_masked, 1)\n",
    "\n",
    "# =============================================================================\n",
    "# UPDATE REFERENCE DATASET PATHS TO MASKED VERSIONS\n",
    "# =============================================================================\n",
    "reference_dems['tinitaly_crop']['masked_path'] = tinitaly_masked_path\n",
    "reference_dems['copernicus']['masked_path'] = copernicus_masked_path\n",
    "\n",
    "# Store masked arrays in memory for quick access\n",
    "tinitaly_10m = tinitaly_10m_masked\n",
    "copernicus_10m = copernicus_10m_masked\n",
    "# corine_10m = corine_10m_masked"
   ],
   "id": "d2b3cac818bd758c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SAMPLE REFERENCE DEMS AT SAOCOM LOCATIONS",
   "id": "651324acaed34b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# SAMPLE REFERENCE DEMS AT SAOCOM LOCATIONS\n",
    "# =============================================================================\n",
    "# Sample TINITALY at each SAOCOM point\n",
    "tinitaly_heights = []\n",
    "for idx, row in saocom_gdf.iterrows():\n",
    "    row_idx, col_idx = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "    if 0 <= row_idx < grid_height and 0 <= col_idx < grid_width:\n",
    "        height = tinitaly_10m[row_idx, col_idx]\n",
    "        tinitaly_heights.append(height if height != NODATA else np.nan)\n",
    "    else:\n",
    "        tinitaly_heights.append(np.nan)\n",
    "\n",
    "saocom_gdf['tinitaly_height'] = tinitaly_heights\n",
    "\n",
    "# Sample Copernicus at each SAOCOM point\n",
    "copernicus_heights = []\n",
    "for idx, row in saocom_gdf.iterrows():\n",
    "    row_idx, col_idx = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "    if 0 <= row_idx < grid_height and 0 <= col_idx < grid_width:\n",
    "        height = copernicus_10m[row_idx, col_idx]\n",
    "        copernicus_heights.append(height if height != NODATA else np.nan)\n",
    "    else:\n",
    "        copernicus_heights.append(np.nan)\n",
    "\n",
    "saocom_gdf['copernicus_height'] = copernicus_heights\n",
    "\n",
    "# Rename HEIGHT column for clarity\n",
    "saocom_gdf['HEIGHT_RELATIVE'] = saocom_gdf['HEIGHT']\n",
    "\n",
    "# =============================================================================\n",
    "# CALIBRATE SAOCOM TO TINITALY (Method 1: Constant Offset)\n",
    "# =============================================================================\n",
    "# Filter to stable points: high coherence, valid reference data\n",
    "stable_mask_tin = (\n",
    "    (saocom_gdf['COHER'] >= 0.8) &\n",
    "    (saocom_gdf['tinitaly_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_RELATIVE'].notna()) &\n",
    "    (np.abs(saocom_gdf['HEIGHT_RELATIVE']) < 1000)  # Exclude extreme outliers\n",
    ")\n",
    "\n",
    "stable_points_tin = saocom_gdf[stable_mask_tin].copy()\n",
    "\n",
    "# Calculate offset: difference between reference DEM and SAOCOM relative heights\n",
    "height_diff_tin = stable_points_tin['tinitaly_height'] - stable_points_tin['HEIGHT_RELATIVE']\n",
    "offset_tinitaly = np.median(height_diff_tin)  # Median for robustness\n",
    "\n",
    "print(f\"\\nTINITALY Calibration:\")\n",
    "print(f\"  Stable points used: {len(stable_points_tin):,}\")\n",
    "print(f\"  Constant offset: {offset_tinitaly:.3f} m\")\n",
    "print(f\"  Offset std dev: {np.std(height_diff_tin):.3f} m\")\n",
    "\n",
    "# Apply correction to all SAOCOM points\n",
    "saocom_gdf['HEIGHT_ABSOLUTE_TIN'] = saocom_gdf['HEIGHT_RELATIVE'] + offset_tinitaly\n",
    "\n",
    "# =============================================================================\n",
    "# CALIBRATE SAOCOM TO COPERNICUS (Method 1: Constant Offset)\n",
    "# =============================================================================\n",
    "stable_mask_cop = (\n",
    "    (saocom_gdf['COHER'] >= 0.8) &\n",
    "    (saocom_gdf['copernicus_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_RELATIVE'].notna()) &\n",
    "    (np.abs(saocom_gdf['HEIGHT_RELATIVE']) < 1000)\n",
    ")\n",
    "\n",
    "stable_points_cop = saocom_gdf[stable_mask_cop].copy()\n",
    "\n",
    "height_diff_cop = stable_points_cop['copernicus_height'] - stable_points_cop['HEIGHT_RELATIVE']\n",
    "offset_copernicus = np.median(height_diff_cop)\n",
    "\n",
    "print(f\"\\nCOPERNICUS Calibration:\")\n",
    "print(f\"  Stable points used: {len(stable_points_cop):,}\")\n",
    "print(f\"  Constant offset: {offset_copernicus:.3f} m\")\n",
    "print(f\"  Offset std dev: {np.std(height_diff_cop):.3f} m\")\n",
    "\n",
    "saocom_gdf['HEIGHT_ABSOLUTE_COP'] = saocom_gdf['HEIGHT_RELATIVE'] + offset_copernicus\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION: CALCULATE RMSE AT STABLE POINTS\n",
    "# =============================================================================\n",
    "# TINITALY validation\n",
    "residuals_tin = stable_points_tin['tinitaly_height'] - (stable_points_tin['HEIGHT_RELATIVE'] + offset_tinitaly)\n",
    "rmse_tin = np.sqrt(np.mean(residuals_tin**2))\n",
    "\n",
    "# Copernicus validation\n",
    "residuals_cop = stable_points_cop['copernicus_height'] - (stable_points_cop['HEIGHT_RELATIVE'] + offset_copernicus)\n",
    "rmse_cop = np.sqrt(np.mean(residuals_cop**2))\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  TINITALY RMSE: {rmse_tin:.3f} m\")\n",
    "print(f\"  Copernicus RMSE: {rmse_cop:.3f} m\")\n",
    "print(f\"\\nRecommendation: Use HEIGHT_ABSOLUTE_TIN (lower RMSE expected)\")"
   ],
   "id": "b545c5dfde927107",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CREATE SAOCOM COVERAGE GRID",
   "id": "7ce1b23f2deecf20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# CREATE SAOCOM COVERAGE GRID\n",
    "# =============================================================================\n",
    "# Initialize coverage array matching the 10m grid\n",
    "saocom_coverage = np.zeros((grid_height, grid_width), dtype=bool)\n",
    "\n",
    "# Convert SAOCOM points to grid indices\n",
    "saocom_rows, saocom_cols = rowcol(target_transform,\n",
    "                                   saocom_gdf.geometry.x.values,\n",
    "                                   saocom_gdf.geometry.y.values)\n",
    "\n",
    "# Mark cells with SAOCOM data\n",
    "valid_indices = ((saocom_rows >= 0) & (saocom_rows < grid_height) &\n",
    "                 (saocom_cols >= 0) & (saocom_cols < grid_width))\n",
    "saocom_coverage[saocom_rows[valid_indices], saocom_cols[valid_indices]] = True\n",
    "\n",
    "# =============================================================================\n",
    "# CALCULATE OVERALL VOID STATISTICS\n",
    "# =============================================================================\n",
    "# Study area mask (inside hull, excluding nodata)\n",
    "study_area_mask = hull_mask\n",
    "\n",
    "# Void mask (study area cells without SAOCOM data)\n",
    "void_mask = study_area_mask & (~saocom_coverage)\n",
    "\n",
    "n_total_cells = np.sum(study_area_mask)\n",
    "n_occupied_cells = np.sum(study_area_mask & saocom_coverage)\n",
    "n_void_cells = np.sum(void_mask)\n",
    "void_percentage = 100 * n_void_cells / n_total_cells if n_total_cells > 0 else 0\n",
    "print(void_percentage)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE VOID MASK AS RASTER\n",
    "# =============================================================================\n",
    "void_mask_path = RESULTS_DIR / \"saocom_void_mask.tif\"\n",
    "profile_void = profile.copy()\n",
    "profile_void['dtype'] = 'uint8'\n",
    "profile_void['nodata'] = 255\n",
    "void_raster = np.full((grid_height, grid_width), 255, dtype=np.uint8)\n",
    "void_raster[study_area_mask] = 0  # Data area\n",
    "void_raster[void_mask] = 1  # Void cells\n",
    "\n",
    "with rasterio.open(void_mask_path, 'w', **profile_void) as dst:\n",
    "    dst.write(void_raster, 1)"
   ],
   "id": "54fb161ba66aeecc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LOAD REFERENCE DEM DATA (Already in memory from Cell 4)",
   "id": "e6663a8a847aa387"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# LOAD REFERENCE DEM DATA (Already in memory from Cell 4)\n",
    "# =============================================================================\n",
    "tinitaly_data = tinitaly_10m.copy()\n",
    "copernicus_data = copernicus_10m.copy()\n",
    "\n",
    "# =============================================================================\n",
    "# CALCULATE ELEVATION DIFFERENCE (TINITALY - COPERNICUS)\n",
    "# =============================================================================\n",
    "elevation_diff = tinitaly_data - copernicus_data\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE VALID COMPARISON MASK\n",
    "# =============================================================================\n",
    "valid_mask = (tinitaly_data != NODATA) & (copernicus_data != NODATA)\n",
    "\n",
    "# Extract valid data for statistics\n",
    "# valid_pixels = np.sum(valid_mask)\n",
    "valid_pixels = int(np.sum(valid_mask))\n",
    "valid_diffs = elevation_diff[valid_mask]\n",
    "valid_tinitaly = tinitaly_data[valid_mask]\n",
    "valid_copernicus = copernicus_data[valid_mask]\n",
    "print(valid_diffs)\n",
    "# =============================================================================\n",
    "# CALCULATE REFERENCE COMPARISON STATISTICS\n",
    "# =============================================================================\n",
    "ref_metrics = {\n",
    "    'n_pixels': int(valid_pixels),\n",
    "    'mean_diff': float(np.mean(valid_diffs)),\n",
    "    'median_diff': float(np.median(valid_diffs)),\n",
    "    'std_diff': float(np.std(valid_diffs)),\n",
    "    'rmse': float(np.sqrt(np.mean(valid_diffs**2))),\n",
    "    'mae': float(np.mean(np.abs(valid_diffs))),\n",
    "    'nmad': float(1.4826 * np.median(np.abs(valid_diffs - np.median(valid_diffs)))),\n",
    "    'min_diff': float(np.min(valid_diffs)),\n",
    "    'max_diff': float(np.max(valid_diffs)),\n",
    "    'correlation': float(np.corrcoef(valid_tinitaly, valid_copernicus)[0, 1])\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINE EQUALITY TOLERANCE USING NMAD\n",
    "# =============================================================================\n",
    "# Use NMAD as statistical threshold for \"roughly equal\"\n",
    "equal_tolerance = ref_metrics['nmad']\n",
    "print(equal_tolerance)\n",
    "# =============================================================================\n",
    "# DIRECTIONAL COMPARISON GRIDS WITH EQUALITY BUFFER\n",
    "# =============================================================================\n",
    "# Where TINITALY significantly > Copernicus\n",
    "tinitaly_higher_mask = (valid_mask) & (elevation_diff > equal_tolerance)\n",
    "tinitaly_higher_data = np.full_like(elevation_diff, np.nan)\n",
    "tinitaly_higher_data[tinitaly_higher_mask] = elevation_diff[tinitaly_higher_mask]\n",
    "\n",
    "# Where TINITALY significantly < Copernicus\n",
    "tinitaly_lower_mask = (valid_mask) & (elevation_diff < -equal_tolerance)\n",
    "tinitaly_lower_data = np.full_like(elevation_diff, np.nan)\n",
    "tinitaly_lower_data[tinitaly_lower_mask] = elevation_diff[tinitaly_lower_mask]\n",
    "\n",
    "# Where TINITALY ≈ Copernicus (within tolerance)\n",
    "roughly_equal_mask = (valid_mask) & (np.abs(elevation_diff) <= equal_tolerance)\n",
    "roughly_equal_data = np.full_like(elevation_diff, np.nan)\n",
    "roughly_equal_data[roughly_equal_mask] = elevation_diff[roughly_equal_mask]\n",
    "\n",
    "# Pixel counts and percentages\n",
    "higher_pixels = int(np.sum(tinitaly_higher_mask))\n",
    "lower_pixels = int(np.sum(tinitaly_lower_mask))\n",
    "equal_pixels = int(np.sum(roughly_equal_mask))\n",
    "\n",
    "pct_higher = float(100 * higher_pixels / valid_pixels) if valid_pixels > 0 else 0.0\n",
    "pct_lower = float(100 * lower_pixels / valid_pixels) if valid_pixels > 0 else 0.0\n",
    "pct_equal = float(100 * equal_pixels / valid_pixels) if valid_pixels > 0 else 0.0\n",
    "\n",
    "# =============================================================================\n",
    "# HEIGHT STATISTICS COMPARISON\n",
    "# =============================================================================\n",
    "def calculate_height_stats(data, name):\n",
    "    \"\"\"Calculate comprehensive height statistics\"\"\"\n",
    "    valid_data = data[~np.isnan(data)]\n",
    "\n",
    "    if len(valid_data) == 0:\n",
    "        return None\n",
    "\n",
    "    stats = {\n",
    "        'Dataset': name,\n",
    "        'Count': len(valid_data),\n",
    "        'Min': np.min(valid_data),\n",
    "        'Max': np.max(valid_data),\n",
    "        'Mean': np.mean(valid_data),\n",
    "        'Median': np.median(valid_data),\n",
    "        'Std Dev': np.std(valid_data),\n",
    "        'Range': np.max(valid_data) - np.min(valid_data),\n",
    "        'Q25': np.percentile(valid_data, 25),\n",
    "        'Q75': np.percentile(valid_data, 75),\n",
    "        'IQR': np.percentile(valid_data, 75) - np.percentile(valid_data, 25)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Collect statistics\n",
    "stats_list = []\n",
    "\n",
    "# SAOCOM relative heights\n",
    "stats_list.append(calculate_height_stats(\n",
    "    saocom_gdf['HEIGHT_RELATIVE'].values,\n",
    "    'SAOCOM (Relative)'\n",
    "))\n",
    "\n",
    "# TINITALY sampled at SAOCOM points\n",
    "stats_list.append(calculate_height_stats(\n",
    "    saocom_gdf['tinitaly_height'].values,\n",
    "    'TINITALY (at SAOCOM pts)'\n",
    "))\n",
    "\n",
    "# Copernicus sampled at SAOCOM points\n",
    "stats_list.append(calculate_height_stats(\n",
    "    saocom_gdf['copernicus_height'].values,\n",
    "    'Copernicus (at SAOCOM pts)'\n",
    "))\n",
    "\n",
    "# TINITALY full raster (within study area)\n",
    "tinitaly_valid = tinitaly_10m[tinitaly_10m != NODATA]\n",
    "stats_list.append(calculate_height_stats(\n",
    "    tinitaly_valid,\n",
    "    'TINITALY (Full Grid)'\n",
    "))\n",
    "\n",
    "# Copernicus full raster (within study area)\n",
    "copernicus_valid = copernicus_10m[copernicus_10m != NODATA]\n",
    "stats_list.append(calculate_height_stats(\n",
    "    copernicus_valid,\n",
    "    'Copernicus (Full Grid)'\n",
    "))\n",
    "\n",
    "# Create DataFrame\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "# Display with formatting\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"HEIGHT STATISTICS SUMMARY (all values in meters)\")\n",
    "print(\"=\"*90)\n",
    "print(stats_df.to_string(index=False, float_format=lambda x: f'{x:.2f}'))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Additional comparison: SAOCOM vs Reference DEMs\n",
    "print(\"\\nDIFFERENCE STATISTICS (SAOCOM Relative - Reference DEM):\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "# SAOCOM - TINITALY\n",
    "diff_tin = saocom_gdf['HEIGHT_RELATIVE'] - saocom_gdf['tinitaly_height']\n",
    "diff_tin_valid = diff_tin.dropna()\n",
    "print(f\"\\nSAOCOM - TINITALY:\")\n",
    "print(f\"  Mean difference: {diff_tin_valid.mean():+.3f} m\")\n",
    "print(f\"  Median difference: {diff_tin_valid.median():+.3f} m\")\n",
    "print(f\"  Std deviation: {diff_tin_valid.std():.3f} m\")\n",
    "print(f\"  RMSE: {np.sqrt((diff_tin_valid**2).mean()):.3f} m\")\n",
    "\n",
    "# SAOCOM - Copernicus\n",
    "diff_cop = saocom_gdf['HEIGHT_RELATIVE'] - saocom_gdf['copernicus_height']\n",
    "diff_cop_valid = diff_cop.dropna()\n",
    "print(f\"\\nSAOCOM - Copernicus:\")\n",
    "print(f\"  Mean difference: {diff_cop_valid.mean():+.3f} m\")\n",
    "print(f\"  Median difference: {diff_cop_valid.median():+.3f} m\")\n",
    "print(f\"  Std deviation: {diff_cop_valid.std():.3f} m\")\n",
    "print(f\"  RMSE: {np.sqrt((diff_cop_valid**2).mean()):.3f} m\")\n",
    "\n",
    "# TINITALY - Copernicus (reference comparison)\n",
    "ref_diff = (tinitaly_10m[valid_mask] - copernicus_10m[valid_mask])\n",
    "ref_diff_valid = ref_diff[~np.isnan(ref_diff)]\n",
    "print(f\"\\nTINITALY - Copernicus (Reference Check):\")\n",
    "print(f\"  Mean difference: {ref_diff_valid.mean():+.3f} m\")\n",
    "print(f\"  Median difference: {np.median(ref_diff_valid):+.3f} m\")\n",
    "print(f\"  Std deviation: {ref_diff_valid.std():.3f} m\")\n",
    "print(f\"  RMSE: {np.sqrt((ref_diff_valid**2).mean()):.3f} m\")"
   ],
   "id": "86bbe0cb6f0b1b68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LOAD DBF LOOKUP TABLE",
   "id": "b265fb24777a1820"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3. LOAD DBF LOOKUP TABLE\n",
    "# -----------------------------------------------------------------------------\n",
    "dbf_table = DBF(corine_dbf_path, load=True)\n",
    "lookup_df = pd.DataFrame(iter(dbf_table))\n",
    "\n",
    "# Create mapping dictionaries\n",
    "value_to_code = dict(zip(lookup_df['Value'], lookup_df['CODE_18']))\n",
    "value_to_label = dict(zip(lookup_df['Value'], lookup_df['LABEL3']))\n",
    "code_to_label = dict(zip(lookup_df['CODE_18'], lookup_df['LABEL3']))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. LOAD, MASK, AND REMAP CORINE (OPTIMIZED)\n",
    "# -----------------------------------------------------------------------------\n",
    "with rasterio.open(corine_path) as src:\n",
    "    # Reproject hull to match CORINE CRS\n",
    "    hull_corine_crs = hull_gdf.to_crs(src.crs)\n",
    "\n",
    "    # Crop to study area using convex hull FIRST (faster processing)\n",
    "    corine_raw, crop_transform = mask(src, hull_corine_crs.geometry, crop=True, filled=False)\n",
    "    corine_raw = corine_raw[0]  # Extract from (1, h, w) to (h, w)\n",
    "\n",
    "    corine_crs = src.crs\n",
    "    corine_res = src.res\n",
    "    corine_nodata = src.nodata if src.nodata is not None else 255\n",
    "    corine_bounds = src.bounds\n",
    "\n",
    "# Remap values: Value → CODE_18 (on cropped array)\n",
    "corine_remapped = np.full_like(corine_raw, 0, dtype=np.uint16)\n",
    "for value, code in value_to_code.items():\n",
    "    corine_remapped[corine_raw == value] = code\n",
    "corine_remapped[corine_raw == corine_nodata] = 0  # NoData = 0\n",
    "\n",
    "# Save intermediate remapped version\n",
    "corine_remapped_path = RESULTS_DIR / \"corine_remapped_cropped.tif\"\n",
    "profile_remapped = {\n",
    "    'driver': 'GTiff', 'dtype': 'uint16',\n",
    "    'width': corine_remapped.shape[1], 'height': corine_remapped.shape[0],\n",
    "    'count': 1, 'crs': corine_crs, 'transform': crop_transform,\n",
    "    'nodata': 0, 'compress': 'lzw'\n",
    "}\n",
    "with rasterio.open(corine_remapped_path, 'w', **profile_remapped) as dst:\n",
    "    dst.write(corine_remapped, 1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. RESAMPLE TO 10M GRID\n",
    "# -----------------------------------------------------------------------------\n",
    "corine_10m = np.full((grid_height, grid_width), 0, dtype=np.uint16)\n",
    "\n",
    "with rasterio.open(corine_remapped_path) as src:\n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=corine_10m,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=TARGET_CRS,\n",
    "        resampling=Resampling.nearest,  # Use nearest for categorical data\n",
    "        src_nodata=0,\n",
    "        dst_nodata=0\n",
    "    )\n",
    "\n",
    "# Save resampled version\n",
    "corine_10m_path = RESULTS_DIR / \"corine_10m.tif\"\n",
    "profile_10m = {\n",
    "    'driver': 'GTiff', 'dtype': 'uint16',\n",
    "    'width': grid_width, 'height': grid_height,\n",
    "    'count': 1, 'crs': TARGET_CRS, 'transform': target_transform,\n",
    "    'nodata': 0, 'compress': 'lzw'\n",
    "}\n",
    "with rasterio.open(corine_10m_path, 'w', **profile_10m) as dst:\n",
    "    dst.write(corine_10m, 1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. MASK TO HULL\n",
    "# -----------------------------------------------------------------------------\n",
    "corine_10m_masked = corine_10m.copy()\n",
    "corine_10m_masked[~hull_mask] = 0\n",
    "\n",
    "# Save final masked version\n",
    "corine_masked_path = RESULTS_DIR / \"corine_10m_masked.tif\"\n",
    "with rasterio.open(corine_masked_path, 'w', **profile_10m) as dst:\n",
    "    dst.write(corine_10m_masked, 1)\n",
    "\n",
    "# Update working array\n",
    "corine_10m = corine_10m_masked\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "unique_codes = np.unique(corine_10m[corine_10m > 0])\n",
    "print(f\"\\nCORINE Processing Complete:\")\n",
    "print(f\"  Original CRS: {corine_crs}\")\n",
    "print(f\"  Unique classes: {len(unique_codes)}\")\n",
    "print(f\"  Classes present: {sorted(unique_codes)}\")\n",
    "print(f\"  Final resolution: {GRID_SIZE}m\")\n",
    "print(f\"  Output path: {corine_masked_path}\")\n",
    "print(saocom_gdf)"
   ],
   "id": "aaf3725115ec5742",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SIMPLE SPATIAL OVERLAP VISUALIZATION",
   "id": "573965626fbb4f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# SIMPLE SPATIAL OVERLAP VISUALIZATION\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# 1. Plot original TINITALY DEM\n",
    "with rasterio.open(tinitaly_path) as src:\n",
    "    # Reproject to target CRS for comparison\n",
    "    from rasterio.warp import transform_bounds\n",
    "\n",
    "    # Get DEM bounds in target CRS\n",
    "    dem_bounds_target = transform_bounds(src.crs, TARGET_CRS, *src.bounds)\n",
    "\n",
    "    print(f\"TINITALY bounds (original CRS): {src.bounds}\")\n",
    "    print(f\"TINITALY bounds (UTM 32N): {dem_bounds_target}\")\n",
    "    print(f\"TINITALY CRS: {src.crs}\")\n",
    "\n",
    "    # Read a downsampled version for quick plotting\n",
    "    dem_data = src.read(1, out_shape=(\n",
    "        int(src.height / 10),\n",
    "        int(src.width / 10)\n",
    "    ))\n",
    "\n",
    "    # Plot DEM extent as a rectangle\n",
    "    from matplotlib.patches import Rectangle\n",
    "    dem_rect = Rectangle(\n",
    "        (dem_bounds_target[0], dem_bounds_target[1]),\n",
    "        dem_bounds_target[2] - dem_bounds_target[0],\n",
    "        dem_bounds_target[3] - dem_bounds_target[1],\n",
    "        linewidth=3, edgecolor='blue', facecolor='none',\n",
    "        label='TINITALY Extent'\n",
    "    )\n",
    "    ax.add_patch(dem_rect)\n",
    "\n",
    "# 2. Plot SAOCOM points\n",
    "saocom_gdf.plot(ax=ax, markersize=1, color='red', alpha=0.5, label='SAOCOM Points')\n",
    "\n",
    "# 3. Plot study area (convex hull)\n",
    "hull_gdf.boundary.plot(ax=ax, color='green', linewidth=2, linestyle='--', label='Study Area Hull')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "ax.set_title('Spatial Coverage: SAOCOM vs TINITALY DEM', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, color='gray')\n",
    "\n",
    "# Add text box with extents\n",
    "info_text = f\"\"\"SAOCOM Extent:\n",
    "X: [{saocom_gdf.geometry.x.min():.0f}, {saocom_gdf.geometry.x.max():.0f}]\n",
    "Y: [{saocom_gdf.geometry.y.min():.0f}, {saocom_gdf.geometry.y.max():.0f}]\n",
    "\n",
    "TINITALY Extent (UTM 32N):\n",
    "X: [{dem_bounds_target[0]:.0f}, {dem_bounds_target[2]:.0f}]\n",
    "Y: [{dem_bounds_target[1]:.0f}, {dem_bounds_target[3]:.0f}]\n",
    "\"\"\"\n",
    "ax.text(0.02, 0.98, info_text, transform=ax.transAxes,\n",
    "        fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"spatial_coverage.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# CHECK IF EXTENTS OVERLAP\n",
    "# =============================================================================\n",
    "print(\"\\n=== OVERLAP CHECK ===\")\n",
    "overlap_x = not (saocom_gdf.geometry.x.max() < dem_bounds_target[0] or\n",
    "                 saocom_gdf.geometry.x.min() > dem_bounds_target[2])\n",
    "overlap_y = not (saocom_gdf.geometry.y.max() < dem_bounds_target[1] or\n",
    "                 saocom_gdf.geometry.y.min() > dem_bounds_target[3])\n",
    "\n",
    "print(f\"X-axis overlap: {overlap_x}\")\n",
    "print(f\"Y-axis overlap: {overlap_y}\")\n",
    "print(f\"Full overlap: {overlap_x and overlap_y}\")\n",
    "\n",
    "if not (overlap_x and overlap_y):\n",
    "    print(\"\\n⚠️ NO OVERLAP DETECTED - SAOCOM data is outside TINITALY coverage!\")\n",
    "    print(\"You need a different TINITALY tile that covers this area.\")\n"
   ],
   "id": "64f7bca6720b4967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### COMPREHENSIVE REFERENCE DEM COMPARISON VISUALIZATION",
   "id": "b8f504554b1d9f36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE REFERENCE DEM COMPARISON VISUALIZATION\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(4, 2, figsize=(20, 28), facecolor='white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Plot 1: TINITALY elevation\n",
    "ax = axes[0, 0]\n",
    "ax.set_facecolor('white')\n",
    "tinitaly_display = np.ma.masked_where(tinitaly_data == NODATA, tinitaly_data)\n",
    "cmap1 = plt.cm.terrain.copy()\n",
    "cmap1.set_bad(color='white', alpha=0)\n",
    "im1 = ax.imshow(tinitaly_display, cmap=cmap1, origin='upper', extent=extent)\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title('TINITALY Elevation', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar1 = plt.colorbar(im1, ax=ax, label='Elevation (m)', shrink=0.8)\n",
    "cbar1.ax.yaxis.label.set_color('black')\n",
    "cbar1.ax.tick_params(colors='black')\n",
    "stats1 = f\"\"\"Min: {np.nanmin(tinitaly_display):.1f}m\n",
    "Max: {np.nanmax(tinitaly_display):.1f}m\n",
    "Mean: {np.nanmean(tinitaly_display):.1f}m\n",
    "Std: {np.nanstd(tinitaly_display):.1f}m\"\"\"\n",
    "ax.text(0.02, 0.98, stats1, transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Plot 2: Copernicus elevation\n",
    "ax = axes[0, 1]\n",
    "ax.set_facecolor('white')\n",
    "copernicus_display = np.ma.masked_where(copernicus_data == NODATA, copernicus_data)\n",
    "cmap2 = plt.cm.terrain.copy()\n",
    "cmap2.set_bad(color='white', alpha=0)\n",
    "im2 = ax.imshow(copernicus_display, cmap=cmap2, origin='upper', extent=extent)\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title('Copernicus Elevation', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar2 = plt.colorbar(im2, ax=ax, label='Elevation (m)', shrink=0.8)\n",
    "cbar2.ax.yaxis.label.set_color('black')\n",
    "cbar2.ax.tick_params(colors='black')\n",
    "stats2 = f\"\"\"Min: {np.nanmin(copernicus_display):.1f}m\n",
    "Max: {np.nanmax(copernicus_display):.1f}m\n",
    "Mean: {np.nanmean(copernicus_display):.1f}m\n",
    "Std: {np.nanstd(copernicus_display):.1f}m\"\"\"\n",
    "ax.text(0.02, 0.98, stats2, transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Plot 3: Difference map (full)\n",
    "ax = axes[1, 0]\n",
    "ax.set_facecolor('white')\n",
    "diff_display = np.ma.masked_where(~valid_mask, elevation_diff)\n",
    "diff_limit = np.percentile(np.abs(valid_diffs), 95)\n",
    "cmap3 = plt.cm.coolwarm.copy()\n",
    "cmap3.set_bad(color='white', alpha=0)\n",
    "im3 = ax.imshow(diff_display, cmap=cmap3, origin='upper', extent=extent,\n",
    "                vmin=-diff_limit, vmax=diff_limit)\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title(f'Elevation Difference\\n(TINITALY - Copernicus)', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar3 = plt.colorbar(im3, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "cbar3.ax.yaxis.label.set_color('black')\n",
    "cbar3.ax.tick_params(colors='black')\n",
    "stats3 = f\"\"\"Pixels: {valid_pixels:,}\n",
    "Mean: {ref_metrics['mean_diff']:+.2f}m\n",
    "RMSE: {ref_metrics['rmse']:.2f}m\n",
    "NMAD: {ref_metrics['nmad']:.2f}m\n",
    "MAE: {ref_metrics['mae']:.2f}m\n",
    "Std: {ref_metrics['std_diff']:.2f}m\n",
    "Corr: {ref_metrics['correlation']:.3f}\n",
    "Range: [{ref_metrics['min_diff']:.1f}, {ref_metrics['max_diff']:.1f}]m\"\"\"\n",
    "ax.text(0.02, 0.98, stats3, transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Plot 4: Statistics summary\n",
    "ax = axes[1, 1]\n",
    "ax.set_facecolor('white')\n",
    "le68 = np.percentile(np.abs(valid_diffs), 68.27)\n",
    "le90 = np.percentile(np.abs(valid_diffs), 90)\n",
    "le95 = np.percentile(np.abs(valid_diffs), 95)\n",
    "stats_text = f\"\"\"REFERENCE DEM COMPARISON\n",
    "\n",
    "Valid Pixels: {valid_pixels:,}\n",
    "\n",
    "CRITICAL METRICS:\n",
    "Mean Error (Bias): {ref_metrics['mean_diff']:+.2f} m\n",
    "RMSE: {ref_metrics['rmse']:.2f} m\n",
    "NMAD (robust): {ref_metrics['nmad']:.2f} m\n",
    "Std Deviation: {ref_metrics['std_diff']:.2f} m\n",
    "\n",
    "SECONDARY METRICS:\n",
    "MAE: {ref_metrics['mae']:.2f} m\n",
    "Correlation: {ref_metrics['correlation']:.4f}\n",
    "LE68: {le68:.2f} m\n",
    "LE90: {le90:.2f} m\n",
    "LE95: {le95:.2f} m\n",
    "Median: {ref_metrics['median_diff']:+.2f} m\n",
    "\n",
    "DIRECTIONAL BREAKDOWN:\n",
    "(Tolerance: ±{equal_tolerance:.2f} m)\n",
    "TINITALY Higher: {higher_pixels:,} ({pct_higher:.1f}%)\n",
    "Copernicus Higher: {lower_pixels:,} ({pct_lower:.1f}%)\n",
    "Roughly Equal: {equal_pixels:,} ({pct_equal:.1f}%)\n",
    "\n",
    "Range: {ref_metrics['min_diff']:+.1f} to {ref_metrics['max_diff']:+.1f} m\n",
    "\"\"\"\n",
    "ax.text(0.05, 0.5, stats_text, transform=ax.transAxes,\n",
    "        fontfamily='monospace', fontsize=9, verticalalignment='center', color='black')\n",
    "ax.axis('off')\n",
    "ax.set_title('Summary Statistics', fontweight='bold', fontsize=12, color='black')\n",
    "\n",
    "# Plot 5: Where TINITALY > Copernicus\n",
    "ax = axes[2, 0]\n",
    "ax.set_facecolor('white')\n",
    "cmap5 = plt.cm.YlOrRd.copy()\n",
    "cmap5.set_bad(color='white', alpha=0)\n",
    "im5 = ax.imshow(tinitaly_higher_data, cmap=cmap5, origin='upper', extent=extent,\n",
    "                vmin=0, vmax=np.nanmax(tinitaly_higher_data))\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title(f'TINITALY > Copernicus', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar5 = plt.colorbar(im5, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "cbar5.ax.yaxis.label.set_color('black')\n",
    "cbar5.ax.tick_params(colors='black')\n",
    "higher_vals = tinitaly_higher_data[~np.isnan(tinitaly_higher_data)]\n",
    "stats5 = f\"\"\"Pixels: {higher_pixels:,} ({pct_higher:.1f}%)\n",
    "Mean: {np.mean(higher_vals):.2f}m\n",
    "Std: {np.std(higher_vals):.2f}m\n",
    "RMSE: {np.sqrt(np.mean(higher_vals**2)):.2f}m\n",
    "Max: {np.max(higher_vals):.2f}m\"\"\"\n",
    "ax.text(0.02, 0.98, stats5, transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Plot 6: Where TINITALY < Copernicus\n",
    "ax = axes[2, 1]\n",
    "ax.set_facecolor('white')\n",
    "cmap6 = plt.cm.Blues_r.copy()\n",
    "cmap6.set_bad(color='white', alpha=0)\n",
    "im6 = ax.imshow(tinitaly_lower_data, cmap=cmap6, origin='upper', extent=extent,\n",
    "                vmin=np.nanmin(tinitaly_lower_data), vmax=0)\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title(f'Copernicus > TINITALY', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar6 = plt.colorbar(im6, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "cbar6.ax.yaxis.label.set_color('black')\n",
    "cbar6.ax.tick_params(colors='black')\n",
    "lower_vals = tinitaly_lower_data[~np.isnan(tinitaly_lower_data)]\n",
    "stats6 = f\"\"\"Pixels: {lower_pixels:,} ({pct_lower:.1f}%)\n",
    "Mean: {np.mean(lower_vals):.2f}m\n",
    "Std: {np.std(lower_vals):.2f}m\n",
    "RMSE: {np.sqrt(np.mean(lower_vals**2)):.2f}m\n",
    "Min: {np.min(lower_vals):.2f}m\"\"\"\n",
    "ax.text(0.02, 0.98, stats6, transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Plot 7: Where roughly equal\n",
    "ax = axes[3, 0]\n",
    "ax.set_facecolor('white')\n",
    "cmap7 = plt.cm.Greens.copy()\n",
    "cmap7.set_bad(color='white', alpha=0)\n",
    "im7 = ax.imshow(roughly_equal_data, cmap=cmap7, origin='upper', extent=extent,\n",
    "                vmin=-equal_tolerance, vmax=equal_tolerance)\n",
    "hull_gdf.boundary.plot(ax=ax, color='darkred', linewidth=2.5, label='Study Area')\n",
    "ax.set_title(f'Roughly Equal (±{equal_tolerance:.2f}m)', fontweight='bold', fontsize=12, color='black')\n",
    "ax.set_xlabel('UTM Easting (m)', color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', color='black')\n",
    "ax.grid(True, color='black', alpha=0.3, linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "cbar7 = plt.colorbar(im7, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "cbar7.ax.yaxis.label.set_color('black')\n",
    "cbar7.ax.tick_params(colors='black')\n",
    "equal_vals = roughly_equal_data[~np.isnan(roughly_equal_data)]\n",
    "stats7 = f\"\"\"Pixels: {equal_pixels:,} ({pct_equal:.1f}%)\n",
    "Mean: {np.mean(equal_vals):.2f}m\n",
    "Std: {np.std(equal_vals):.2f}m\n",
    "RMSE: {np.sqrt(np.mean(equal_vals**2)):.2f}m\n",
    "MAE: {np.mean(np.abs(equal_vals)):.2f}m\"\"\"\n",
    "ax.text(0.02, 0.98, stats7, transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# # Plot 8: Histogram of differences\n",
    "# ax = axes[3, 1]\n",
    "# ax.set_facecolor('white')\n",
    "# ax.hist(valid_diffs, bins=100, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "# ax.set_xlim(valid_diffs.min() * 1.05, valid_diffs.max() * 1.05)\n",
    "# ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "# ax.axvline(ref_metrics['mean_diff'], color='green', linestyle='-', linewidth=2,\n",
    "#            label=f'Mean: {ref_metrics[\"mean_diff\"]:+.2f}m')\n",
    "# ax.axvline(equal_tolerance, color='orange', linestyle='--', linewidth=1.5,\n",
    "#            label=f'±{equal_tolerance:.2f}m')\n",
    "# ax.axvline(-equal_tolerance, color='orange', linestyle='--', linewidth=1.5)\n",
    "# ax.set_xlabel('Elevation Difference (m)', color='black')\n",
    "# ax.set_ylabel('Frequency', color='black')\n",
    "# ax.set_title('Difference Distribution', fontweight='bold', fontsize=12, color='black')\n",
    "# ax.tick_params(colors='black')\n",
    "# ax.legend(loc='upper right', fontsize=9)\n",
    "# ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_edgecolor('black')\n",
    "# ax.set_yscale('log')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# Plot 8: Histogram of differences\n",
    "ax = axes[3, 1]\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Create histogram\n",
    "n, bins, patches = ax.hist(valid_diffs, bins=50, alpha=0.75,\n",
    "                           color='steelblue', edgecolor='black')\n",
    "\n",
    "# Add reference lines\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "ax.axvline(ref_metrics['mean_diff'], color='green', linestyle='-', linewidth=2,\n",
    "           label=f'Mean: {ref_metrics[\"mean_diff\"]:+.2f}m')\n",
    "ax.axvline(equal_tolerance, color='orange', linestyle='--', linewidth=1.5,\n",
    "           label=f'±NMAD: {equal_tolerance:.2f}m')\n",
    "ax.axvline(-equal_tolerance, color='orange', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# --- ADD STATISTICS BOX ---\n",
    "# Calculate the required statistics directly from the data\n",
    "stats_text = (f\"Mean = {valid_diffs.mean():+.2f} m\\n\"\n",
    "              f\"Std Dev = {valid_diffs.std():.2f} m\\n\"\n",
    "              f\"Min = {valid_diffs.min():.2f} m\\n\"\n",
    "              f\"Max = {valid_diffs.max():.2f} m\\n\"\n",
    "              f\"RMSE = {ref_metrics['rmse']:.2f} m\\n\"\n",
    "              f\"NMAD = {ref_metrics['nmad']:.2f} m\")\n",
    "\n",
    "# Place text box in the top-right corner\n",
    "ax.text(0.97, 0.97, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='black'))\n",
    "\n",
    "# --- SET AXIS LIMITS TO DATA EXTENT ---\n",
    "x_min = float(valid_diffs.min())\n",
    "x_max = float(valid_diffs.max())\n",
    "x_padding = (x_max - x_min) * 0.05 # Increased padding slightly\n",
    "ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "\n",
    "# --- LABELS AND STYLING ---\n",
    "ax.set_xlabel('Elevation Difference (m)', color='black', fontsize=11)\n",
    "ax.set_ylabel('Frequency', color='black', fontsize=11)\n",
    "ax.set_title('Difference Distribution', fontweight='bold', fontsize=12, color='black')\n",
    "ax.tick_params(colors='black')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARE DIFFERENCE DATA\n",
    "# =============================================================================\n",
    "# Calculate differences using calibrated SAOCOM heights\n",
    "saocom_gdf['diff_tinitaly'] = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']\n",
    "saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height']\n",
    "\n",
    "# Create coherence bins if not already present\n",
    "if 'coherence_bin' not in saocom_gdf.columns:\n",
    "    coherence_bins = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    coherence_labels = [f\"{coherence_bins[i]:.1f}-{coherence_bins[i+1]:.1f}\"\n",
    "                        for i in range(len(coherence_bins)-1)]\n",
    "    saocom_gdf['coherence_bin'] = pd.cut(saocom_gdf['COHER'],\n",
    "                                         bins=coherence_bins,\n",
    "                                         labels=coherence_labels,\n",
    "                                         include_lowest=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. BASIC VIOLIN PLOTS - ALL REFERENCE COMPARISONS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming saocom_gdf and RESULTS_DIR are defined\n",
    "# saocom_gdf = ...\n",
    "# RESULTS_DIR = ...\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8), facecolor='white')\n",
    "\n",
    "# Prepare data\n",
    "plot_data = pd.DataFrame({\n",
    "    'SAOCOM - TINITALY': saocom_gdf['diff_tinitaly'],\n",
    "    'SAOCOM - Copernicus': saocom_gdf['diff_copernicus']\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# FIX: Filter outliers from the data before plotting\n",
    "# =============================================================================\n",
    "# Calculate the 1st and 99th percentiles to define a reasonable range\n",
    "p01 = plot_data.quantile(0.01).min()\n",
    "p99 = plot_data.quantile(0.99).max()\n",
    "\n",
    "# Filter the data for plotting\n",
    "tinitaly_filtered = plot_data['SAOCOM - TINITALY'].dropna().clip(p01, p99)\n",
    "copernicus_filtered = plot_data['SAOCOM - Copernicus'].dropna().clip(p01, p99)\n",
    "# =============================================================================\n",
    "\n",
    "# Create violin plot with the FILTERED data\n",
    "parts = ax.violinplot([tinitaly_filtered, copernicus_filtered],\n",
    "                      positions=[1, 2],\n",
    "                      showmeans=True,\n",
    "                      showmedians=True,\n",
    "                      showextrema=True)\n",
    "\n",
    "# Color the violins\n",
    "colors = ['#4472C4', '#ED7D31']\n",
    "for pc, color in zip(parts['bodies'], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(0.7)\n",
    "    pc.set_edgecolor('black')\n",
    "\n",
    "# Style other elements\n",
    "for partname in ('cbars', 'cmins', 'cmaxes', 'cmedians', 'cmeans'):\n",
    "    if partname in parts:\n",
    "        parts[partname].set_edgecolor('black')\n",
    "        parts[partname].set_linewidth(1.5)\n",
    "\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Zero')\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['SAOCOM -\\nTINITALY', 'SAOCOM -\\nCopernicus'], fontsize=11)\n",
    "ax.set_ylabel('Elevation Difference (m)', fontsize=12)\n",
    "ax.set_title('Distribution of Elevation Differences (1st-99th Percentile)', fontweight='bold', fontsize=14)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Add statistics using the ORIGINAL (unfiltered) data for accuracy\n",
    "for i, col in enumerate(['SAOCOM - TINITALY', 'SAOCOM - Copernicus'], 1):\n",
    "    data = plot_data[col].dropna() # Using the original full dataset for stats\n",
    "    plot_max = locals()[f\"{col.split(' - ')[1].lower()}_filtered\"].max() # Get max from filtered data for text placement\n",
    "\n",
    "    stats_text = f\"n={len(data):,}\\nμ={data.mean():.2f}m\\nσ={data.std():.2f}m\"\n",
    "    ax.text(i, plot_max * 0.9, stats_text, ha='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(RESULTS_DIR / \"reference_dem_comparison_filtered.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. VIOLIN PLOTS BY COHERENCE BINS\n",
    "# =============================================================================\n",
    "# VIOLIN PLOTS BY COHERENCE BINS\n",
    "\n",
    "# =============================================================================\n",
    "# 4. SUMMARY STATISTICS TABLE\n",
    "# =============================================================================\n",
    "summary_stats = []\n",
    "\n",
    "for comparison in ['diff_tinitaly', 'diff_copernicus']:\n",
    "    data = saocom_gdf[comparison].dropna()\n",
    "    name = 'SAOCOM - TINITALY' if 'tinitaly' in comparison else 'SAOCOM - Copernicus'\n",
    "\n",
    "    summary_stats.append({\n",
    "        'Comparison': name,\n",
    "        'N Points': f\"{len(data):,}\",\n",
    "        'Mean': f\"{data.mean():+.2f} m\",\n",
    "        'Median': f\"{data.median():+.2f} m\",\n",
    "        'Std Dev': f\"{data.std():.2f} m\",\n",
    "        'RMSE': f\"{np.sqrt((data**2).mean()):.2f} m\",\n",
    "        'Range': f\"[{data.min():.1f}, {data.max():.1f}] m\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VIOLIN PLOT SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n"
   ],
   "id": "3f46f0c83d8ef692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SAOCOM HEIGHT RESIDUAL OUTLIER DETECTION AND VISUALIZATION",
   "id": "50c4fc0b43a1e4fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def score_outliers_isolation_forest(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    residual_col: str,\n",
    "    **kwargs\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Assigns an anomaly score to each point using the Isolation Forest algorithm.\n",
    "    This function is unchanged and remains the core of the detection process.\n",
    "\n",
    "    Args:\n",
    "        gdf (gpd.GeoDataFrame): The input GeoDataFrame.\n",
    "        residual_col (str): The name of the column containing the height residuals.\n",
    "        **kwargs: Additional keyword arguments to pass to the IsolationForest model.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: The original GeoDataFrame with a new 'outlier_score' column.\n",
    "    \"\"\"\n",
    "    if gdf.empty or residual_col not in gdf.columns:\n",
    "        print(\"Warning: Input GeoDataFrame is empty or residual column not found.\")\n",
    "        gdf['outlier_score'] = np.nan\n",
    "        return gdf\n",
    "\n",
    "    points_3d = np.c_[\n",
    "        gdf.geometry.x,\n",
    "        gdf.geometry.y,\n",
    "        gdf[residual_col].fillna(0)\n",
    "    ]\n",
    "    scaler = StandardScaler()\n",
    "    points_3d_scaled = scaler.fit_transform(points_3d)\n",
    "\n",
    "    model_params = {'n_estimators': 100, 'contamination': 'auto', 'random_state': 42, 'n_jobs': -1}\n",
    "    model_params.update(kwargs)\n",
    "\n",
    "    print(\"Fitting Isolation Forest model...\")\n",
    "    model = IsolationForest(**model_params)\n",
    "    model.fit(points_3d_scaled)\n",
    "\n",
    "    gdf_scored = gdf.copy()\n",
    "    gdf_scored['outlier_score'] = model.decision_function(points_3d_scaled)\n",
    "\n",
    "    print(\"Scoring complete. Added 'outlier_score' column.\")\n",
    "    return gdf_scored\n",
    "\n",
    "def filter_by_score_iqr(\n",
    "    gdf_scored: gpd.GeoDataFrame,\n",
    "    iqr_multiplier: float = 1\n",
    ") -> tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Filters a scored GeoDataFrame using a statistically-driven threshold.\n",
    "\n",
    "    This function calculates the outlier threshold by applying the IQR method\n",
    "    to the 'outlier_score' column itself. This removes the need for an\n",
    "    arbitrary percentage cutoff.\n",
    "\n",
    "    Args:\n",
    "        gdf_scored (gpd.GeoDataFrame): GeoDataFrame with an 'outlier_score' column.\n",
    "        iqr_multiplier (float): The multiplier for the IQR to define the cutoff.\n",
    "                                A standard value is 1.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the cleaned GeoDataFrame and the outlier GeoDataFrame.\n",
    "    \"\"\"\n",
    "    if 'outlier_score' not in gdf_scored.columns:\n",
    "        raise ValueError(\"Input GeoDataFrame must have an 'outlier_score' column.\")\n",
    "\n",
    "    scores = gdf_scored['outlier_score']\n",
    "    q1 = scores.quantile(0.25)\n",
    "    q3 = scores.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # The threshold is statistically determined from the distribution of scores\n",
    "    score_threshold = q1 - (iqr_multiplier * iqr)\n",
    "    print(score_threshold)\n",
    "    is_outlier_mask = scores < score_threshold\n",
    "\n",
    "    outliers = gdf_scored[is_outlier_mask].copy()\n",
    "    gdf_cleaned = gdf_scored[~is_outlier_mask].copy()\n",
    "\n",
    "    total_points, n_outliers = len(gdf_scored), len(outliers)\n",
    "    pct_outliers = (n_outliers / total_points) * 100 if total_points > 0 else 0\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Statistically-Driven Filtering (IQR on Anomaly Scores)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Score Q1: {q1:.4f}, Q3: {q3:.4f}, IQR: {iqr:.4f}\")\n",
    "    print(f\"IQR Multiplier: {iqr_multiplier}\")\n",
    "    print(f\"Calculated Score Threshold: < {score_threshold:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Total Points: {total_points:,}\")\n",
    "    print(f\"Outliers Removed: {n_outliers:,} ({pct_outliers:.2f}%)\")\n",
    "    print(f\"Remaining Points: {len(gdf_cleaned):,}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return gdf_cleaned, outliers\n",
    "\n",
    "def visualize_outlier_results(\n",
    "    gdf_original: gpd.GeoDataFrame,\n",
    "    gdf_cleaned: gpd.GeoDataFrame,\n",
    "    outliers: gpd.GeoDataFrame,\n",
    "    residual_col: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a two-panel plot to visualize the outlier removal results.\n",
    "    (This function is unchanged).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 9), facecolor='white', gridspec_kw={'width_ratios': [1.2, 1]})\n",
    "\n",
    "    # --- Panel 1: Spatial Distribution ---\n",
    "    ax1 = axes[0]\n",
    "    vmin, vmax = np.nanpercentile(gdf_cleaned[residual_col], [2, 98])\n",
    "\n",
    "    scatter = ax1.scatter(\n",
    "        gdf_cleaned.geometry.x, gdf_cleaned.geometry.y,\n",
    "        c=gdf_cleaned[residual_col], cmap='RdBu_r', s=5,\n",
    "        vmin=vmin, vmax=vmax, alpha=0.8, label='Cleaned Data'\n",
    "    )\n",
    "    plt.colorbar(scatter, ax=ax1, label=f'Residual ({residual_col}) (m)', shrink=0.7)\n",
    "\n",
    "    if not outliers.empty:\n",
    "        outliers.plot(ax=ax1, markersize=25, color='yellow',\n",
    "                      edgecolors='black', linewidth=0.8,\n",
    "                      label=f'Outliers (n={len(outliers):,})', zorder=5)\n",
    "\n",
    "    ax1.set_title('Spatial Distribution of Cleaned Data and Outliers', fontweight='bold')\n",
    "    ax1.set_xlabel('UTM Easting (m)')\n",
    "    ax1.set_ylabel('UTM Northing (m)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.4)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # --- Panel 2: Residual Distribution Histogram ---\n",
    "    ax2 = axes[1]\n",
    "    original_residuals = gdf_original[residual_col].dropna()\n",
    "    cleaned_residuals = gdf_cleaned[residual_col].dropna()\n",
    "\n",
    "    ax2.hist(original_residuals, bins=100, alpha=0.5, label=f'Before (n={len(original_residuals):,})', color='gray')\n",
    "    ax2.hist(cleaned_residuals, bins=50, alpha=1, label=f'After (n={len(cleaned_residuals):,})', color='#2E86AB')\n",
    "\n",
    "    ax2.set_title('Residual Distribution Before and After Cleaning', fontweight='bold')\n",
    "    ax2.set_xlabel(f'Residual ({residual_col}) (m)')\n",
    "    ax2.set_ylabel('Frequency (Log Scale)')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(RESULTS_DIR / \"difference_by_coherence.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# # =============================================================================\n",
    "# # EXAMPLE USAGE\n",
    "# # =============================================================================\n",
    "# if __name__ == '__main__':\n",
    "#     # 1. Create a sample GeoDataFrame for demonstration\n",
    "#     print(\"Creating sample GeoDataFrame for demonstration...\")\n",
    "#     np.random.seed(42)\n",
    "#     clean_points = np.random.rand(1000, 2) * 1000\n",
    "#     clean_residuals = np.random.normal(0, 2, 1000)\n",
    "#     outlier_points = np.array([[500, 500], [100, 900], [900, 100], [10, 10]])\n",
    "#     outlier_residuals = np.array([80, -65, 95, 5])\n",
    "#\n",
    "#     all_coords = np.vstack([clean_points, outlier_points])\n",
    "#     all_residuals = np.concatenate([clean_residuals, outlier_residuals])\n",
    "#     sample_gdf = gpd.GeoDataFrame(\n",
    "#         {'diff_tinitaly': all_residuals},\n",
    "#         geometry=[Point(x, y) for x, y in all_coords]\n",
    "#     )\n",
    "\n",
    "# --- Step 1: Score all the points ---\n",
    "print(len(saocom_gdf))\n",
    "saocom_gdf_scored = score_outliers_isolation_forest(saocom_gdf, 'diff_tinitaly')\n",
    "\n",
    "# --- Step 2: Filter using the STATISTICAL method ---\n",
    "# No more guessing a percentage! The function calculates the cutoff itself.\n",
    "saocom_gdf_cleaned, saocom_outliers = filter_by_score_iqr(saocom_gdf_scored)\n",
    "\n",
    "# --- Step 3: Visualize the results ---\n",
    "visualize_outlier_results(saocom_gdf, saocom_gdf_cleaned, saocom_outliers, 'diff_tinitaly')\n",
    "saocom_gdf = saocom_gdf_cleaned\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_height_statistics_summary(gdf, gdf_name=\"SAOCOM Data\"):\n",
    "    \"\"\"\n",
    "    Calculates and prints a comprehensive height statistics summary for a given\n",
    "    SAOCOM GeoDataFrame against the reference DEMs.\n",
    "\n",
    "    Args:\n",
    "        gdf (gpd.GeoDataFrame): The input GeoDataFrame containing SAOCOM points.\n",
    "                                Must include 'HEIGHT_RELATIVE', 'tinitaly_height',\n",
    "                                and 'copernicus_height' columns.\n",
    "        gdf_name (str): The name of the dataset for labeling the output.\n",
    "    \"\"\"\n",
    "    if not all(col in gdf.columns for col in ['HEIGHT_RELATIVE', 'tinitaly_height', 'copernicus_height']):\n",
    "        print(f\"Error: Input GeoDataFrame '{gdf_name}' is missing required height columns.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\"*95)\n",
    "    print(f\" STATISTICAL SUMMARY FOR: {gdf_name.upper()} ({len(gdf)} points)\")\n",
    "    print(\"=\"*95)\n",
    "\n",
    "    # =============================================================================\n",
    "    # HEIGHT STATISTICS COMPARISON\n",
    "    # =============================================================================\n",
    "    stats_list = []\n",
    "\n",
    "    # Function to calculate stats for a data series\n",
    "    def calculate_height_stats(data, name):\n",
    "        valid_data = data.dropna()\n",
    "        if len(valid_data) == 0: return None\n",
    "        return {\n",
    "            'Dataset': name,\n",
    "            'Count': len(valid_data), 'Min': np.min(valid_data),\n",
    "            'Max': np.max(valid_data), 'Mean': np.mean(valid_data),\n",
    "            'Median': np.median(valid_data), 'Std Dev': np.std(valid_data),\n",
    "            'Q25': np.percentile(valid_data, 25), 'Q75': np.percentile(valid_data, 75)\n",
    "        }\n",
    "\n",
    "    # Add stats for the input GDF\n",
    "    stats_list.append(calculate_height_stats(gdf['HEIGHT_RELATIVE'], f'{gdf_name} (Relative)'))\n",
    "    stats_list.append(calculate_height_stats(gdf['tinitaly_height'], f'TINITALY (at {gdf_name} pts)'))\n",
    "    stats_list.append(calculate_height_stats(gdf['copernicus_height'], f'Copernicus (at {gdf_name} pts)'))\n",
    "\n",
    "    # Create and display DataFrame\n",
    "    stats_df = pd.DataFrame([s for s in stats_list if s is not None])\n",
    "    print(\"\\nHEIGHT STATISTICS SUMMARY (all values in meters)\")\n",
    "    print(\"-\"*95)\n",
    "    print(stats_df.to_string(index=False, float_format=lambda x: f'{x:.2f}'))\n",
    "    print(\"-\"*95)\n",
    "\n",
    "\n",
    "    # =============================================================================\n",
    "    # DIFFERENCE STATISTICS (SAOCOM - REFERENCE)\n",
    "    # =============================================================================\n",
    "    print(\"\\nDIFFERENCE STATISTICS (SAOCOM Relative - Reference DEM):\")\n",
    "    print(\"-\"*95)\n",
    "\n",
    "    # SAOCOM - TINITALY\n",
    "    diff_tin_valid = (gdf['HEIGHT_RELATIVE'] - gdf['tinitaly_height']).dropna()\n",
    "    print(f\"\\n{gdf_name} - TINITALY:\")\n",
    "    print(f\"  Mean difference: {diff_tin_valid.mean():+.3f} m\")\n",
    "    print(f\"  Median difference: {diff_tin_valid.median():+.3f} m\")\n",
    "    print(f\"  Std deviation: {diff_tin_valid.std():.3f} m\")\n",
    "    print(f\"  RMSE: {np.sqrt((diff_tin_valid**2).mean()):.3f} m\")\n",
    "\n",
    "    # SAOCOM - Copernicus\n",
    "    diff_cop_valid = (gdf['HEIGHT_RELATIVE'] - gdf['copernicus_height']).dropna()\n",
    "    print(f\"\\n{gdf_name} - Copernicus:\")\n",
    "    print(f\"  Mean difference: {diff_cop_valid.mean():+.3f} m\")\n",
    "    print(f\"  Median difference: {diff_cop_valid.median():+.3f} m\")\n",
    "    print(f\"  Std deviation: {diff_cop_valid.std():.3f} m\")\n",
    "    print(f\"  RMSE: {np.sqrt((diff_cop_valid**2).mean()):.3f} m\")\n",
    "    print(\"=\"*95)\n",
    "\n",
    "# Run the summary for the main cleaned dataframe\n",
    "generate_height_statistics_summary(saocom_gdf_cleaned, gdf_name=\"SAOCOM Cleaned\")\n",
    "\n",
    "# Run the summary for the outliers that were removed\n",
    "generate_height_statistics_summary(saocom_outliers, gdf_name=\"SAOCOM Outliers\")\n",
    "\n",
    "# You can also run it on the original, unfiltered dataframe for comparison\n",
    "# generate_height_statistics_summary(saocom_gdf, gdf_name=\"SAOCOM Original\")\n"
   ],
   "id": "a3428b4a90d0d43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. SPATIAL SAMPLE CORINE LAND COVER AT SAOCOM POINTS",
   "id": "b82cd7f2ce2fd9f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# PRE-REQUISITE: CALCULATE HEIGHT RESIDUALS\n",
    "# (This step was missing/unexecuted from the previous cell sequence)\n",
    "# =============================================================================\n",
    "# Residual = Calibrated SAOCOM Height - Reference DEM Height\n",
    "saocom_gdf['diff_tinitaly'] = saocom_gdf['HEIGHT_ABSOLUTE_TIN'] - saocom_gdf['tinitaly_height']\n",
    "# saocom_gdf['diff_copernicus'] = saocom_gdf['HEIGHT_ABSOLUTE_COP'] - saocom_gdf['copernicus_height'] # Not needed for this table\n",
    "\n",
    "# =============================================================================\n",
    "# 1. SPATIAL SAMPLE CORINE LAND COVER AT SAOCOM POINTS\n",
    "# =============================================================================\n",
    "# The corine_10m raster is already loaded, reprojected, and masked (Cell 202).\n",
    "\n",
    "corine_codes = []\n",
    "# Assuming the global variables target_transform, grid_height, grid_width, corine_10m, and NODATA are defined in previous cells\n",
    "for idx, row in saocom_gdf.iterrows():\n",
    "    # Use the same transform and grid dimensions as defined in Cell 200\n",
    "    row_idx, col_idx = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "\n",
    "    if 0 <= row_idx < grid_height and 0 <= col_idx < grid_width:\n",
    "        code = corine_10m[row_idx, col_idx]\n",
    "        # Skip NoData/Masked value (255)\n",
    "        corine_codes.append(code if code != 255 else 0)\n",
    "    else:\n",
    "        corine_codes.append(0) # 0 represents NoData/outside study area\n",
    "\n",
    "saocom_gdf['corine_code'] = corine_codes\n",
    "\n",
    "# Filter out points outside the valid CORINE area (where code is 0)\n",
    "saocom_lc_analysis = saocom_gdf[saocom_gdf['corine_code'] != 0].copy()\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CALCULATE ROBUST STATISTICS BY LAND COVER CLASS\n",
    "# =============================================================================\n",
    "\n",
    "def nmad(data):\n",
    "    \"\"\"Normalized Median Absolute Deviation (robust measure of spread)\"\"\"\n",
    "    return 1.4826 * np.median(np.abs(data - np.median(data)))\n",
    "\n",
    "# Calculate stats for the recommended residual: SAOCOM (calibrated to TINITALY) - TINITALY DEM\n",
    "lc_height_stats = saocom_lc_analysis.groupby('corine_code')['diff_tinitaly'].agg([\n",
    "    'count',\n",
    "    'median',\n",
    "    'mean',\n",
    "    'std',\n",
    "    nmad\n",
    "]).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "lc_height_stats.rename(columns={\n",
    "    'count': 'N_Points',\n",
    "    'median': 'Median_Diff_m',\n",
    "    'mean': 'Mean_Diff_m',\n",
    "    'std': 'Std_Dev_m',\n",
    "    'nmad': 'NMAD_m'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add land cover label for interpretability\n",
    "lc_height_stats['LC_Label'] = lc_height_stats['corine_code'].map(CORINE_CLASSES)\n",
    "\n",
    "# Reorder and filter for classes with enough samples (N > 50)\n",
    "MIN_SAMPLES = 50\n",
    "lc_height_stats_filtered = lc_height_stats[lc_height_stats['N_Points'] >= MIN_SAMPLES]\n",
    "lc_height_stats_filtered = lc_height_stats_filtered.sort_values('LC_Label', ascending=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DISPLAY RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"HEIGHT RESIDUAL STATISTICS by CORINE Land Cover (N > {MIN_SAMPLES})\")\n",
    "print(\"(Residual = Calibrated SAOCOM Height - TINITALY Reference DEM)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "display_cols = ['corine_code', 'LC_Label', 'N_Points', 'Median_Diff_m', 'NMAD_m', 'Mean_Diff_m', 'Std_Dev_m']\n",
    "\n",
    "# Print the filtered, robustly sorted table\n",
    "print(lc_height_stats_filtered[display_cols].to_string(\n",
    "    index=False,\n",
    "    float_format=lambda x: f'{x:+.2f}' if 'Diff' in lc_height_stats_filtered.columns.tolist() else f'{x:.2f}', # Generic float formatting\n",
    "    formatters={'N_Points': '{:,}'.format,\n",
    "                'Median_Diff_m': '{:+.2f} m'.format,\n",
    "                'NMAD_m': '{:.2f} m'.format,\n",
    "                'Mean_Diff_m': '{:+.2f} m'.format,\n",
    "                'Std_Dev_m': '{:.2f} m'.format}\n",
    "))\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Store the filtered results for later use in plotting/reporting\n",
    "lc_height_stats_final = lc_height_stats_filtered.copy()\n",
    "\n",
    "# =============================================================================\n",
    "# 1. SETUP AND DEFINITIONS (from previous cells)\n",
    "# =============================================================================\n",
    "# Global variables assumed defined:\n",
    "# corine_10m (masked CLC raster), study_area_mask (valid area inside hull),\n",
    "# saocom_coverage (boolean array: True where SAOCOM data exists),\n",
    "# void_mask (study_area_mask & ~saocom_coverage), GRID_SIZE (10m)\n",
    "# CORINE_CLASSES (LC code lookup)\n",
    "\n",
    "# Recalculate global void stats for context\n",
    "n_total_cells = np.sum(study_area_mask)\n",
    "n_void_cells = np.sum(void_mask)\n",
    "void_percentage_global = 100 * n_void_cells / n_total_cells if n_total_cells > 0 else 0\n",
    "\n",
    "# Get unique, valid CORINE codes within the study area\n",
    "unique_lc_codes = np.unique(corine_10m[study_area_mask])\n",
    "unique_lc_codes = unique_lc_codes[unique_lc_codes != 0] # Filter out 0/NoData\n",
    "\n",
    "# =============================================================================\n",
    "# 2. VOID ANALYSIS BY LAND COVER CLASS\n",
    "# =============================================================================\n",
    "void_stats_by_lc = []\n",
    "cell_area_km2 = (GRID_SIZE / 1000.0) ** 2 # 0.0001 km^2\n",
    "\n",
    "for lc_code in unique_lc_codes:\n",
    "    # Mask for this land cover class within the study area\n",
    "    lc_mask = study_area_mask & (corine_10m == lc_code)\n",
    "\n",
    "    # Total cells of this land cover\n",
    "    total_lc_cells = np.sum(lc_mask)\n",
    "\n",
    "    if total_lc_cells == 0:\n",
    "        continue\n",
    "\n",
    "    # Void cells within this land cover\n",
    "    void_lc_cells = np.sum(lc_mask & void_mask)\n",
    "\n",
    "    # METRIC 1: What % of this land cover is void? (Key Metric for coverage performance)\n",
    "    pct_of_lc_that_is_void = 100 * void_lc_cells / total_lc_cells\n",
    "\n",
    "    # METRIC 2: What % of total voids is this land cover? (Key Metric for contribution)\n",
    "    pct_of_total_voids = 100 * void_lc_cells / n_void_cells if n_void_cells > 0 else 0\n",
    "\n",
    "    void_stats_by_lc.append({\n",
    "        'corine_code': lc_code,\n",
    "        'label': CORINE_CLASSES.get(lc_code, f'Unknown_{lc_code}'),\n",
    "        'total_cells': total_lc_cells,\n",
    "        'void_cells': void_lc_cells,\n",
    "        'Area_km2': total_lc_cells * cell_area_km2,\n",
    "        'Pct_LC_is_Void': pct_of_lc_that_is_void,\n",
    "        'Pct_of_Total_Voids': pct_of_total_voids,\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "void_stats_df = pd.DataFrame(void_stats_by_lc)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DISPLAY RESULTS\n",
    "# =============================================================================\n",
    "# Filter for significant land cover classes (e.g., > 1 km2 area)\n",
    "MIN_AREA_KM2 = 1.0\n",
    "void_stats_filtered = void_stats_df[void_stats_df['Area_km2'] >= MIN_AREA_KM2].copy()\n",
    "\n",
    "# Sort by the primary metric: Percentage of the LC class that is void\n",
    "void_stats_filtered = void_stats_filtered.sort_values('Pct_LC_is_Void', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(f\"VOID ANALYSIS by CORINE Land Cover (Area > {MIN_AREA_KM2:.1f} km²)\")\n",
    "print(f\"Overall Void Percentage (Study Area): {void_percentage_global:.2f}%\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "display_cols = ['corine_code', 'label', 'Area_km2', 'void_cells', 'Pct_LC_is_Void', 'Pct_of_Total_Voids']\n",
    "\n",
    "# Print the filtered table\n",
    "print(void_stats_filtered[display_cols].to_string(\n",
    "    index=False,\n",
    "    float_format=lambda x: f'{x:.2f}',\n",
    "    formatters={'Area_km2': '{:.1f} km²'.format,\n",
    "                'void_cells': '{:,}'.format,\n",
    "                'Pct_LC_is_Void': '{:.2f} %'.format,\n",
    "                'Pct_of_Total_Voids': '{:.2f} %'.format}\n",
    "))\n",
    "\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Store the filtered results for later use in plotting/reporting\n",
    "lc_void_stats_final = void_stats_filtered.copy()"
   ],
   "id": "706690cf955e34aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  1. PREPARE DATA FOR PLOTTING",
   "id": "e4a7facf951d0d07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARE DATA FOR PLOTTING\n",
    "# =============================================================================\n",
    "# Use the full saocom_lc_analysis DataFrame which contains both the residuals\n",
    "# ('diff_tinitaly') and the sampled land cover codes ('corine_code').\n",
    "\n",
    "# Define major land cover groups for better visualization (CLC Level 1)\n",
    "def get_clc_level1(code):\n",
    "    \"\"\"Maps CLC Level 3 code to Level 1 category\"\"\"\n",
    "    if 100 <= code < 200: return '1. Artificial Surfaces'\n",
    "    if 200 <= code < 300: return '2. Agricultural Areas'\n",
    "    if 300 <= code < 400: return '3. Forest & Semi-Natural Areas'\n",
    "    if 400 <= code < 500: return '4. Wetlands'\n",
    "    if 500 <= code < 600: return '5. Water Bodies'\n",
    "    return 'Other'\n",
    "\n",
    "# Add Level 1 categories to the analysis DataFrame\n",
    "saocom_lc_analysis['LC_Level_1'] = saocom_lc_analysis['corine_code'].apply(get_clc_level1)\n",
    "saocom_lc_analysis['LC_Label'] = saocom_lc_analysis['corine_code'].map(CORINE_CLASSES)\n",
    "\n",
    "# Filter for the most common Level 3 classes (using the N_Points filter from Step 1)\n",
    "common_codes = lc_height_stats_final['corine_code'].unique()\n",
    "plot_df_L3 = saocom_lc_analysis[saocom_lc_analysis['corine_code'].isin(common_codes)].copy()\n",
    "\n",
    "# Filter extreme outliers for better plot scaling (e.g., 99th percentile)\n",
    "q_low = plot_df_L3['diff_tinitaly'].quantile(0.005)\n",
    "q_high = plot_df_L3['diff_tinitaly'].quantile(0.995)\n",
    "plot_df_L3_filtered = plot_df_L3[(plot_df_L3['diff_tinitaly'] >= q_low) &\n",
    "                                (plot_df_L3['diff_tinitaly'] <= q_high)]\n",
    "\n",
    "# Sort the categories by the NMAD metric (best to worst performance)\n",
    "nmad_order = lc_height_stats_final.sort_values('LC_Label', ascending=False)['LC_Label'].tolist()\n",
    "plot_df_L3_filtered['LC_Label'] = pd.Categorical(\n",
    "    plot_df_L3_filtered['LC_Label'],\n",
    "    categories=nmad_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "q_low = plot_df_L3['diff_copernicus'].quantile(0.005)\n",
    "q_high = plot_df_L3['diff_copernicus'].quantile(0.995)\n",
    "plot_df_cop_filtered = plot_df_L3[(plot_df_L3['diff_copernicus'] >= q_low) &\n",
    "                                (plot_df_L3['diff_copernicus'] <= q_high)]\n",
    "\n",
    "# Sort the categories by the NMAD metric (best to worst performance)\n",
    "nmad_order = lc_height_stats_final.sort_values('LC_Label', ascending=False)['LC_Label'].tolist()\n",
    "plot_df_cop_filtered['LC_Label'] = pd.Categorical(\n",
    "    plot_df_cop_filtered['LC_Label'],\n",
    "    categories=nmad_order,\n",
    "    ordered=True\n",
    ")\n"
   ],
   "id": "1d88b2f34cd41e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SENTINEL-2 RGB PREPARATION",
   "id": "f692fa9c5f4dc233"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# SENTINEL-2 RGB PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "# File discovery\n",
    "sentinel_files = list((DATA_DIR / \"sentinel_data\").glob(\"*.tif\"))\n",
    "if not sentinel_files:\n",
    "    raise FileNotFoundError(\"No Sentinel files found in sentinel_data directory\")\n",
    "\n",
    "# Load Sentinel bands (assuming separate R, G, B files or multi-band)\n",
    "with rasterio.open(sentinel_files[0]) as src:\n",
    "    sentinel_count = src.count\n",
    "\n",
    "    if sentinel_count >= 3:\n",
    "        # Multi-band file - read RGB bands\n",
    "        sentinel_r = src.read(1)  # Band 1 (Red)\n",
    "        sentinel_g = src.read(2)  # Band 2 (Green)\n",
    "        sentinel_b = src.read(3)  # Band 3 (Blue)\n",
    "        sentinel_transform_orig = src.transform\n",
    "        sentinel_crs = src.crs\n",
    "    else:\n",
    "        # Single band files - need to find R, G, B separately\n",
    "        r_file = next((f for f in sentinel_files if 'B04' in f.name or 'red' in f.name.lower()), None)\n",
    "        g_file = next((f for f in sentinel_files if 'B03' in f.name or 'green' in f.name.lower()), None)\n",
    "        b_file = next((f for f in sentinel_files if 'B02' in f.name or 'blue' in f.name.lower()), None)\n",
    "\n",
    "        if not all([r_file, g_file, b_file]):\n",
    "            raise FileNotFoundError(\"Could not find RGB bands in Sentinel files\")\n",
    "\n",
    "        with rasterio.open(r_file) as r_src:\n",
    "            sentinel_r = r_src.read(1)\n",
    "            sentinel_transform_orig = r_src.transform\n",
    "            sentinel_crs = r_src.crs\n",
    "        with rasterio.open(g_file) as g_src:\n",
    "            sentinel_g = g_src.read(1)\n",
    "        with rasterio.open(b_file) as b_src:\n",
    "            sentinel_b = b_src.read(1)\n",
    "\n",
    "# Resample each band to 10m grid\n",
    "sentinel_r_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "sentinel_g_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "sentinel_b_10m = np.zeros((grid_height, grid_width), dtype=np.float32)\n",
    "\n",
    "for band_src, band_dst in [(sentinel_r, sentinel_r_10m),\n",
    "                            (sentinel_g, sentinel_g_10m),\n",
    "                            (sentinel_b, sentinel_b_10m)]:\n",
    "    reproject(\n",
    "        source=band_src,\n",
    "        destination=band_dst,\n",
    "        src_transform=sentinel_transform_orig,\n",
    "        src_crs=sentinel_crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=TARGET_CRS,\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "# Stack into RGB array\n",
    "sentinel_rgb = np.stack([sentinel_r_10m, sentinel_g_10m, sentinel_b_10m], axis=2)\n",
    "\n",
    "# Mask to study area\n",
    "sentinel_rgb[~hull_mask] = 0\n",
    "\n",
    "# Normalize to 0-1 for display (using 2-98 percentile stretch for contrast)\n",
    "sentinel_rgb_norm = np.zeros_like(sentinel_rgb, dtype=np.float32)\n",
    "for i in range(3):\n",
    "    band = sentinel_rgb[:, :, i]\n",
    "    valid_pixels = band[hull_mask]\n",
    "\n",
    "    if len(valid_pixels) > 0:\n",
    "        p2, p98 = np.percentile(valid_pixels[valid_pixels > 0], [2, 98])\n",
    "        band_norm = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "        sentinel_rgb_norm[:, :, i] = band_norm\n",
    "\n",
    "print(f\"\\nSentinel-2 RGB Prepared:\")\n",
    "print(f\"  Shape: {sentinel_rgb_norm.shape}\")\n",
    "print(f\"  Resolution: {GRID_SIZE}m\")\n",
    "print(f\"  Value range: [{sentinel_rgb_norm.min():.3f}, {sentinel_rgb_norm.max():.3f}]\")"
   ],
   "id": "c603c5472a10e4a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. GENERATE VIOLIN PLOT (Level 3 - Detailed Performance)",
   "id": "9fed879e4544c721"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# 1. GENERATE STATS WITHIN THE PLOT SCRIPT\n",
    "# =============================================================================\n",
    "print(\"Generating statistics just-in-time for the plot...\")\n",
    "\n",
    "def calculate_nmad(series):\n",
    "    \"\"\"Calculates the Normalized Median Absolute Deviation (NMAD).\"\"\"\n",
    "    return (series - series.median()).abs().median() * 1.4826\n",
    "\n",
    "# Create a new, temporary stats DataFrame by grouping the plotting data\n",
    "stats_for_plot = plot_df_L3_filtered.groupby('LC_Label')['diff_tinitaly'].agg(\n",
    "    Median_Diff_m='median',\n",
    "    NMAD_m=calculate_nmad,\n",
    "    Std_Dev_m='std',\n",
    "    Min_Diff_m='min',\n",
    "    Max_Diff_m='max'\n",
    ").reset_index()\n",
    "\n",
    "# Determine the plotting order based on the NMAD we just calculated\n",
    "nmad_order = stats_for_plot.sort_values('NMAD_m')['LC_Label'].tolist()\n",
    "\n",
    "# Define an anchor point for the text annotations\n",
    "q_high = plot_df_L3_filtered['diff_tinitaly'].quantile(0.99) + 5\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. GENERATE VIOLIN PLOT (Level 3 - Detailed Performance)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(16, 9), facecolor='white')\n",
    "\n",
    "# Use violin plot, ordering it with the 'nmad_order' list we just created\n",
    "sns.violinplot(\n",
    "    x='diff_tinitaly',\n",
    "    y='LC_Label',\n",
    "    data=plot_df_L3_filtered,\n",
    "    order=nmad_order,  # Use the calculated order here\n",
    "    inner='quartile',\n",
    "    palette='Spectral_r',\n",
    "    orient='h',\n",
    "    linewidth=1.0,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Add a vertical line at zero error\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Distribution of SAOCOM Height Residuals by Land Cover (CLC Level 3)', fontweight='bold', fontsize=18)\n",
    "plt.xlabel('Height Residual (Calibrated SAOCOM - TINITALY DEM) [m]', fontsize=14)\n",
    "plt.ylabel('CORINE Land Cover Class (Ordered by NMAD)', fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# --- Add Annotations using the stats we just generated ---\n",
    "for i, label in enumerate(nmad_order):\n",
    "    # Query the 'stats_for_plot' DataFrame we created above\n",
    "    stats = stats_for_plot.query(\"LC_Label == @label\").iloc[0]\n",
    "\n",
    "    stats_text = (\n",
    "        f\"Median: {stats['Median_Diff_m']:+.2f} m\\n\"\n",
    "        f\"NMAD: {stats['NMAD_m']:.2f} m\\n\"\n",
    "        f\"Std Dev: {stats['Std_Dev_m']:.2f} m\\n\"\n",
    "        f\"Min/Max: [{stats['Min_Diff_m']:.1f}, {stats['Max_Diff_m']:.1f}] m\"\n",
    "    )\n",
    "\n",
    "    plt.text(q_high, i, stats_text,\n",
    "             verticalalignment='center',\n",
    "             horizontalalignment='left',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8)\n",
    "            )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.8, 1])\n",
    "plt.show()\n",
    "print(\"Violin Plot for Level 3 Land Cover classes generated successfully.\")\n",
    "# Add this line to save the figure\n",
    "plt.savefig(RESULTS_DIR / 'saocom_tinitaly_residuals_by_landcover.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# COPERNICUS STATISTICS AND VIOLIN PLOT (Level 3)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Generating statistics for Copernicus plot...\")\n",
    "\n",
    "def calculate_nmad(series):\n",
    "    \"\"\"Calculates the Normalized Median Absolute Deviation (NMAD).\"\"\"\n",
    "    return (series - series.median()).abs().median() * 1.4826\n",
    "\n",
    "# Create a new stats DataFrame by grouping the filtered Copernicus plotting data\n",
    "stats_for_cop_plot = plot_df_cop_filtered.groupby('LC_Label')['diff_copernicus'].agg(\n",
    "    Median_Diff_m='median',\n",
    "    NMAD_m=calculate_nmad,\n",
    "    Std_Dev_m='std',\n",
    "    Min_Diff_m='min',\n",
    "    Max_Diff_m='max'\n",
    ").reset_index()\n",
    "\n",
    "# Determine the plotting order based on the NMAD we just calculated\n",
    "nmad_order_cop = stats_for_cop_plot.sort_values('NMAD_m')['LC_Label'].tolist()\n",
    "\n",
    "# Define an anchor point for the text annotations\n",
    "q_high_cop = plot_df_cop_filtered['diff_copernicus'].quantile(0.995) + 5\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. GENERATE COPERNICUS VIOLIN PLOT (Level 3)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(16, 9), facecolor='white')\n",
    "\n",
    "# Generate the violin plot, ordering it with the 'nmad_order_cop' list\n",
    "sns.violinplot(\n",
    "    x='diff_copernicus',\n",
    "    y='LC_Label',\n",
    "    data=plot_df_cop_filtered,\n",
    "    order=nmad_order_cop,  # Use the calculated order here\n",
    "    inner='quartile',\n",
    "    palette='Spectral_r',\n",
    "    orient='h',\n",
    "    linewidth=1.0,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Add a vertical line at zero error\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Distribution of SAOCOM Height Residuals by Land Cover (vs. Copernicus)', fontweight='bold', fontsize=18)\n",
    "plt.xlabel('Height Residual (Calibrated SAOCOM - Copernicus DEM) [m]', fontsize=14)\n",
    "plt.ylabel('CORINE Land Cover Class (Ordered by NMAD)', fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# --- Add Annotations using the stats we just generated ---\n",
    "for i, label in enumerate(nmad_order_cop):\n",
    "    # Query the 'stats_for_cop_plot' DataFrame\n",
    "    stats = stats_for_cop_plot.query(\"LC_Label == @label\").iloc[0]\n",
    "\n",
    "    stats_text = (\n",
    "        f\"Median: {stats['Median_Diff_m']:+.2f} m\\n\"\n",
    "        f\"NMAD: {stats['NMAD_m']:.2f} m\\n\"\n",
    "        f\"Std Dev: {stats['Std_Dev_m']:.2f} m\\n\"\n",
    "        f\"Min/Max: [{stats['Min_Diff_m']:.1f}, {stats['Max_Diff_m']:.1f}] m\"\n",
    "    )\n",
    "\n",
    "    plt.text(q_high_cop, i, stats_text,\n",
    "             verticalalignment='center',\n",
    "             horizontalalignment='left',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8)\n",
    "            )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.8, 1])\n",
    "plt.show()\n",
    "print(\"Violin Plot for Copernicus comparison generated successfully.\")\n",
    "# Add this line to save the figure\n",
    "plt.savefig(RESULTS_DIR / 'saocom_copernicus_residuals_by_landcover.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "# =============================================================================\n",
    "# 3. GENERATE BOX PLOT (Level 1 - Broad Comparison)\n",
    "# =============================================================================\n",
    "plt.figure(figsize=(10, 6), facecolor='white')\n",
    "\n",
    "# Use box plot for a cleaner Level 1 aggregation\n",
    "sns.boxplot(\n",
    "    x='LC_Level_1',\n",
    "    y='diff_tinitaly',\n",
    "    data=plot_df_L3_filtered,\n",
    "    palette='Set2',\n",
    "    linewidth=1.0,\n",
    "    showfliers=False # Do not show outliers already filtered\n",
    ")\n",
    "\n",
    "# Add a horizontal line at zero error\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\n",
    "    'SAOCOM Height Residuals by Land Cover (CLC Level 1)',\n",
    "    fontweight='bold',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.xlabel('CORINE Land Cover Category (Level 1)', fontsize=11)\n",
    "plt.ylabel('Height Residual (m)', fontsize=11)\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Box Plot for Level 1 Land Cover categories generated successfully.\")\n",
    "\n",
    "# =============================================================================\n",
    "# CORINE LAND COVER VISUALIZATION\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(figsize=(14, 10), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Get extent\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Mask NoData/zero values for transparency\n",
    "corine_display = np.ma.masked_where((corine_10m == 0) | (corine_10m == 255), corine_10m)\n",
    "\n",
    "# Get unique classes in study area\n",
    "unique_codes = np.unique(corine_display.compressed())\n",
    "\n",
    "# Create colormap for present classes only\n",
    "colors_list = [CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5)) for code in unique_codes]\n",
    "cmap = ListedColormap(colors_list)\n",
    "norm = BoundaryNorm(boundaries=np.append(unique_codes, unique_codes[-1]+1) - 0.5,\n",
    "                    ncolors=len(unique_codes))\n",
    "\n",
    "# Plot CORINE\n",
    "im = ax.imshow(corine_display, cmap=cmap, norm=norm, origin='upper', extent=extent)\n",
    "\n",
    "# Add study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2, label='Study Area')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=14, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=14, color='black')\n",
    "ax.set_title('CORINE Land Cover 2018', fontweight='bold', fontsize=18, color='black')\n",
    "ax.tick_params(colors='black', labelsize=12)\n",
    "ax.grid(True, alpha=0.3, linewidth=0.5, color='black')\n",
    "\n",
    "# Create legend with only present classes\n",
    "legend_elements = [plt.Rectangle((0,0),1,1, facecolor=CORINE_COLORS_MPL[code],\n",
    "                                 edgecolor='black', linewidth=0.5,\n",
    "                                 label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\")\n",
    "                   for code in sorted(unique_codes)]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          fontsize=13, frameon=True, fancybox=False, edgecolor='black')\n",
    "\n",
    "# Add scale bar\n",
    "scalebar = ScaleBar(1, location='lower right', box_alpha=0.8, color='black')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Add statistics box\n",
    "total_area_km2 = np.sum(study_area_mask) * 0.0001\n",
    "stats_text = f\"Study Area: {total_area_km2:.2f} km²\\nClasses: {len(unique_codes)}\"\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=12,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "        alpha=0.9, edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCORINE Land Cover Map:\")\n",
    "print(f\"  Total classes present: {len(unique_codes)}\")\n",
    "print(f\"  Study area: {total_area_km2:.2f} km²\")\n",
    "## =============================================================================\n",
    "# SAOCOM HEIGHT RESIDUALS - INTERPOLATED HEAT MAPS\n",
    "# =============================================================================\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 10), facecolor='white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Filter valid points\n",
    "valid_tin = saocom_gdf[saocom_gdf['diff_tinitaly'].notna()].copy()\n",
    "valid_cop = saocom_gdf[saocom_gdf['diff_copernicus'].notna()].copy()\n",
    "\n",
    "# Calculate symmetric color limits (95th percentile)\n",
    "tin_limit = np.percentile(np.abs(valid_tin['diff_tinitaly']), 95)\n",
    "cop_limit = np.percentile(np.abs(valid_cop['diff_copernicus']), 95)\n",
    "common_limit = max(tin_limit, cop_limit)\n",
    "\n",
    "# Create interpolation grid (matching the 10m grid)\n",
    "xi = np.linspace(xmin_grid, xmax_grid, grid_width)\n",
    "yi = np.linspace(ymax_grid, ymin_grid, grid_height)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "# =============================================================================\n",
    "# Plot 1: SAOCOM - TINITALY Heat Map\n",
    "# =============================================================================\n",
    "ax = axes[0]\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Background: Sentinel RGB (very faint)\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.2)\n",
    "\n",
    "# Extract coordinates and values\n",
    "x_tin = valid_tin.geometry.x.values\n",
    "y_tin = valid_tin.geometry.y.values\n",
    "z_tin = valid_tin['diff_tinitaly'].values\n",
    "\n",
    "# Interpolate to grid using cubic method\n",
    "print(\"Interpolating TINITALY differences...\")\n",
    "zi_tin = griddata((x_tin, y_tin), z_tin, (xi_grid, yi_grid),\n",
    "                  method='cubic', fill_value=np.nan)\n",
    "\n",
    "# Apply Gaussian smoothing for smoother heat map\n",
    "zi_tin_smooth = gaussian_filter(np.nan_to_num(zi_tin, nan=0), sigma=2)\n",
    "zi_tin_smooth[~hull_mask] = np.nan  # Mask to study area\n",
    "\n",
    "# Plot heat map\n",
    "im1 = ax.imshow(zi_tin_smooth, extent=extent, origin='upper',\n",
    "                cmap='RdBu_r', alpha=0.8,\n",
    "                vmin=-common_limit, vmax=common_limit,\n",
    "                interpolation='bilinear')\n",
    "\n",
    "# Overlay original points (small, for reference)\n",
    "ax.scatter(x_tin, y_tin, c=z_tin, cmap='RdBu_r',\n",
    "           s=0.5, alpha=0.3, edgecolors='none',\n",
    "           vmin=-common_limit, vmax=common_limit)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Colorbar\n",
    "cbar1 = plt.colorbar(im1, ax=ax, label='Height Difference (m)',\n",
    "                     shrink=0.8, pad=0.02)\n",
    "cbar1.ax.tick_params(labelsize=10, colors='black')\n",
    "cbar1.ax.yaxis.label.set_color('black')\n",
    "\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "ax.set_title('SAOCOM - TINITALY\\nInterpolated Height Residual Heat Map',\n",
    "             fontweight='bold', fontsize=14, color='black')\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "\n",
    "# Statistics box\n",
    "stats_text = f\"\"\"Points: {len(valid_tin):,}\n",
    "Mean: {valid_tin['diff_tinitaly'].mean():+.2f} m\n",
    "Median: {valid_tin['diff_tinitaly'].median():+.2f} m\n",
    "RMSE: {np.sqrt((valid_tin['diff_tinitaly']**2).mean()):.2f} m\n",
    "NMAD: {1.4826 * np.median(np.abs(valid_tin['diff_tinitaly'] - valid_tin['diff_tinitaly'].median())):.2f} m\n",
    "Std: {valid_tin['diff_tinitaly'].std():.2f} m\n",
    "\n",
    "Interpolation: Cubic + Gaussian\n",
    "Color Scale: ±{common_limit:.1f} m\n",
    "Red = SAOCOM Higher\n",
    "Blue = TINITALY Higher\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9,\n",
    "                 edgecolor='black'))\n",
    "\n",
    "# =============================================================================\n",
    "# Plot 2: SAOCOM - Copernicus Heat Map\n",
    "# =============================================================================\n",
    "ax = axes[1]\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Background: Sentinel RGB (very faint)\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.2)\n",
    "\n",
    "# Extract coordinates and values\n",
    "x_cop = valid_cop.geometry.x.values\n",
    "y_cop = valid_cop.geometry.y.values\n",
    "z_cop = valid_cop['diff_copernicus'].values\n",
    "\n",
    "# Interpolate to grid using cubic method\n",
    "print(\"Interpolating Copernicus differences...\")\n",
    "zi_cop = griddata((x_cop, y_cop), z_cop, (xi_grid, yi_grid),\n",
    "                  method='cubic', fill_value=np.nan)\n",
    "\n",
    "# Apply Gaussian smoothing\n",
    "zi_cop_smooth = gaussian_filter(np.nan_to_num(zi_cop, nan=0), sigma=2)\n",
    "zi_cop_smooth[~hull_mask] = np.nan  # Mask to study area\n",
    "\n",
    "# Plot heat map\n",
    "im2 = ax.imshow(zi_cop_smooth, extent=extent, origin='upper',\n",
    "                cmap='RdBu_r', alpha=0.8,\n",
    "                vmin=-common_limit, vmax=common_limit,\n",
    "                interpolation='bilinear')\n",
    "\n",
    "# Overlay original points (small, for reference)\n",
    "ax.scatter(x_cop, y_cop, c=z_cop, cmap='RdBu_r',\n",
    "           s=0.5, alpha=0.3, edgecolors='none',\n",
    "           vmin=-common_limit, vmax=common_limit)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Colorbar\n",
    "cbar2 = plt.colorbar(im2, ax=ax, label='Height Difference (m)',\n",
    "                     shrink=0.8, pad=0.02)\n",
    "cbar2.ax.tick_params(labelsize=10, colors='black')\n",
    "cbar2.ax.yaxis.label.set_color('black')\n",
    "\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "ax.set_title('SAOCOM - Copernicus\\nInterpolated Height Residual Heat Map',\n",
    "             fontweight='bold', fontsize=14, color='black')\n",
    "ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "ax.tick_params(colors='black')\n",
    "\n",
    "# Statistics box\n",
    "stats_text = f\"\"\"Points: {len(valid_cop):,}\n",
    "Mean: {valid_cop['diff_copernicus'].mean():+.2f} m\n",
    "Median: {valid_cop['diff_copernicus'].median():+.2f} m\n",
    "RMSE: {np.sqrt((valid_cop['diff_copernicus']**2).mean()):.2f} m\n",
    "NMAD: {1.4826 * np.median(np.abs(valid_cop['diff_copernicus'] - valid_cop['diff_copernicus'].median())):.2f} m\n",
    "Std: {valid_cop['diff_copernicus'].std():.2f} m\n",
    "\n",
    "Interpolation: Cubic + Gaussian\n",
    "Color Scale: ±{common_limit:.1f} m\n",
    "Red = SAOCOM Higher\n",
    "Blue = Copernicus Higher\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9,\n",
    "                 edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'saocom_residual_heatmaps_interpolated.png',\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved: saocom_residual_heatmaps_interpolated.png\")\n",
    "print(f\"Interpolation method: Cubic spline + Gaussian smoothing (sigma=2)\")\n",
    "print(f\"Color scale range: ±{common_limit:.2f} m\")\n",
    "\n"
   ],
   "id": "b889084bf560beb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Class Overlays Basic\n",
   "id": "a3baa4dd4b2b89f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### INDIVIDUAL CLASS OVERLAY MAPS (COLORBLIND-FRIENDLY)",
   "id": "616b3bb301efccf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# INDIVIDUAL CLASS OVERLAY MAPS (COLORBLIND-FRIENDLY)\n",
    "# =============================================================================\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Get unique classes present in data\n",
    "unique_classes = np.unique(corine_10m[corine_10m > 0])\n",
    "\n",
    "# Create one map per class\n",
    "for lc_code in sorted(unique_classes):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Display Sentinel RGB as background\n",
    "    ax.imshow(sentinel_rgb_norm, extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid],\n",
    "              origin='upper', alpha=0.7)  # Slight transparency to help overlay show\n",
    "\n",
    "    # Get color for this land cover class\n",
    "    fill_color = tuple(c/255 for c in CORINE_COLORS.get(lc_code, (128, 128, 128)))\n",
    "\n",
    "    # Create mask for this land cover class\n",
    "    lc_mask = (corine_10m == lc_code)\n",
    "\n",
    "    # Vectorize to get boundaries\n",
    "    mask_shapes = shapes(lc_mask.astype(np.uint8), mask=lc_mask, transform=target_transform)\n",
    "\n",
    "    # Convert to polygons and plot\n",
    "    polys = [shape(geom) for geom, val in mask_shapes if val == 1]\n",
    "\n",
    "    if polys:\n",
    "        for poly in polys:\n",
    "            if poly.is_valid:\n",
    "                x, y = poly.exterior.xy\n",
    "\n",
    "                # Fill with class-specific color + hatching for visibility\n",
    "                ax.fill(x, y, color=fill_color, alpha=0.4,\n",
    "                       edgecolor='none', hatch='///', linewidth=0)\n",
    "\n",
    "                # Bold black outline for definition\n",
    "                ax.plot(x, y, color='black', linewidth=2.5, alpha=0.9)\n",
    "\n",
    "                # Colored inner outline\n",
    "                ax.plot(x, y, color=fill_color, linewidth=1.5, alpha=1.0)\n",
    "\n",
    "    # Add study area boundary\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=3, linestyle='--', alpha=0.8)\n",
    "    hull_gdf.boundary.plot(ax=ax, color='red', linewidth=1.5, linestyle='--', alpha=1.0)\n",
    "\n",
    "    # Calculate statistics\n",
    "    lc_count = np.sum(lc_mask)\n",
    "    area_km2 = lc_count * (GRID_SIZE**2) / 1e6\n",
    "    pct_area = 100 * lc_count / np.sum(corine_10m > 0)\n",
    "\n",
    "    # Title with statistics\n",
    "    class_name = CORINE_CLASSES.get(lc_code, f'Class {lc_code}')\n",
    "    ax.set_title(f'Land Cover: {class_name}\\n'\n",
    "                 f'Code {lc_code} | Area: {area_km2:.1f} km² ({pct_area:.1f}%)',\n",
    "                 fontweight='bold', fontsize=13, pad=15)\n",
    "\n",
    "    ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "    ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "\n",
    "    # Legend with hatching\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=fill_color, edgecolor='black', linewidth=2,\n",
    "              alpha=0.4, hatch='///', label=class_name),\n",
    "        Patch(facecolor='none', edgecolor='red', linestyle='--',\n",
    "              linewidth=2, label='Study Area')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10,\n",
    "              frameon=True, fancybox=False, edgecolor='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    safe_name = class_name.replace(' ', '_').replace(',', '').replace('/', '_')\n",
    "    filename = f'landcover_{lc_code}_{safe_name}.png'\n",
    "    plt.savefig(RESULTS_DIR / filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(unique_classes)} individual land cover overlay maps\")"
   ],
   "id": "4df0f162885db27d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SAOCOM VS TINITALY COMPARISON",
   "id": "2c164913486822f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# SAOCOM VS TINITALY COMPARISON\n",
    "# =============================================================================\n",
    "# Filter for valid comparisons with elevation range check\n",
    "valid_elevation_range = (50, 850)\n",
    "\n",
    "saocom_tinitaly_mask = (\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()) &\n",
    "    (saocom_gdf['tinitaly_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'] >= valid_elevation_range[0]) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_TIN'] <= valid_elevation_range[1]) &\n",
    "    (saocom_gdf['COHER'] >= 0.5)\n",
    ")\n",
    "saocom_tinitaly_valid = saocom_gdf[saocom_tinitaly_mask]\n",
    "\n",
    "saocom_tinitaly_diff = (saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'] -\n",
    "                        saocom_tinitaly_valid['tinitaly_height']).values\n",
    "\n",
    "saocom_tinitaly_metrics = {\n",
    "    'n_points': int(len(saocom_tinitaly_diff)),\n",
    "    'mean_diff': float(np.mean(saocom_tinitaly_diff)),\n",
    "    'median_diff': float(np.median(saocom_tinitaly_diff)),\n",
    "    'std_diff': float(np.std(saocom_tinitaly_diff)),\n",
    "    'rmse': float(np.sqrt(np.mean(saocom_tinitaly_diff**2))),\n",
    "    'mae': float(np.mean(np.abs(saocom_tinitaly_diff))),\n",
    "    'nmad': float(1.4826 * np.median(np.abs(saocom_tinitaly_diff - np.median(saocom_tinitaly_diff)))),\n",
    "    'min_diff': float(np.min(saocom_tinitaly_diff)),\n",
    "    'max_diff': float(np.max(saocom_tinitaly_diff)),\n",
    "    'correlation': float(np.corrcoef(saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'].values,\n",
    "                                     saocom_tinitaly_valid['tinitaly_height'].values)[0, 1])\n",
    "}\n",
    "\n",
    "saocom_tinitaly_tolerance = float(saocom_tinitaly_metrics['nmad'])\n",
    "saocom_tinitaly_higher_mask = saocom_tinitaly_diff > saocom_tinitaly_tolerance\n",
    "saocom_tinitaly_lower_mask = saocom_tinitaly_diff < -saocom_tinitaly_tolerance\n",
    "saocom_tinitaly_equal_mask = np.abs(saocom_tinitaly_diff) <= saocom_tinitaly_tolerance\n",
    "\n",
    "saocom_tinitaly_higher_count = np.sum(saocom_tinitaly_higher_mask)\n",
    "saocom_tinitaly_lower_count = np.sum(saocom_tinitaly_lower_mask)\n",
    "saocom_tinitaly_equal_count = np.sum(saocom_tinitaly_equal_mask)\n",
    "\n",
    "saocom_tinitaly_pct_higher = 100 * saocom_tinitaly_higher_count / len(saocom_tinitaly_diff)\n",
    "saocom_tinitaly_pct_lower = 100 * saocom_tinitaly_lower_count / len(saocom_tinitaly_diff)\n",
    "saocom_tinitaly_pct_equal = 100 * saocom_tinitaly_equal_count / len(saocom_tinitaly_diff)\n",
    "\n",
    "# =============================================================================\n",
    "# SAOCOM VS COPERNICUS COMPARISON\n",
    "# =============================================================================\n",
    "saocom_copernicus_mask = (\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'].notna()) &\n",
    "    (saocom_gdf['copernicus_height'].notna()) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'] >= valid_elevation_range[0]) &\n",
    "    (saocom_gdf['HEIGHT_ABSOLUTE_COP'] <= valid_elevation_range[1]) &\n",
    "    (saocom_gdf['COHER'] >= 0.5)\n",
    ")\n",
    "saocom_copernicus_valid = saocom_gdf[saocom_copernicus_mask]\n",
    "\n",
    "saocom_copernicus_diff = (saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'] -\n",
    "                          saocom_copernicus_valid['copernicus_height']).values\n",
    "\n",
    "saocom_copernicus_metrics = {\n",
    "    'n_points': int(len(saocom_copernicus_diff)),\n",
    "    'mean_diff': float(np.mean(saocom_copernicus_diff)),\n",
    "    'median_diff': float(np.median(saocom_copernicus_diff)),\n",
    "    'std_diff': float(np.std(saocom_copernicus_diff)),\n",
    "    'rmse': float(np.sqrt(np.mean(saocom_copernicus_diff**2))),\n",
    "    'mae': float(np.mean(np.abs(saocom_copernicus_diff))),\n",
    "    'nmad': float(1.4826 * np.median(np.abs(saocom_copernicus_diff - np.median(saocom_copernicus_diff)))),\n",
    "    'min_diff': float(np.min(saocom_copernicus_diff)),\n",
    "    'max_diff': float(np.max(saocom_copernicus_diff)),\n",
    "    'correlation': float(np.corrcoef(saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'].values,\n",
    "                                     saocom_copernicus_valid['copernicus_height'].values)[0, 1])\n",
    "}\n",
    "\n",
    "saocom_copernicus_tolerance = float(saocom_copernicus_metrics['nmad'])\n",
    "saocom_copernicus_higher_mask = saocom_copernicus_diff > saocom_copernicus_tolerance\n",
    "saocom_copernicus_lower_mask = saocom_copernicus_diff < -saocom_copernicus_tolerance\n",
    "saocom_copernicus_equal_mask = np.abs(saocom_copernicus_diff) <= saocom_copernicus_tolerance\n",
    "\n",
    "saocom_copernicus_higher_count = int(np.sum(saocom_copernicus_higher_mask))\n",
    "saocom_copernicus_lower_count = int(np.sum(saocom_copernicus_lower_mask))\n",
    "saocom_copernicus_equal_count = int(np.sum(saocom_copernicus_equal_mask))\n",
    "\n",
    "saocom_copernicus_pct_higher = float(100 * saocom_copernicus_higher_count / len(saocom_copernicus_diff))\n",
    "saocom_copernicus_pct_lower = float(100 * saocom_copernicus_lower_count / len(saocom_copernicus_diff))\n",
    "saocom_copernicus_pct_equal = float(100 * saocom_copernicus_equal_count / len(saocom_copernicus_diff))\n",
    "\n"
   ],
   "id": "3590ef9aef1cf80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculate slope from TINITALY DEM",
   "id": "8824d5029d8f4434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # REPLACE the old outlier detection section with:\n",
    "# # (The Isolation Forest code becomes the primary outlier detection)\n",
    "# #\n",
    "# # Update variable names for consistency:\n",
    "# normal_points = saocom_gdf_cleaned  # Previously defined differently\n",
    "# outlier_points = saocom_outliers    # Previously defined differently\n",
    "#\n",
    "# # Remove/comment out the old IQR-based outlier detection that created:\n",
    "# # - outliers_iqr\n",
    "# # - outliers_zscore\n",
    "# # - outliers_nmad\n",
    "# # - is_outlier (based on voting)\n",
    "#\n",
    "# # Update all downstream references:\n",
    "# n_outliers = len(saocom_outliers)  # Use this consistently\n",
    "# pct_outliers = (n_outliers / len(saocom_gdf_scored)) * 100\n",
    "# # =============================================================================\n",
    "# # TOPOGRAPHIC ANALYSIS OF OUTLIERS\n",
    "# # =============================================================================\n",
    "# from scipy.ndimage import sobel\n",
    "#\n",
    "# def calculate_slope(dem, grid_size=10):\n",
    "#     \"\"\"Calculate slope in degrees\"\"\"\n",
    "#     dx = sobel(dem, axis=1) / (8 * grid_size)\n",
    "#     dy = sobel(dem, axis=0) / (8 * grid_size)\n",
    "#     slope = np.degrees(np.arctan(np.sqrt(dx**2 + dy**2)))\n",
    "#     slope[dem == NODATA] = np.nan\n",
    "#     return slope\n",
    "#\n",
    "# # Calculate slope\n",
    "# slope_grid = calculate_slope(tinitaly_10m, GRID_SIZE)\n",
    "#\n",
    "# # Sample terrain at point locations\n",
    "# def sample_terrain(gdf, slope_grid, dem):\n",
    "#     \"\"\"Sample slope and elevation at point locations\"\"\"\n",
    "#     slopes, elevs = [], []\n",
    "#     for _, row in gdf.iterrows():\n",
    "#         r, c = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "#         if 0 <= r < grid_height and 0 <= c < grid_width:\n",
    "#             slopes.append(slope_grid[r, c] if not np.isnan(slope_grid[r, c]) else np.nan)\n",
    "#             elevs.append(dem[r, c] if dem[r, c] != NODATA else np.nan)\n",
    "#         else:\n",
    "#             slopes.append(np.nan)\n",
    "#             elevs.append(np.nan)\n",
    "#     return slopes, elevs\n",
    "#\n",
    "# # Sample outliers\n",
    "# outlier_slopes, outlier_elevs = sample_terrain(saocom_outliers, slope_grid, tinitaly_10m)\n",
    "# saocom_outliers['slope'] = outlier_slopes\n",
    "# saocom_outliers['elevation'] = outlier_elevs\n",
    "#\n",
    "# # Sample normal points\n",
    "# normal_sample = saocom_gdf.sample(n=min(5000, len(saocom_gdf)), random_state=42)\n",
    "# normal_slopes, normal_elevs = sample_terrain(normal_sample, slope_grid, tinitaly_10m)\n",
    "# normal_sample['slope'] = normal_slopes\n",
    "# normal_sample['elevation'] = normal_elevs\n",
    "#\n",
    "# # Visualization\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(18, 16), facecolor='white')\n",
    "#\n",
    "# # Slope map\n",
    "# ax = axes[0, 0]\n",
    "# im = ax.imshow(np.ma.masked_invalid(slope_grid), cmap='terrain', origin='upper',\n",
    "#                extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid], vmin=0, vmax=45)\n",
    "# saocom_outliers.plot(ax=ax, markersize=15, color='red', edgecolors='black', linewidth=0.5)\n",
    "# plt.colorbar(im, ax=ax, label='Slope (°)')\n",
    "# ax.set_title('Terrain Slope with Outliers', fontweight='bold')\n",
    "# ax.set_xlabel('UTM Easting (m)')\n",
    "# ax.set_ylabel('UTM Northing (m)')\n",
    "#\n",
    "# # Residual vs Slope\n",
    "# ax = axes[0, 1]\n",
    "# ax.scatter(normal_sample['slope'], np.abs(normal_sample['diff_tinitaly']),\n",
    "#            s=5, alpha=0.3, c='steelblue', label='Normal')\n",
    "# ax.scatter(saocom_outliers['slope'], np.abs(saocom_outliers['diff_tinitaly']),\n",
    "#            s=30, alpha=0.7, c='red', edgecolors='black', linewidth=0.5, label='Outliers')\n",
    "# ax.set_xlabel('Slope (°)')\n",
    "# ax.set_ylabel('|Residual| (m)')\n",
    "# ax.set_title('Residual vs Slope', fontweight='bold')\n",
    "# ax.legend()\n",
    "# ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Residual vs Elevation\n",
    "# ax = axes[1, 0]\n",
    "# ax.scatter(normal_sample['elevation'], np.abs(normal_sample['diff_tinitaly']),\n",
    "#            s=5, alpha=0.3, c='steelblue', label='Normal')\n",
    "# ax.scatter(saocom_outliers['elevation'], np.abs(saocom_outliers['diff_tinitaly']),\n",
    "#            s=30, alpha=0.7, c='red', edgecolors='black', linewidth=0.5, label='Outliers')\n",
    "# ax.set_xlabel('Elevation (m)')\n",
    "# ax.set_ylabel('|Residual| (m)')\n",
    "# ax.set_title('Residual vs Elevation', fontweight='bold')\n",
    "# ax.legend()\n",
    "# ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Statistics\n",
    "# ax = axes[1, 1]\n",
    "# ax.axis('off')\n",
    "#\n",
    "# outlier_stats = saocom_outliers[['slope', 'elevation']].describe()\n",
    "# normal_stats = normal_sample[['slope', 'elevation']].describe()\n",
    "#\n",
    "# stats_text = f\"\"\"TOPOGRAPHIC ANALYSIS\n",
    "#\n",
    "# OUTLIERS (n={len(saocom_outliers):,}):\n",
    "# Slope: {outlier_stats.loc['mean', 'slope']:.1f}° ± {outlier_stats.loc['std', 'slope']:.1f}°\n",
    "# Elevation: {outlier_stats.loc['mean', 'elevation']:.1f} ± {outlier_stats.loc['std', 'elevation']:.1f} m\n",
    "#\n",
    "# NORMAL (n={len(normal_sample):,}):\n",
    "# Slope: {normal_stats.loc['mean', 'slope']:.1f}° ± {normal_stats.loc['std', 'slope']:.1f}°\n",
    "# Elevation: {normal_stats.loc['mean', 'elevation']:.1f} ± {normal_stats.loc['std', 'elevation']:.1f} m\n",
    "#\n",
    "# DIFFERENCE:\n",
    "# Slope: {outlier_stats.loc['mean', 'slope'] - normal_stats.loc['mean', 'slope']:+.1f}°\n",
    "# Elevation: {outlier_stats.loc['mean', 'elevation'] - normal_stats.loc['mean', 'elevation']:+.1f} m\"\"\"\n",
    "#\n",
    "# ax.text(0.1, 0.5, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#         verticalalignment='center', fontfamily='monospace',\n",
    "#         bbox=dict(boxstyle='round', facecolor='white', edgecolor='black'))\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'outliers_vs_topography.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ],
   "id": "ee2500213b7766db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    ### 3d model\n",
   "id": "4f0559fad1cd3db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Use the cleaned dataset and outliers from Isolation Forest\n",
    "normal_sample_3d = saocom_gdf.sample(n=min(5000, len(saocom_gdf)), random_state=42)\n",
    "outlier_sample_3d = saocom_outliers.sample(n=min(500, len(saocom_outliers)), random_state=42) if len(saocom_outliers) > 0 else saocom_outliers\n",
    "\n",
    "# Create SAOCOM interpolated surface\n",
    "saocom_valid = saocom_gdf[saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()].copy()\n",
    "x_saocom = saocom_valid.geometry.x.values\n",
    "y_saocom = saocom_valid.geometry.y.values\n",
    "z_saocom = saocom_valid['HEIGHT_ABSOLUTE_TIN'].values\n",
    "\n",
    "# Create grid for surface\n",
    "xi = np.linspace(xmin_grid, xmax_grid, 100)\n",
    "yi = np.linspace(ymin_grid, ymax_grid, 100)\n",
    "xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "\n",
    "# Interpolate SAOCOM surface\n",
    "zi_saocom = griddata((x_saocom, y_saocom), z_saocom, (xi_grid, yi_grid),\n",
    "                     method='linear', fill_value=np.nan)\n",
    "\n",
    "# Downsample TINITALY surface\n",
    "tinitaly_downsampled = tinitaly_10m[::10, ::10]\n",
    "x_tin = np.linspace(xmin_grid, xmax_grid, tinitaly_downsampled.shape[1])\n",
    "y_tin = np.linspace(ymax_grid, ymin_grid, tinitaly_downsampled.shape[0])\n",
    "x_tin_grid, y_tin_grid = np.meshgrid(x_tin, y_tin)\n",
    "tinitaly_downsampled = np.where(tinitaly_downsampled == NODATA, np.nan, tinitaly_downsampled)\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# TINITALY Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_tin_grid, y=y_tin_grid, z=tinitaly_downsampled,\n",
    "    colorscale='Earth', name='TINITALY DEM', showscale=True,\n",
    "    colorbar=dict(x=1.15, title='Elevation (m)'),\n",
    "    visible=True, opacity=0.8,\n",
    "    hovertemplate='X: %{x:.0f}<br>Y: %{y:.0f}<br>TINITALY: %{z:.1f}m<extra></extra>'\n",
    "))\n",
    "\n",
    "# SAOCOM Interpolated Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=xi_grid, y=yi_grid, z=zi_saocom,\n",
    "    colorscale='Viridis', name='SAOCOM Surface',\n",
    "    showscale=False, visible=False, opacity=0.7,\n",
    "    hovertemplate='X: %{x:.0f}<br>Y: %{y:.0f}<br>SAOCOM: %{z:.1f}m<extra></extra>'\n",
    "))\n",
    "\n",
    "# Normal SAOCOM Points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=normal_sample_3d.geometry.x, y=normal_sample_3d.geometry.y,\n",
    "    z=normal_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "    mode='markers', name='SAOCOM Points',\n",
    "    marker=dict(size=2, color=normal_sample_3d['diff_tinitaly'],\n",
    "                colorscale='RdBu_r', cmin=-10, cmax=10,\n",
    "                colorbar=dict(x=1.0, title='Residual (m)', len=0.5, y=0.25),\n",
    "                showscale=True, line=dict(width=0)),\n",
    "    text=[f\"Residual: {r:+.2f}m<br>Height: {h:.1f}m<br>Coherence: {c:.2f}\"\n",
    "          for r, h, c in zip(normal_sample_3d['diff_tinitaly'],\n",
    "                            normal_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "                            normal_sample_3d['COHER'])],\n",
    "    hovertemplate='%{text}<extra></extra>', visible=True\n",
    "))\n",
    "\n",
    "# Outlier Points\n",
    "if len(outlier_sample_3d) > 0:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=outlier_sample_3d.geometry.x, y=outlier_sample_3d.geometry.y,\n",
    "        z=outlier_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "        mode='markers', name='Outliers',\n",
    "        marker=dict(size=6, color='red', symbol='diamond',\n",
    "                   line=dict(color='black', width=1)),\n",
    "        text=[f\"<b>OUTLIER</b><br>Residual: {r:+.2f}m<br>Height: {h:.1f}m<br>Coherence: {c:.2f}\"\n",
    "              for r, h, c in zip(outlier_sample_3d['diff_tinitaly'],\n",
    "                                outlier_sample_3d['HEIGHT_ABSOLUTE_TIN'],\n",
    "                                outlier_sample_3d['COHER'])],\n",
    "        hovertemplate='%{text}<extra></extra>', visible=True\n",
    "    ))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(type=\"buttons\", direction=\"down\", x=0.02, xanchor=\"left\",\n",
    "             y=0.98, yanchor=\"top\",\n",
    "             buttons=[\n",
    "                 dict(label=\"All\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, True, True, True]}]),\n",
    "                 dict(label=\"Surfaces Only\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, True, False, False]}]),\n",
    "                 dict(label=\"Points Only\", method=\"update\",\n",
    "                      args=[{\"visible\": [False, False, True, True]}]),\n",
    "                 dict(label=\"TINITALY + Points\", method=\"update\",\n",
    "                      args=[{\"visible\": [True, False, True, True]}]),\n",
    "                 dict(label=\"SAOCOM Surface + Outliers\", method=\"update\",\n",
    "                      args=[{\"visible\": [False, True, False, True]}]),\n",
    "             ]),\n",
    "        dict(type=\"buttons\", direction=\"right\", x=0.02, xanchor=\"left\",\n",
    "             y=0.02, yanchor=\"bottom\",\n",
    "             buttons=[\n",
    "                 dict(label=\"Toggle TINITALY\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [0]]),\n",
    "                 dict(label=\"Toggle SAOCOM Surface\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [1]]),\n",
    "                 dict(label=\"Toggle Points\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [2]]),\n",
    "                 dict(label=\"Toggle Outliers\", method=\"restyle\",\n",
    "                      args=[\"visible\", \"toggle\"], args2=[{\"visible\": [True]}, [3]]),\n",
    "             ])\n",
    "    ],\n",
    "    scene=dict(xaxis_title='UTM Easting (m)', yaxis_title='UTM Northing (m)',\n",
    "               zaxis_title='Elevation (m)', aspectmode='manual',\n",
    "               aspectratio=dict(x=1, y=1, z=0.3),\n",
    "               camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))),\n",
    "    title=dict(text='3D SAOCOM vs TINITALY Analysis<br><sub>Top: Presets | Bottom: Toggle layers</sub>',\n",
    "               x=0.5, xanchor='center'),\n",
    "    width=1400, height=900, showlegend=True,\n",
    "    legend=dict(x=0.02, y=0.5),\n",
    "    paper_bgcolor='white', plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.write_html(RESULTS_DIR / 'saocom_3d_interactive.html')\n",
    "print(f\"Saved: {RESULTS_DIR / 'saocom_3d_interactive.html'}\")\n",
    "fig.show()"
   ],
   "id": "da913839ec3aed88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SAOCOM RESIDUAL OUTLIERS - KERNEL DENSITY HEAT MAP (ArcGIS-style)",
   "id": "824729e264d13e80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # =============================================================================\n",
    "# # SAOCOM RESIDUAL OUTLIERS - KERNEL DENSITY HEAT MAP (ArcGIS-style)\n",
    "# # =============================================================================\n",
    "# from scipy.stats import gaussian_kde\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 1. PREPARE OUTLIER DATA\n",
    "# # =============================================================================\n",
    "# # Separate by sign for better visualization\n",
    "# positive_outliers = outlier_points[outlier_points['diff_tinitaly'] > 0].copy()\n",
    "# negative_outliers = outlier_points[outlier_points['diff_tinitaly'] < 0].copy()\n",
    "#\n",
    "# print(f\"Positive outliers (SAOCOM higher): {len(positive_outliers)}\")\n",
    "# print(f\"Negative outliers (TINITALY higher): {len(negative_outliers)}\")\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 2. CREATE KERNEL DENSITY ESTIMATION\n",
    "# # =============================================================================\n",
    "#\n",
    "# def create_kde_heatmap(points_gdf, grid_res=50):\n",
    "#     \"\"\"Create kernel density heat map from point data\"\"\"\n",
    "#     if len(points_gdf) < 2:\n",
    "#         return None, None, None\n",
    "#\n",
    "#     # Extract coordinates\n",
    "#     x = points_gdf.geometry.x.values\n",
    "#     y = points_gdf.geometry.y.values\n",
    "#\n",
    "#     # Create grid\n",
    "#     xi = np.linspace(xmin_grid, xmax_grid, int((xmax_grid - xmin_grid) / grid_res))\n",
    "#     yi = np.linspace(ymax_grid, ymin_grid, int((ymax_grid - ymin_grid) / grid_res))\n",
    "#     xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "#\n",
    "#     # Perform kernel density estimation\n",
    "#     positions = np.vstack([xi_grid.ravel(), yi_grid.ravel()])\n",
    "#     values = np.vstack([x, y])\n",
    "#     kernel = gaussian_kde(values)\n",
    "#     density = np.reshape(kernel(positions).T, xi_grid.shape)\n",
    "#\n",
    "#     # Apply hull mask\n",
    "#     from scipy.ndimage import zoom\n",
    "#     mask_factor_y = density.shape[0] / hull_mask.shape[0]\n",
    "#     mask_factor_x = density.shape[1] / hull_mask.shape[1]\n",
    "#     hull_mask_resampled = zoom(hull_mask.astype(float),\n",
    "#                                (mask_factor_y, mask_factor_x), order=0) > 0.5\n",
    "#     density[~hull_mask_resampled] = np.nan\n",
    "#\n",
    "#     return density, xi, yi\n",
    "#\n",
    "# # Generate density maps\n",
    "# print(\"\\nGenerating kernel density heat maps...\")\n",
    "#\n",
    "# all_outlier_density, all_xi, all_yi = create_kde_heatmap(outlier_points, grid_res=50)\n",
    "# positive_density, pos_xi, pos_yi = create_kde_heatmap(positive_outliers, grid_res=50)\n",
    "# negative_density, neg_xi, neg_yi = create_kde_heatmap(negative_outliers, grid_res=50)\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 3. CREATE ARCGIS-STYLE HEAT MAP COLORMAP\n",
    "# # =============================================================================\n",
    "# # ArcGIS heat map style: transparent -> blue -> cyan -> yellow -> red\n",
    "# heat_colors = [\n",
    "#     (0.0, (1.0, 1.0, 1.0, 0.0)),    # Transparent white\n",
    "#     (0.2, (0.0, 0.0, 1.0, 0.3)),    # Blue (low density)\n",
    "#     (0.4, (0.0, 1.0, 1.0, 0.5)),    # Cyan\n",
    "#     (0.6, (0.0, 1.0, 0.0, 0.7)),    # Green\n",
    "#     (0.8, (1.0, 1.0, 0.0, 0.85)),   # Yellow\n",
    "#     (1.0, (1.0, 0.0, 0.0, 1.0))     # Red (high density)\n",
    "# ]\n",
    "# arcgis_cmap = LinearSegmentedColormap.from_list('arcgis_heat',\n",
    "#                                                  [c for _, c in heat_colors])\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 4. VISUALIZATION - COMBINED AND SEPARATE HEAT MAPS\n",
    "# # =============================================================================\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(22, 20), facecolor='white')\n",
    "#\n",
    "# extent_grid = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "#\n",
    "# # Plot 1: ALL OUTLIERS - Combined Heat Map\n",
    "# ax = axes[0, 0]\n",
    "# ax.set_facecolor('white')\n",
    "#\n",
    "# # Background\n",
    "# ax.imshow(sentinel_rgb_norm, extent=extent_grid, origin='upper', alpha=0.3)\n",
    "#\n",
    "# # Heat map\n",
    "# if all_outlier_density is not None:\n",
    "#     # Normalize density for better visualization\n",
    "#     density_normalized = all_outlier_density / np.nanmax(all_outlier_density)\n",
    "#\n",
    "#     im1 = ax.imshow(\n",
    "#         density_normalized,\n",
    "#         extent=[all_xi.min(), all_xi.max(), all_yi.min(), all_yi.max()],\n",
    "#         origin='upper',\n",
    "#         cmap=arcgis_cmap,\n",
    "#         alpha=0.85,\n",
    "#         interpolation='bilinear'\n",
    "#     )\n",
    "#\n",
    "#     cbar1 = plt.colorbar(im1, ax=ax, label='Outlier Density', shrink=0.7)\n",
    "#     cbar1.ax.tick_params(labelsize=10)\n",
    "#\n",
    "# # Overlay actual outlier points (small)\n",
    "# outlier_points.plot(ax=ax, markersize=2, color='white', alpha=0.3,\n",
    "#                     edgecolors='black', linewidth=0.3)\n",
    "#\n",
    "# # Study area boundary\n",
    "# hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "#\n",
    "# ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "# ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "# ax.set_title('All Residual Outliers - Kernel Density Heat Map\\n(ArcGIS Style)',\n",
    "#              fontweight='bold', fontsize=14, color='black')\n",
    "# ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "# ax.tick_params(colors='black')\n",
    "#\n",
    "# stats_text = f\"\"\"Total Outliers: {n_outliers:,}\n",
    "# Positive: {len(positive_outliers):,}\n",
    "# Negative: {len(negative_outliers):,}\n",
    "#\n",
    "# Residual Range:\n",
    "# [{outlier_points['diff_tinitaly'].min():+.1f},\n",
    "#  {outlier_points['diff_tinitaly'].max():+.1f}] m\n",
    "#\n",
    "# Heat colors show\n",
    "# concentration of outliers\"\"\"\n",
    "#\n",
    "# ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#         verticalalignment='top', fontfamily='monospace',\n",
    "#         bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "#                  edgecolor='black', linewidth=1.5))\n",
    "#\n",
    "# # Plot 2: POSITIVE OUTLIERS (SAOCOM Higher)\n",
    "# ax = axes[0, 1]\n",
    "# ax.set_facecolor('white')\n",
    "#\n",
    "# ax.imshow(sentinel_rgb_norm, extent=extent_grid, origin='upper', alpha=0.3)\n",
    "#\n",
    "# if positive_density is not None and len(positive_outliers) >= 2:\n",
    "#     density_normalized = positive_density / np.nanmax(positive_density)\n",
    "#\n",
    "#     im2 = ax.imshow(\n",
    "#         density_normalized,\n",
    "#         extent=[pos_xi.min(), pos_xi.max(), pos_yi.min(), pos_yi.max()],\n",
    "#         origin='upper',\n",
    "#         cmap=arcgis_cmap,\n",
    "#         alpha=0.85,\n",
    "#         interpolation='bilinear'\n",
    "#     )\n",
    "#\n",
    "#     cbar2 = plt.colorbar(im2, ax=ax, label='Outlier Density', shrink=0.7)\n",
    "#     cbar2.ax.tick_params(labelsize=10)\n",
    "#\n",
    "#     # Overlay points\n",
    "#     positive_outliers.plot(ax=ax, markersize=3, color='white', alpha=0.4,\n",
    "#                           edgecolors='red', linewidth=0.5)\n",
    "#\n",
    "# hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "#\n",
    "# ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "# ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "# ax.set_title('Positive Outliers - Kernel Density\\n(SAOCOM > TINITALY)',\n",
    "#              fontweight='bold', fontsize=14, color='black')\n",
    "# ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "# ax.tick_params(colors='black')\n",
    "#\n",
    "# if len(positive_outliers) > 0:\n",
    "#     stats_text = f\"\"\"Count: {len(positive_outliers):,}\n",
    "# Mean: {positive_outliers['diff_tinitaly'].mean():+.2f} m\n",
    "# Max: {positive_outliers['diff_tinitaly'].max():+.2f} m\n",
    "#\n",
    "# SAOCOM reports\n",
    "# HIGHER than TINITALY\"\"\"\n",
    "#\n",
    "#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#             verticalalignment='top', fontfamily='monospace',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "#                      edgecolor='black', linewidth=1.5))\n",
    "#\n",
    "# # Plot 3: NEGATIVE OUTLIERS (TINITALY Higher)\n",
    "# ax = axes[1, 0]\n",
    "# ax.set_facecolor('white')\n",
    "#\n",
    "# ax.imshow(sentinel_rgb_norm, extent=extent_grid, origin='upper', alpha=0.3)\n",
    "#\n",
    "# if negative_density is not None and len(negative_outliers) >= 2:\n",
    "#     density_normalized = negative_density / np.nanmax(negative_density)\n",
    "#\n",
    "#     im3 = ax.imshow(\n",
    "#         density_normalized,\n",
    "#         extent=[neg_xi.min(), neg_xi.max(), neg_yi.min(), neg_yi.max()],\n",
    "#         origin='upper',\n",
    "#         cmap=arcgis_cmap,\n",
    "#         alpha=0.85,\n",
    "#         interpolation='bilinear'\n",
    "#     )\n",
    "#\n",
    "#     cbar3 = plt.colorbar(im3, ax=ax, label='Outlier Density', shrink=0.7)\n",
    "#     cbar3.ax.tick_params(labelsize=10)\n",
    "#\n",
    "#     # Overlay points\n",
    "#     negative_outliers.plot(ax=ax, markersize=3, color='white', alpha=0.4,\n",
    "#                           edgecolors='blue', linewidth=0.5)\n",
    "#\n",
    "# hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "#\n",
    "# ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "# ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "# ax.set_title('Negative Outliers - Kernel Density\\n(TINITALY > SAOCOM)',\n",
    "#              fontweight='bold', fontsize=14, color='black')\n",
    "# ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "# ax.tick_params(colors='black')\n",
    "#\n",
    "# if len(negative_outliers) > 0:\n",
    "#     stats_text = f\"\"\"Count: {len(negative_outliers):,}\n",
    "# Mean: {negative_outliers['diff_tinitaly'].mean():+.2f} m\n",
    "# Min: {negative_outliers['diff_tinitaly'].min():+.2f} m\n",
    "#\n",
    "# TINITALY reports\n",
    "# HIGHER than SAOCOM\"\"\"\n",
    "#\n",
    "#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#             verticalalignment='top', fontfamily='monospace',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "#                      edgecolor='black', linewidth=1.5))\n",
    "#\n",
    "# # Plot 4: OUTLIERS BY RESIDUAL MAGNITUDE (Points colored by value)\n",
    "# ax = axes[1, 1]\n",
    "# ax.set_facecolor('white')\n",
    "#\n",
    "# ax.imshow(sentinel_rgb_norm, extent=extent_grid, origin='upper', alpha=0.3)\n",
    "#\n",
    "# # Scatter plot colored by residual magnitude\n",
    "# scatter = ax.scatter(\n",
    "#     outlier_points.geometry.x,\n",
    "#     outlier_points.geometry.y,\n",
    "#     c=outlier_points['diff_tinitaly'],\n",
    "#     cmap='RdBu_r',\n",
    "#     s=30,\n",
    "#     alpha=0.8,\n",
    "#     edgecolors='black',\n",
    "#     linewidth=0.5,\n",
    "#     vmin=outlier_points['diff_tinitaly'].min(),\n",
    "#     vmax=outlier_points['diff_tinitaly'].max()\n",
    "# )\n",
    "#\n",
    "# cbar4 = plt.colorbar(scatter, ax=ax, label='Residual (m)', shrink=0.7)\n",
    "# cbar4.ax.tick_params(labelsize=10)\n",
    "#\n",
    "# # Mark extreme outliers\n",
    "# max_positive = outlier_points.loc[outlier_points['diff_tinitaly'].idxmax()]\n",
    "# max_negative = outlier_points.loc[outlier_points['diff_tinitaly'].idxmin()]\n",
    "#\n",
    "# ax.scatter(max_positive.geometry.x, max_positive.geometry.y,\n",
    "#            s=300, marker='*', color='yellow', edgecolors='black',\n",
    "#            linewidth=2.5, zorder=10, label=f'Max: {max_positive[\"diff_tinitaly\"]:+.1f}m')\n",
    "# ax.scatter(max_negative.geometry.x, max_negative.geometry.y,\n",
    "#            s=100, marker='v', color='cyan', edgecolors='black',\n",
    "#            linewidth=2.5, zorder=10, label=f'Min: {max_negative[\"diff_tinitaly\"]:+.1f}m')\n",
    "#\n",
    "# hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "#\n",
    "# ax.set_xlabel('UTM Easting (m)', fontsize=12, color='black')\n",
    "# ax.set_ylabel('UTM Northing (m)', fontsize=12, color='black')\n",
    "# ax.set_title('Outliers by Residual Magnitude\\n(Point Size = Fixed, Color = Residual Value)',\n",
    "#              fontweight='bold', fontsize=14, color='black')\n",
    "# ax.legend(loc='upper right', fontsize=10)\n",
    "# ax.grid(True, alpha=0.3, color='black', linewidth=0.5)\n",
    "# ax.tick_params(colors='black')\n",
    "#\n",
    "# stats_text = f\"\"\"Outliers: {n_outliers:,}\n",
    "#\n",
    "# Red = SAOCOM Higher\n",
    "# Blue = TINITALY Higher\n",
    "#\n",
    "# Extreme Values:\n",
    "# Max: {outlier_points['diff_tinitaly'].max():+.2f} m (★)\n",
    "# Min: {outlier_points['diff_tinitaly'].min():+.2f} m (▼)\"\"\"\n",
    "#\n",
    "# ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "#         verticalalignment='top', fontfamily='monospace',\n",
    "#         bbox=dict(boxstyle='round', facecolor='white', alpha=0.95,\n",
    "#                  edgecolor='black', linewidth=1.5))\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_outlier_heatmap_kde.png',\n",
    "#             dpi=300, bbox_inches='tight', facecolor='white')\n",
    "# plt.show()\n",
    "#\n",
    "# print(\"\\nSaved: saocom_outlier_heatmap_kde.png\")\n",
    "# print(f\"Total outliers visualized: {n_outliers:,}\")\n",
    "# print(f\"  Positive (SAOCOM > TINITALY): {len(positive_outliers):,}\")\n",
    "# print(f\"  Negative (TINITALY > SAOCOM): {len(negative_outliers):,}\")"
   ],
   "id": "1a38df7f33eb1755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Note: This script assumes the following variables are pre-defined from previous cells:\n",
    "# saocom_gdf, COHERENCE_THRESHOLD, hull_mask, hull_gdf, grid_height, grid_width,\n",
    "# target_transform, xmin_grid, xmax_grid, ymin_grid, ymax_grid,\n",
    "# saocom_tinitaly_metrics, saocom_copernicus_metrics, RESULTS_DIR\n",
    "\n",
    "def create_difference_grid(gdf, height_col, ref_col, grid_shape, transform, hull_mask):\n",
    "    \"\"\"Grids point data differences onto a raster grid using nearest neighbor interpolation.\"\"\"\n",
    "    query_str = f\"`{height_col}`.notna() & `{ref_col}`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "    valid_points = gdf.query(query_str).copy()\n",
    "    valid_points['diff'] = valid_points[height_col] - valid_points[ref_col]\n",
    "\n",
    "    if valid_points.empty:\n",
    "        return np.full(grid_shape, np.nan), valid_points\n",
    "\n",
    "    # Create grid coordinates for interpolation\n",
    "    grid_height, grid_width = grid_shape\n",
    "    x_coords = np.linspace(transform.c, transform.c + transform.a * grid_width, grid_width)\n",
    "    y_coords = np.linspace(transform.f, transform.f + transform.e * grid_height, grid_height)\n",
    "    xi_grid, yi_grid = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "    # Interpolate and mask the grid\n",
    "    diff_grid = griddata(\n",
    "        (valid_points.geometry.x, valid_points.geometry.y),\n",
    "        valid_points['diff'],\n",
    "        (xi_grid, yi_grid),\n",
    "        method='nearest'\n",
    "    )\n",
    "    diff_grid[~hull_mask] = np.nan\n",
    "    return diff_grid, valid_points\n",
    "\n",
    "def plot_panel(ax, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "    \"\"\"Helper function to plot a single map panel.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    cmap.set_bad(color='white', alpha=0)\n",
    "    extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "    im = ax.imshow(data, cmap=cmap, origin='upper', extent=extent, vmin=vmin, vmax=vmax)\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('UTM Easting (m)')\n",
    "    ax.set_ylabel('UTM Northing (m)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "    if stats_text:\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# --- Main Execution ---\n",
    "print(\"Gridding SAOCOM differences (using cleaned data)...\")\n",
    "diff_grid_tin, points_tin = create_difference_grid(saocom_gdf, 'HEIGHT_ABSOLUTE_TIN', 'tinitaly_height', (grid_height, grid_width), target_transform, hull_mask)\n",
    "diff_grid_cop, points_cop = create_difference_grid(saocom_gdf, 'HEIGHT_ABSOLUTE_COP', 'copernicus_height', (grid_height, grid_width), target_transform, hull_mask)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14), facecolor='white')\n",
    "fig.suptitle('SAOCOM vs. Reference DEMs - Gridded Difference Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plotting parameters\n",
    "v_tin = np.nanpercentile(np.abs(points_tin['diff']), 98)\n",
    "v_cop = np.nanpercentile(np.abs(points_cop['diff']), 98)\n",
    "stats_tin = f\"n = {len(points_tin):,}\\nMean = {points_tin['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_tin['diff']**2)):.2f} m\"\n",
    "stats_cop = f\"n = {len(points_cop):,}\\nMean = {points_cop['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_cop['diff']**2)):.2f} m\"\n",
    "\n",
    "# Row 1: SAOCOM vs TINITALY\n",
    "plot_panel(axes[0, 0], diff_grid_tin, 'SAOCOM - TINITALY\\nFull Difference', plt.cm.coolwarm, -v_tin, v_tin, stats_tin)\n",
    "plot_panel(axes[0, 1], np.where(diff_grid_tin > 0, diff_grid_tin, np.nan), 'SAOCOM > TINITALY', plt.cm.Reds, 0, v_tin)\n",
    "plot_panel(axes[0, 2], np.where(diff_grid_tin < 0, diff_grid_tin, np.nan), 'TINITALY > SAOCOM', plt.cm.Blues_r, -v_tin, 0)\n",
    "\n",
    "# Row 2: SAOCOM vs Copernicus\n",
    "plot_panel(axes[1, 0], diff_grid_cop, 'SAOCOM - Copernicus\\nFull Difference', plt.cm.coolwarm, -v_cop, v_cop, stats_cop)\n",
    "plot_panel(axes[1, 1], np.where(diff_grid_cop > 0, diff_grid_cop, np.nan), 'SAOCOM > Copernicus', plt.cm.Reds, 0, v_cop)\n",
    "plot_panel(axes[1, 2], np.where(diff_grid_cop < 0, diff_grid_cop, np.nan), 'Copernicus > SAOCOM', plt.cm.Blues_r, -v_cop, 0)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_gridded_comparison.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "d7f0ff39558e2e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Note: This script assumes the following variables are pre-defined from previous cells:\n",
    "# saocom_gdf, COHERENCE_THRESHOLD, hull_gdf, saocom_tinitaly_metrics,\n",
    "# saocom_copernicus_metrics, RESULTS_DIR, xmin_grid, xmax_grid, ymin_grid, ymax_grid\n",
    "\n",
    "# =============================================================================\n",
    "# Helper function for plotting points (Unchanged)\n",
    "# =============================================================================\n",
    "def plot_points_panel(ax, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "    \"\"\"Helper function to plot a single map panel using a scatter plot.\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    im = ax.scatter(data.geometry.x, data.geometry.y, c=data['diff'],\n",
    "                    s=1, alpha=0.7, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('UTM Easting (m)')\n",
    "    ax.set_ylabel('UTM Northing (m)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "    if stats_text:\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# =============================================================================\n",
    "# Data preparation (Unchanged)\n",
    "# =============================================================================\n",
    "print(\"Filtering SAOCOM differences for plotting...\")\n",
    "\n",
    "query_str_tin = f\"`HEIGHT_ABSOLUTE_TIN`.notna() & `tinitaly_height`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "points_tin = saocom_gdf.query(query_str_tin).copy()\n",
    "points_tin['diff'] = points_tin['HEIGHT_ABSOLUTE_TIN'] - points_tin['tinitaly_height']\n",
    "\n",
    "query_str_cop = f\"`HEIGHT_ABSOLUTE_COP`.notna() & `copernicus_height`.notna() & COHER >= @COHERENCE_THRESHOLD\"\n",
    "points_cop = saocom_gdf.query(query_str_cop).copy()\n",
    "points_cop['diff'] = points_cop['HEIGHT_ABSOLUTE_COP'] - points_cop['copernicus_height']\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "# =============================================================================\n",
    "# MODIFIED: Change subplot layout from (2, 3) to (3, 2) and adjust figsize\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 20), facecolor='white')\n",
    "fig.suptitle('SAOCOM vs. Reference DEMs - Point-Based Difference Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plotting parameters (Unchanged)\n",
    "v_tin = np.nanpercentile(np.abs(points_tin['diff']), 98)\n",
    "v_cop = np.nanpercentile(np.abs(points_cop['diff']), 98)\n",
    "stats_tin = f\"n = {len(points_tin):,}\\nMean = {points_tin['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_tin['diff']**2)):.2f} m\"\n",
    "stats_cop = f\"n = {len(points_cop):,}\\nMean = {points_cop['diff'].mean():+.2f} m\\nRMSE = {np.sqrt(np.mean(points_cop['diff']**2)):.2f} m\"\n",
    "\n",
    "# =============================================================================\n",
    "# MODIFIED: Update axes indexing for the new 3x2 layout\n",
    "# =============================================================================\n",
    "# Row 1: Full Difference Maps\n",
    "plot_points_panel(axes[0, 0], points_tin, 'SAOCOM - TINITALY\\nFull Difference', plt.cm.coolwarm, -v_tin, v_tin, stats_tin)\n",
    "plot_points_panel(axes[0, 1], points_cop, 'SAOCOM - Copernicus\\nFull Difference', plt.cm.coolwarm, -v_cop, v_cop, stats_cop)\n",
    "\n",
    "# Row 2: SAOCOM > Reference DEM\n",
    "plot_points_panel(axes[1, 0], points_tin[points_tin['diff'] > 0], 'SAOCOM > TINITALY', plt.cm.Reds, 0, v_tin)\n",
    "plot_points_panel(axes[1, 1], points_cop[points_cop['diff'] > 0], 'SAOCOM > Copernicus', plt.cm.Reds, 0, v_cop)\n",
    "\n",
    "# Row 3: Reference DEM > SAOCOM\n",
    "plot_points_panel(axes[2, 0], points_tin[points_tin['diff'] < 0], 'TINITALY > SAOCOM', plt.cm.Blues_r, -v_tin, 0)\n",
    "plot_points_panel(axes[2, 1], points_cop[points_cop['diff'] < 0], 'Copernicus > SAOCOM', plt.cm.Blues_r, -v_cop, 0)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_point_comparison_3x2.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "9d13b5663bafe95b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Edited Histograms\n",
    "\n"
   ],
   "id": "986658038cb36f24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_distribution(ax, diff_series, title, metrics):\n",
    "    \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    ax.hist(diff_series, bins=50, alpha=0.75, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "    ax.axvline(metrics['mean_diff'], color='green', linestyle='-', label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "\n",
    "    stats_text = (f\"n = {metrics['n_points']:,}\\n\"\n",
    "                  f\"RMSE = {metrics['rmse']:.2f} m\\n\"\n",
    "                  f\"NMAD = {metrics['nmad']:.2f} m\\n\"\n",
    "                  f\"Std Dev = {metrics['std_diff']:.2f} m\")\n",
    "\n",
    "    ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Elevation Difference (m)', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "fig.suptitle('Residual Distributions (Cleaned Data)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Use the 'diff' column from the points DataFrames created in the previous cell\n",
    "plot_distribution(axes[0], points_tin['diff'], 'SAOCOM - TINITALY', saocom_tinitaly_metrics)\n",
    "plot_distribution(axes[1], points_cop['diff'], 'SAOCOM - Copernicus', saocom_copernicus_metrics)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_residual_distributions.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "78e87c7a7d043613",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_scatter_comparison(ax, x_data, y_data, x_label, y_label, title, stats):\n",
    "    \"\"\"\n",
    "    Creates a simple 1:1 scatter plot to compare two sets of height data.\n",
    "    \"\"\"\n",
    "    ax.set_facecolor('white') # Set background to white\n",
    "\n",
    "    # Plot the individual data points\n",
    "    ax.scatter(x_data, y_data, s=1, alpha=0.3, c='steelblue', label='Data Points')\n",
    "\n",
    "    # Determine plot limits and draw the 1:1 line\n",
    "    lims = [\n",
    "        np.min([x_data.min(), y_data.min()]),\n",
    "        np.max([x_data.max(), y_data.max()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'r--', linewidth=2, label='1:1 Line', zorder=10)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    # Add statistics box\n",
    "    stats_text = (f\"n = {stats.get('n_points', stats.get('n_pixels')):,}\\n\"\n",
    "                  f\"Bias = {stats['mean_diff']:.2f} m\\n\"\n",
    "                  f\"RMSE = {stats['rmse']:.2f} m\\n\"\n",
    "                  f\"Corr (r) = {stats['correlation']:.3f}\")\n",
    "\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', color='black', # Text color to black\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7, edgecolor='black'))\n",
    "\n",
    "    # Style the plot\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12, color='black')\n",
    "    ax.set_xlabel(x_label, fontsize=11, color='black')\n",
    "    ax.set_ylabel(y_label, fontsize=11, color='black')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    # Style ticks and spines\n",
    "    ax.tick_params(colors='black')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison Scatter Plots (Cleaned Data)', fontsize=16, fontweight='bold', color='black')\n",
    "\n",
    "# Note: Assumes variables from previous cells are available\n",
    "# (points_tin, points_cop, valid_copernicus, valid_tinitaly, and all metrics dicts)\n",
    "\n",
    "plot_scatter_comparison(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "                        'TINITALY Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs TINITALY', saocom_tinitaly_metrics)\n",
    "\n",
    "plot_scatter_comparison(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "                        'Copernicus Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs Copernicus', saocom_copernicus_metrics)\n",
    "\n",
    "plot_scatter_comparison(axes[2], valid_copernicus, valid_tinitaly,\n",
    "                        'Copernicus Height (m)', 'TINITALY Height (m)', 'TINITALY vs Copernicus', ref_metrics)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_scatter_comparisons.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "bc045bb09b35cc7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Density Plots Color\n",
   "id": "fbf5d5ba2b937348"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison - High-Contrast Hexbin Density Plots', fontsize=16, fontweight='bold')\n",
    "\n",
    "def plot_hexbin(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Helper function to create a hexbin plot with improved contrast.\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    # Create the hexbin plot\n",
    "    # CHANGE 1: Switched to 'inferno' colormap for a high-contrast, \"hotter\" look.\n",
    "    # Other good options are 'plasma' or 'magma'.\n",
    "    hb = ax.hexbin(x_data, y_data, gridsize=150, cmap='inferno',\n",
    "                   norm=colors.LogNorm(), mincnt=1) # Log scale is essential\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(hb, ax=ax, label='Point Count')\n",
    "\n",
    "    # CHANGE 2: Switched 1:1 line to red for better visibility against the colormap.\n",
    "    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "    ax.plot(lims, lims, 'r--', linewidth=2, label='1:1 line', alpha=0.9)\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel(y_label, fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "# This is an alternative function you can use instead of plot_hexbin for a different style.\n",
    "def plot_hist2d(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Alternative helper function to create a 2D histogram (square bins).\"\"\"\n",
    "    ax.set_facecolor('gainsboro')\n",
    "\n",
    "    # Create the 2D histogram\n",
    "    # Bins determines the resolution. Cmin=1 ensures empty bins are not colored.\n",
    "    h = ax.hist2d(x_data, y_data, bins=150, cmap='inferno',\n",
    "                  norm=colors.LogNorm(), cmin=1)\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(h[3], ax=ax, label='Point Count')\n",
    "\n",
    "    # Add 1:1 line\n",
    "    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "    ax.plot(lims, lims, 'w--', linewidth=1.5, label='1:1 line', alpha=0.7) # White line works well here\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel(y_label, fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "# Plot 1: SAOCOM vs TINITALY\n",
    "plot_hexbin(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "            'TINITALY Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs TINITALY')\n",
    "\n",
    "# Plot 2: SAOCOM vs Copernicus\n",
    "plot_hexbin(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "            'Copernicus Height (m)', 'SAOCOM Height (m)', 'SAOCOM vs Copernicus')\n",
    "\n",
    "# Plot 3: TINITALY vs Copernicus\n",
    "plot_hexbin(axes[2], valid_copernicus, valid_tinitaly,\n",
    "            'Copernicus Height (m)', 'TINITALY Height (m)', 'TINITALY vs Copernicus')\n",
    "\n",
    "# To use the 2D histogram instead, you would replace the calls above with:\n",
    "# plot_hist2d(axes[0], ...)\n",
    "# plot_hist2d(axes[1], ...)\n",
    "# plot_hist2d(axes[2], ...)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_hexbin_comparisons_high_contrast.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "d805ab78a400b357",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
    "fig.suptitle('1:1 Height Comparison - Bland-Altman Density Plots', fontsize=16, fontweight='bold')\n",
    "\n",
    "def plot_bland_altman(ax, x_data, y_data, x_label, y_label, title):\n",
    "    \"\"\"Helper function to create a Bland-Altman hexbin plot.\"\"\"\n",
    "    # --- Data Transformation ---\n",
    "    # Calculate the average and difference\n",
    "    average = (x_data + y_data) / 2\n",
    "    difference = y_data - x_data\n",
    "\n",
    "    # Calculate key statistics for the plot\n",
    "    mean_diff = np.mean(difference)\n",
    "    std_diff = np.std(difference)\n",
    "    limit_of_agreement = 1.96 * std_diff\n",
    "\n",
    "    ax.set_facecolor('gainsboro')\n",
    "    # Create the hexbin plot using the transformed data\n",
    "    hb = ax.hexbin(average, difference, gridsize=150, cmap='viridis',\n",
    "                   norm=colors.LogNorm(), mincnt=1)\n",
    "\n",
    "    # Add a color bar\n",
    "    fig.colorbar(hb, ax=ax, label='Point Count')\n",
    "\n",
    "    # --- Add Statistical Lines ---\n",
    "    # Line of perfect agreement (zero difference)\n",
    "    ax.axhline(0, color='white', linestyle='--', linewidth=1.5, label='Zero (Perfect Agreement)')\n",
    "    # Mean difference line\n",
    "    ax.axhline(mean_diff, color='red', linestyle='-', linewidth=2, label=f'Mean Diff: {mean_diff:.2f} m')\n",
    "    # Limits of agreement lines (+/- 1.96 * SD)\n",
    "    ax.axhline(mean_diff + limit_of_agreement, color='red', linestyle='--', linewidth=1.5, label=f'Limits of Agreement (±{limit_of_agreement:.2f} m)')\n",
    "    ax.axhline(mean_diff - limit_of_agreement, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    # Update axis labels for the new plot type\n",
    "    ax.set_xlabel(f'Average of ({x_label} and {y_label})', fontsize=11)\n",
    "    ax.set_ylabel(f'Difference ({y_label} - {x_label})', fontsize=11)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend()\n",
    "\n",
    "# Plot 1: SAOCOM vs TINITALY\n",
    "plot_bland_altman(axes[0], points_tin['tinitaly_height'], points_tin['HEIGHT_ABSOLUTE_TIN'],\n",
    "                  'SAOCOM', 'TINITALY', 'SAOCOM vs TINITALY')\n",
    "\n",
    "# Plot 2: SAOCOM vs Copernicus\n",
    "plot_bland_altman(axes[1], points_cop['copernicus_height'], points_cop['HEIGHT_ABSOLUTE_COP'],\n",
    "                  'SAOCOM', 'Copernicus', 'SAOCOM vs Copernicus')\n",
    "\n",
    "# Plot 3: TINITALY vs Copernicus\n",
    "plot_bland_altman(axes[2], valid_copernicus, valid_tinitaly,\n",
    "                  'TINITALY', 'Copernicus', 'TINITALY vs Copernicus')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(RESULTS_DIR / 'saocom_bland_altman_comparisons.png', dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "id": "4c9d7beeabd1d942",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SAOCOM VS REFERENCE DEMs - GRIDDED COMPARISON ANALYSIS",
   "id": "d7d002b4cf5aed97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.interpolate import griddata\n",
    "# from scipy import stats\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 1. GRIDDED DEM COMPARISON\n",
    "# # =============================================================================\n",
    "#\n",
    "# def process_dem_comparison(gdf, height_col, ref_col, grid_shape, transform, hull_mask, metrics):\n",
    "#     \"\"\"Grids SAOCOM point differences and classifies them against a tolerance.\"\"\"\n",
    "#     # Filter for valid, coherent points and calculate difference\n",
    "#     valid_mask = gdf[height_col].notna() & gdf[ref_col].notna() & (gdf['COHER'] >= COHERENCE_THRESHOLD)\n",
    "#     points = gdf[valid_mask].copy()\n",
    "#     points['diff'] = points[height_col] - points[ref_col]\n",
    "#\n",
    "#     # Interpolate difference onto a grid\n",
    "#     grid_height, grid_width = grid_shape\n",
    "#     xi, yi = np.meshgrid(\n",
    "#         np.linspace(transform.c, transform.c + transform.a * grid_width, grid_width),\n",
    "#         np.linspace(transform.f, transform.f + transform.e * grid_height, grid_height)\n",
    "#     )\n",
    "#     diff_grid = griddata(\n",
    "#         (points.geometry.x, points.geometry.y), points['diff'],\n",
    "#         (xi, yi), method='nearest'\n",
    "#     )\n",
    "#     diff_grid[~hull_mask] = np.nan # Apply hull mask\n",
    "#\n",
    "#     # Classify differences based on NMAD tolerance\n",
    "#     tolerance = metrics['nmad']\n",
    "#     with np.errstate(invalid='ignore'): # Ignore warnings from comparing with NaN\n",
    "#         higher_mask = diff_grid > tolerance\n",
    "#         lower_mask = diff_grid < -tolerance\n",
    "#\n",
    "#     # Generate statistics\n",
    "#     n_valid = np.count_nonzero(~np.isnan(diff_grid))\n",
    "#     stats_dict = {\n",
    "#         'n_total': n_valid,\n",
    "#         'n_higher': np.sum(higher_mask), 'pct_higher': 100 * np.sum(higher_mask) / n_valid,\n",
    "#         'n_lower': np.sum(lower_mask), 'pct_lower': 100 * np.sum(lower_mask) / n_valid,\n",
    "#     }\n",
    "#     return diff_grid, higher_mask, lower_mask, stats_dict, points\n",
    "#\n",
    "# def plot_gridded_comparison(axes, data, title, cmap, vmin=None, vmax=None, stats_text=None):\n",
    "#     \"\"\"Helper function to plot a single difference map.\"\"\"\n",
    "#     ax = axes\n",
    "#     ax.set_facecolor('white')\n",
    "#     cmap.set_bad(color='white', alpha=0)\n",
    "#     im = ax.imshow(data, cmap=cmap, origin='upper', extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid], vmin=vmin, vmax=vmax)\n",
    "#     hull_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5)\n",
    "#     plt.colorbar(im, ax=ax, label='Difference (m)', shrink=0.8)\n",
    "#     ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "#     ax.set_xlabel('UTM Easting (m)')\n",
    "#     ax.set_ylabel('UTM Northing (m)')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "#     if stats_text:\n",
    "#         ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9, va='top',\n",
    "#                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "# # --- Main Plotting Logic for Gridded Comparison ---\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(20, 14), facecolor='white')\n",
    "#\n",
    "# # Define datasets to compare\n",
    "# comparisons = [\n",
    "#     {'name': 'TINITALY', 'h_col': 'HEIGHT_ABSOLUTE_TIN', 'r_col': 'tinitaly_height', 'metrics': saocom_tinitaly_metrics},\n",
    "#     {'name': 'Copernicus', 'h_col': 'HEIGHT_ABSOLUTE_COP', 'r_col': 'copernicus_height', 'metrics': saocom_copernicus_metrics}\n",
    "# ]\n",
    "#\n",
    "# for i, p in enumerate(comparisons):\n",
    "#     diff_grid, higher, lower, stats, points = process_dem_comparison(\n",
    "#         saocom_gdf, p['h_col'], p['r_col'], (grid_height, grid_width), target_transform, hull_mask, p['metrics']\n",
    "#     )\n",
    "#\n",
    "#     # Plot 1: Full Difference\n",
    "#     diff_limit = np.percentile(np.abs(points['diff']), 95)\n",
    "#     stats1 = f\"Points: {stats['n_total']:,}\\nMean: {p['metrics']['mean_diff']:+.2f}m\\nRMSE: {p['metrics']['rmse']:.2f}m\\nNMAD: {p['metrics']['nmad']:.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 0], diff_grid, f\"SAOCOM - {p['name']}\\nFull Difference\", plt.cm.coolwarm.copy(), -diff_limit, diff_limit, stats1)\n",
    "#\n",
    "#     # Plot 2: SAOCOM Higher\n",
    "#     higher_grid = np.where(higher, diff_grid, np.nan)\n",
    "#     stats2 = f\"Points: {stats['n_higher']:,}\\nMean: {np.nanmean(higher_grid):.2f}m\\nMax: {np.nanmax(higher_grid):.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 1], higher_grid, f\"SAOCOM > {p['name']}\\n({stats['pct_higher']:.1f}%)\", plt.cm.YlOrRd.copy(), 0, np.nanmax(higher_grid), stats2)\n",
    "#\n",
    "#     # Plot 3: SAOCOM Lower\n",
    "#     lower_grid = np.where(lower, diff_grid, np.nan)\n",
    "#     stats3 = f\"Points: {stats['n_lower']:,}\\nMean: {np.nanmean(lower_grid):.2f}m\\nMin: {np.nanmin(lower_grid):.2f}m\"\n",
    "#     plot_gridded_comparison(axes[i, 2], lower_grid, f\"{p['name']} > SAOCOM\\n({stats['pct_lower']:.1f}%)\", plt.cm.Blues_r.copy(), np.nanmin(lower_grid), 0, stats3)\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_comparison_directional.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 2. RESIDUAL DISTRIBUTION HISTOGRAMS\n",
    "# # =============================================================================\n",
    "#\n",
    "# def plot_residual_histogram(ax, diff_series, metrics, tolerance, title):\n",
    "#     \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "#     ax.hist(diff_series, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "#     ax.axvline(0, color='red', ls='--', lw=2, label='Zero')\n",
    "#     ax.axvline(metrics['mean_diff'], color='green', ls='-', lw=2, label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "#     ax.axvline(tolerance, color='orange', ls='--', lw=1.5, label=f\"±NMAD: {tolerance:.2f}m\")\n",
    "#     ax.axvline(-tolerance, color='orange', ls='--', lw=1.5)\n",
    "#\n",
    "#     stats_text = f\"n = {metrics['n_points']:,}\\nRMSE = {metrics['rmse']:.2f}m\\nNMAD = {metrics['nmad']:.2f}m\\nStd Dev = {metrics['std_diff']:.2f}m\"\n",
    "#     ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=9, va='top', ha='right',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "#     ax.set(xlabel='Elevation Difference (m)', ylabel='Frequency (Log Scale)',\n",
    "#            title=title, yscale='log')\n",
    "#     ax.legend(loc='upper right', fontsize=10)\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "# plot_residual_histogram(axes[0], saocom_tinitaly_diff, saocom_tinitaly_metrics, saocom_tinitaly_tolerance, 'SAOCOM - TINITALY Distribution')\n",
    "# plot_residual_histogram(axes[1], saocom_copernicus_diff, saocom_copernicus_metrics, saocom_copernicus_tolerance, 'SAOCOM - Copernicus Distribution')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_residual_distributions.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 3. ENSEMBLE OUTLIER DETECTION\n",
    "# # =============================================================================\n",
    "#\n",
    "# # Filter for valid heights and run detection methods\n",
    "# valid_saocom = saocom_gdf[saocom_gdf['HEIGHT_ABSOLUTE_TIN'].notna()].copy()\n",
    "# heights = valid_saocom['HEIGHT_ABSOLUTE_TIN']\n",
    "#\n",
    "# # Method 1: IQR (3x multiplier for extreme outliers)\n",
    "# q1, q3 = heights.quantile(0.25), heights.quantile(0.75)\n",
    "# iqr = q3 - q1\n",
    "# outliers_iqr = (heights < (q1 - 3 * iqr)) | (heights > (q3 + 3 * iqr))\n",
    "#\n",
    "# # Method 2: Z-score\n",
    "# outliers_zscore = np.abs(stats.zscore(heights)) > 3\n",
    "#\n",
    "# # Method 3: Modified Z-score (NMAD-based)\n",
    "# median_abs_dev = np.median(np.abs(heights - heights.median()))\n",
    "# mod_z_scores = 0.6745 * (heights - heights.median()) / median_abs_dev\n",
    "# outliers_nmad = np.abs(mod_z_scores) > 3.5\n",
    "#\n",
    "# # Combine methods: outlier if flagged by at least 2\n",
    "# is_outlier = np.sum([outliers_iqr, outliers_zscore, outliers_nmad], axis=0) >= 2\n",
    "# valid_saocom['is_outlier'] = is_outlier\n",
    "# normal_points = valid_saocom[~is_outlier]\n",
    "# outlier_points = valid_saocom[is_outlier]\n",
    "#\n",
    "# print(f\"Ensemble outlier detection complete. Found {len(outlier_points)} outliers.\")\n",
    "#\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 4. OUTLIER VISUALIZATION & ANALYSIS\n",
    "# # =============================================================================\n",
    "#\n",
    "# fig = plt.figure(figsize=(18, 16), facecolor='white')\n",
    "# gs = fig.add_gridspec(2, 2)\n",
    "#\n",
    "# # Plot 1: Spatial Distribution\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# normal_points.plot(ax=ax1, markersize=0.5, color='#2E86AB', alpha=0.4, label=f'Normal ({len(normal_points):,})')\n",
    "# if not outlier_points.empty:\n",
    "#     outlier_points.plot(ax=ax1, markersize=8, color='#E63946', alpha=0.9, ec='black', lw=0.3, label=f'Outliers ({len(outlier_points):,})')\n",
    "# hull_gdf.boundary.plot(ax=ax1, color='black', lw=2, ls='--')\n",
    "# ax1.set(title='SAOCOM Height Outliers - Spatial Distribution', xlabel='UTM Easting (m)', ylabel='UTM Northing (m)')\n",
    "# ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Plot 2: Height Distribution\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# ax2.hist(normal_points['HEIGHT_ABSOLUTE_TIN'], bins=50, alpha=0.6, color='#2E86AB', label='Normal')\n",
    "# if not outlier_points.empty:\n",
    "#     ax2.hist(outlier_points['HEIGHT_ABSOLUTE_TIN'], bins=20, alpha=0.8, color='#E63946', label='Outliers')\n",
    "# ax2.axvline(q1 - 3 * iqr, color='orange', ls='--', label=f'IQR Bound')\n",
    "# ax2.axvline(q3 + 3 * iqr, color='orange', ls='--')\n",
    "# ax2.set(title='Height Distribution with Outlier Thresholds', xlabel='Height (m)', ylabel='Frequency')\n",
    "# ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "#\n",
    "# # Plot 3: Box Plot\n",
    "# ax3 = fig.add_subplot(gs[1, 0])\n",
    "# box_data = [normal_points['HEIGHT_ABSOLUTE_TIN'].dropna()]\n",
    "# if not outlier_points.empty:\n",
    "#     box_data.append(outlier_points['HEIGHT_ABSOLUTE_TIN'].dropna())\n",
    "# bp = ax3.boxplot(box_data, patch_artist=True, showmeans=True, meanline=True,\n",
    "#                  labels=['Normal', 'Outliers'] if not outlier_points.empty else ['Normal'])\n",
    "# colors = ['#2E86AB', '#E63946']\n",
    "# for patch, color in zip(bp['boxes'], colors):\n",
    "#     patch.set_facecolor(color)\n",
    "# ax3.set(title='Height Distribution Comparison', ylabel='Height (m)')\n",
    "# ax3.grid(True, axis='y', alpha=0.3)\n",
    "#\n",
    "# # Plot 4: Summary Text\n",
    "# ax4 = fig.add_subplot(gs[1, 1])\n",
    "# ax4.axis('off')\n",
    "# summary_text = f\"\"\"OUTLIER ANALYSIS SUMMARY\n",
    "# -----------------------------------\n",
    "# Flagged by IQR Method: {np.sum(outliers_iqr):,}\n",
    "# Flagged by Z-score: {np.sum(outliers_zscore):,}\n",
    "# Flagged by Mod. Z-score: {np.sum(outliers_nmad):,}\n",
    "# -----------------------------------\n",
    "# Final Outliers (≥2 methods): {len(outlier_points):,} ({len(outlier_points)/len(valid_saocom):.2%})\n",
    "# Normal Points: {len(normal_points):,}\n",
    "# -----------------------------------\n",
    "# Normal Mean Height: {normal_points['HEIGHT_ABSOLUTE_TIN'].mean():.2f} m\n",
    "# Outlier Mean Height: {outlier_points['HEIGHT_ABSOLUTE_TIN'].mean():.2f} m\n",
    "# \"\"\"\n",
    "# ax4.text(0.05, 0.5, summary_text, va='center', fontfamily='monospace',\n",
    "#          bbox=dict(boxstyle='round', facecolor='white', ec='black'))\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(RESULTS_DIR / 'saocom_height_outliers_ensemble.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "# # =============================================================================\n",
    "# # 5. SCATTER PLOT COMPARISONS\n",
    "# # =============================================================================\n",
    "#\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(18, 16), facecolor='white')\n",
    "# axes[1, 1].axis('off') # Hide unused subplot\n",
    "#\n",
    "# # Define scatter plot configurations\n",
    "# scatter_plots = [\n",
    "#     {'ax': axes[0, 0], 'x': saocom_tinitaly_valid['tinitaly_height'], 'y': saocom_tinitaly_valid['HEIGHT_ABSOLUTE_TIN'],\n",
    "#      'title': 'SAOCOM vs TINITALY', 'xlabel': 'TINITALY Height (m)', 'metrics': saocom_tinitaly_metrics},\n",
    "#     {'ax': axes[0, 1], 'x': saocom_copernicus_valid['copernicus_height'], 'y': saocom_copernicus_valid['HEIGHT_ABSOLUTE_COP'],\n",
    "#      'title': 'SAOCOM vs Copernicus', 'xlabel': 'Copernicus Height (m)', 'metrics': saocom_copernicus_metrics},\n",
    "#     {'ax': axes[1, 0], 'x': valid_copernicus, 'y': valid_tinitaly,\n",
    "#      'title': 'TINITALY vs Copernicus', 'xlabel': 'Copernicus Height (m)', 'ylabel': 'TINITALY Height (m)', 'metrics': ref_metrics},\n",
    "# ]\n",
    "#\n",
    "# for p in scatter_plots:\n",
    "#     ax = p['ax']\n",
    "#     ax.scatter(p['x'], p['y'], s=1, alpha=0.3, c='steelblue', ec='none')\n",
    "#     min_val, max_val = min(p['x'].min(), p['y'].min()), max(p['x'].max(), p['y'].max())\n",
    "#     ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='1:1 line')\n",
    "#\n",
    "#     stats_text = (f\"n = {p['metrics'].get('n_points', p['metrics'].get('n_pixels')):,}\\n\"\n",
    "#                   f\"Bias = {p['metrics']['mean_diff']:.2f}m\\nRMSE = {p['metrics']['rmse']:.2f}m\\n\"\n",
    "#                   f\"NMAD = {p['metrics']['nmad']:.2f}m\\nCorr (r) = {p['metrics']['correlation']:.3f}\")\n",
    "#\n",
    "#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9, va='top', fontfamily='monospace',\n",
    "#             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, ec='black'))\n",
    "#\n",
    "#     ax.set(title=p['title'], xlabel=p['xlabel'], ylabel=p.get('ylabel', 'SAOCOM Height (m)'))\n",
    "#     ax.legend(); ax.grid(True, alpha=0.3)\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "f8ffbcb8ce5b6d3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VOID ZONES vs LAND COVER ANALYSIS",
   "id": "957d6fce3ae6ea1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# VOID ZONES vs LAND COVER ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CALCULATE VOID STATISTICS BY LAND COVER\n",
    "# =============================================================================\n",
    "void_lc_stats = []\n",
    "\n",
    "for lc_code in np.unique(corine_10m[corine_10m > 0]):\n",
    "    lc_mask = (corine_10m == lc_code) & study_area_mask\n",
    "\n",
    "    total_lc_cells = np.sum(lc_mask)\n",
    "    void_lc_cells = np.sum(lc_mask & void_mask)\n",
    "\n",
    "    if total_lc_cells == 0:\n",
    "        continue\n",
    "\n",
    "    pct_lc_is_void = 100 * void_lc_cells / total_lc_cells\n",
    "    pct_of_total_voids = 100 * void_lc_cells / np.sum(void_mask)\n",
    "\n",
    "    void_lc_stats.append({\n",
    "        'LC_Code': lc_code,\n",
    "        'LC_Name': CORINE_CLASSES.get(lc_code, f'Unknown_{lc_code}'),\n",
    "        'Total_Cells': total_lc_cells,\n",
    "        'Void_Cells': void_lc_cells,\n",
    "        'Area_km2': total_lc_cells * (GRID_SIZE**2) / 1e6,\n",
    "        'Void_Area_km2': void_lc_cells * (GRID_SIZE**2) / 1e6,\n",
    "        'Pct_LC_is_Void': pct_lc_is_void,\n",
    "        'Pct_of_Total_Voids': pct_of_total_voids\n",
    "    })\n",
    "\n",
    "void_lc_df = pd.DataFrame(void_lc_stats).sort_values('Pct_LC_is_Void', ascending=False)\n",
    "\n",
    "# Display table\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(\"VOID ZONES BY LAND COVER CLASS\")\n",
    "print(f\"{'='*120}\")\n",
    "print(void_lc_df[['LC_Code', 'LC_Name', 'Area_km2', 'Void_Area_km2', 'Pct_LC_is_Void', 'Pct_of_Total_Voids']].to_string(index=False))\n",
    "print(f\"{'='*120}\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MAP: VOID ZONES WITH LAND COVER OVERLAY\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Sentinel background\n",
    "ax.imshow(sentinel_rgb_norm, extent=extent, origin='upper', alpha=0.6)\n",
    "\n",
    "# Land cover in void zones only\n",
    "lc_in_voids = corine_10m.copy()\n",
    "lc_in_voids[~void_mask] = 0\n",
    "lc_display = np.ma.masked_where(lc_in_voids == 0, lc_in_voids)\n",
    "\n",
    "void_codes = np.unique(lc_display.compressed())\n",
    "\n",
    "if len(void_codes) > 0:\n",
    "    colors_list = [CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5)) for code in void_codes]\n",
    "    cmap = ListedColormap(colors_list)\n",
    "    norm = BoundaryNorm(boundaries=np.append(void_codes, void_codes[-1]+1) - 0.5,\n",
    "                        ncolors=len(void_codes))\n",
    "\n",
    "    im = ax.imshow(lc_display, cmap=cmap, norm=norm, origin='upper',\n",
    "                  extent=extent, alpha=0.7)\n",
    "\n",
    "# Study area boundary\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--')\n",
    "\n",
    "# Statistics box\n",
    "void_area = np.sum(void_mask) * (GRID_SIZE**2) / 1e6\n",
    "total_area = np.sum(study_area_mask) * (GRID_SIZE**2) / 1e6\n",
    "pct_void = 100 * np.sum(void_mask) / np.sum(study_area_mask)\n",
    "\n",
    "stats_text = f\"\"\"Void Area: {void_area:.2f} km²\n",
    "Total Area: {total_area:.2f} km²\n",
    "Void %: {pct_void:.1f}%\n",
    "LC Classes: {len(void_codes)}\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "        alpha=0.9, edgecolor='black'))\n",
    "\n",
    "# Legend\n",
    "if len(void_codes) > 0:\n",
    "    legend_elements = [mpatches.Rectangle((0,0),1,1,\n",
    "                                         facecolor=CORINE_COLORS_MPL[code],\n",
    "                                         edgecolor='black', linewidth=0.5,\n",
    "                                         label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\")\n",
    "                      for code in sorted(void_codes)]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "             fontsize=9, frameon=True, fancybox=False, edgecolor='black',\n",
    "             title='Land Cover in Void Zones')\n",
    "\n",
    "ax.set_title('Land Cover Distribution in SAOCOM Void Zones',\n",
    "             fontweight='bold', fontsize=14, pad=15)\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "saocom_gdf.plot(ax=ax, markersize=1, color='black', alpha=0.8, label='SAOCOM Points')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'voids_by_landcover_map.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: voids_by_landcover_map.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. BAR CHART: WHICH LAND COVERS HAVE THE MOST VOIDS\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), facecolor='white')\n",
    "\n",
    "# Chart 1: % of each land cover that is void\n",
    "top_pct = void_lc_df.nlargest(15, 'Pct_LC_is_Void')\n",
    "bars1 = ax1.barh(range(len(top_pct)), top_pct['Pct_LC_is_Void'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_pct.iterrows()):\n",
    "    bars1[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars1[i].set_edgecolor('black')\n",
    "    bars1[i].set_linewidth(0.5)\n",
    "\n",
    "ax1.set_yticks(range(len(top_pct)))\n",
    "ax1.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_pct.iterrows()], fontsize=9)\n",
    "ax1.set_xlabel('% of Land Cover Class that is Void', fontsize=11)\n",
    "ax1.set_title('Land Covers with Highest Void Percentage\\n(Worst Coverage Performance)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax1.axvline(pct_void, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Overall Void Rate: {pct_void:.1f}%')\n",
    "ax1.legend()\n",
    "\n",
    "# Chart 2: Contribution to total voids\n",
    "top_contrib = void_lc_df.nlargest(15, 'Pct_of_Total_Voids')\n",
    "bars2 = ax2.barh(range(len(top_contrib)), top_contrib['Pct_of_Total_Voids'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_contrib.iterrows()):\n",
    "    bars2[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars2[i].set_edgecolor('black')\n",
    "    bars2[i].set_linewidth(0.5)\n",
    "\n",
    "ax2.set_yticks(range(len(top_contrib)))\n",
    "ax2.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_contrib.iterrows()], fontsize=9)\n",
    "ax2.set_xlabel('% of Total Void Area', fontsize=11)\n",
    "ax2.set_title('Land Covers Contributing Most to Total Voids\\n(Largest Void Areas)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'voids_by_landcover_charts.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: voids_by_landcover_charts.png\")\n",
    "print(\"\\nVoid analysis complete!\")"
   ],
   "id": "25fa4553895dcd59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VOID ZONES vs LAND COVER - \"SWISS CHEESE\" VISUALIZATION",
   "id": "4b2d47e7bbe85ff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# VOID ZONES vs LAND COVER - \"SWISS CHEESE\" VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# LAND COVER WITH VOIDS - OUTLINED POLYGONS VERSION\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12), facecolor='white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "extent = [xmin_grid, xmax_grid, ymin_grid, ymax_grid]\n",
    "\n",
    "# Get unique land cover classes\n",
    "display_codes = np.unique(corine_10m[(corine_10m > 0) & ~void_mask])\n",
    "\n",
    "print(\"Vectorizing land cover polygons (this may take a moment)...\")\n",
    "im = ax.imshow(corine_display, cmap=cmap, norm=norm, origin='upper', extent=extent, alpha = 0.2)\n",
    "\n",
    "# Process each land cover class\n",
    "for lc_code in sorted(display_codes):\n",
    "    # Create mask: this land cover AND has SAOCOM coverage (not void)\n",
    "    lc_with_coverage = (corine_10m == lc_code) & (~void_mask)\n",
    "\n",
    "    # Vectorize to get boundaries\n",
    "    mask_shapes = shapes(lc_with_coverage.astype(np.uint8),\n",
    "                        mask=lc_with_coverage,\n",
    "                        transform=target_transform)\n",
    "\n",
    "    # Convert to shapely polygons\n",
    "    polys = [shape(geom) for geom, val in mask_shapes if val == 1]\n",
    "\n",
    "    # Get color for this land cover\n",
    "    fill_color = CORINE_COLORS_MPL.get(lc_code, (0.5, 0.5, 0.5))\n",
    "\n",
    "    # Draw each polygon\n",
    "    for poly in polys:\n",
    "        if poly.is_valid:\n",
    "            x, y = poly.exterior.xy\n",
    "\n",
    "            # Very faint fill\n",
    "            ax.fill(x, y, color=fill_color, alpha=0.15, edgecolor='none', zorder=1)\n",
    "\n",
    "            # Colored outline\n",
    "            ax.plot(x, y, color=fill_color, linewidth=1.5, alpha=0.9, zorder=2)\n",
    "\n",
    "# Study area boundary (on top)\n",
    "hull_gdf.boundary.plot(ax=ax, color='black', linewidth=2.5, linestyle='--', zorder=3)\n",
    "\n",
    "# Statistics\n",
    "void_area = np.sum(void_mask) * (GRID_SIZE**2) / 1e6\n",
    "total_area = np.sum(study_area_mask) * (GRID_SIZE**2) / 1e6\n",
    "pct_void = 100 * np.sum(void_mask) / np.sum(study_area_mask)\n",
    "\n",
    "stats_text = f\"\"\"Void Area: {void_area:.2f} km²\n",
    "Coverage Area: {total_area - void_area:.2f} km²\n",
    "Void %: {pct_void:.1f}%\n",
    "Coverage %: {100 - pct_void:.1f}%\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=13,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white',\n",
    "        alpha=0.9, edgecolor='black'), zorder=4)\n",
    "# Legend\n",
    "legend_elements = []\n",
    "for code in sorted(display_codes):\n",
    "    color = CORINE_COLORS_MPL.get(code, (0.5, 0.5, 0.5))\n",
    "    legend_elements.append(mpatches.Rectangle((0,0),1,1,\n",
    "                                             facecolor=color,\n",
    "                                             edgecolor=color,\n",
    "                                             alpha=0.3,\n",
    "                                             linewidth=2,\n",
    "                                             label=f\"{code}: {CORINE_CLASSES.get(code, 'Unknown')}\"))\n",
    "\n",
    "legend_elements.append(mpatches.Rectangle((0,0),1,1,\n",
    "                                         facecolor='white',\n",
    "                                         edgecolor='gray',\n",
    "                                         linewidth=1,\n",
    "                                         label='VOID (No SAOCOM Data)'))\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "         fontsize=13, frameon=True, fancybox=False, edgecolor='black',\n",
    "         title='Land Cover Classes')\n",
    "\n",
    "ax.set_title('CORINE Land Cover with SAOCOM Void Zones\\n(White areas = No coverage)',\n",
    "             fontweight='bold', fontsize=14, pad=15)\n",
    "ax.set_xlabel('UTM Easting (m)', fontsize=11)\n",
    "ax.set_ylabel('UTM Northing (m)', fontsize=11)\n",
    "ax.set_xlim(extent[0], extent[1])\n",
    "ax.set_ylim(extent[2], extent[3])\n",
    "ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'landcover_with_voids_outlined.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: landcover_with_voids_outlined.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. BAR CHART WITH REFERENCE LINES\n",
    "# =============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), facecolor='white')\n",
    "\n",
    "# Chart 1: % of each land cover that is void\n",
    "top_pct = void_lc_df.nlargest(15, 'Pct_LC_is_Void')\n",
    "bars1 = ax1.barh(range(len(top_pct)), top_pct['Pct_LC_is_Void'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_pct.iterrows()):\n",
    "    bars1[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars1[i].set_edgecolor('black')\n",
    "    bars1[i].set_linewidth(0.5)\n",
    "\n",
    "ax1.set_yticks(range(len(top_pct)))\n",
    "ax1.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_pct.iterrows()], fontsize=9)\n",
    "ax1.set_xlabel('% of Land Cover Class that is Void', fontsize=11)\n",
    "ax1.set_title('Land Covers with Highest Void Percentage\\n(Worst Coverage Performance)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add reference lines\n",
    "ax1.axvline(100, color='black', linestyle='-', linewidth=2, label='100% (Total Void)', zorder=3)\n",
    "for pct in [20, 40, 60, 80]:\n",
    "    ax1.axvline(pct, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, zorder=3)\n",
    "    ax1.text(pct, -0.5, f'{pct}%', ha='center', fontsize=9, color='gray')\n",
    "\n",
    "ax1.set_xlim(0, 105)\n",
    "# ax1.legend(loc='lower right')\n",
    "\n",
    "# Chart 2: Contribution to total voids\n",
    "top_contrib = void_lc_df.nlargest(15, 'Pct_of_Total_Voids')\n",
    "bars2 = ax2.barh(range(len(top_contrib)), top_contrib['Pct_of_Total_Voids'])\n",
    "\n",
    "for i, (_, row) in enumerate(top_contrib.iterrows()):\n",
    "    bars2[i].set_color(CORINE_COLORS_MPL.get(row['LC_Code'], (0.5, 0.5, 0.5)))\n",
    "    bars2[i].set_edgecolor('black')\n",
    "    bars2[i].set_linewidth(0.5)\n",
    "\n",
    "ax2.set_yticks(range(len(top_contrib)))\n",
    "ax2.set_yticklabels([f\"{row['LC_Code']}: {row['LC_Name'][:35]}\"\n",
    "                      for _, row in top_contrib.iterrows()], fontsize=9)\n",
    "ax2.set_xlabel('% of Total Void Area', fontsize=11)\n",
    "ax2.set_title('Land Covers Contributing Most to Total Voids\\n(Largest Void Areas)',\n",
    "              fontweight='bold', fontsize=12)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'voids_by_landcover_charts.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: voids_by_landcover_charts.png\")\n",
    "print(\"\\nVoid analysis complete!\")"
   ],
   "id": "cfc36e8c939c80c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### INDIVIDUAL LAND COVER MAPS WITH VOID VISUALIZATION",
   "id": "fb0645c338d3dfdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# 1. PRE-CALCULATE ALL STATISTICS (DERIVED FROM \"SWISS CHEESE\" DATA)\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Calculating statistics for all land cover classes...\")\n",
    "\n",
    "# Get unique classes present in the data\n",
    "unique_classes = np.unique(corine_10m[corine_10m > 0])\n",
    "\n",
    "summary_data = []\n",
    "for lc_code in sorted(unique_classes):\n",
    "    # Create masks from the main \"swiss cheese\" arrays\n",
    "    lc_mask = (corine_10m == lc_code)\n",
    "    lc_total_pixels = np.sum(lc_mask)\n",
    "\n",
    "    if lc_total_pixels > 0:\n",
    "        lc_void_pixels = np.sum(lc_mask & void_mask)\n",
    "        lc_coverage_pixels = lc_total_pixels - lc_void_pixels\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_area_km2 = lc_total_pixels * (GRID_SIZE**2) / 1e6\n",
    "        coverage_area_km2 = lc_coverage_pixels * (GRID_SIZE**2) / 1e6\n",
    "        void_area_km2 = lc_void_pixels * (GRID_SIZE**2) / 1e6\n",
    "\n",
    "        pct_coverage = 100 * lc_coverage_pixels / lc_total_pixels\n",
    "        pct_void = 100 * lc_void_pixels / lc_total_pixels\n",
    "        pct_of_study_area = 100 * lc_total_pixels / np.sum(corine_10m > 0)\n",
    "\n",
    "        summary_data.append({\n",
    "            'LC_Code': lc_code,\n",
    "            'LC_Name': CORINE_CLASSES.get(lc_code, f'Class {lc_code}'),\n",
    "            'Total_km2': total_area_km2,\n",
    "            'Coverage_km2': coverage_area_km2,\n",
    "            'Void_km2': void_area_km2,\n",
    "            'Pct_Coverage': pct_coverage,\n",
    "            'Pct_Void': pct_void,\n",
    "            'Pct_of_Study_Area': pct_of_study_area\n",
    "        })\n",
    "\n",
    "# Create the master DataFrame with all stats\n",
    "stats_df = pd.DataFrame(summary_data)\n",
    "stats_df = stats_df.sort_values(by='Pct_Void', ascending=False) # Sort by worst coverage\n",
    "\n",
    "print(\"✓ Statistics DataFrame created.\")\n",
    "print(stats_df.to_string(index=False, float_format=\"%.2f\"))\n",
    "\n",
    "print(f\"\\nGenerating {len(stats_df)} land cover maps using pre-calculated stats...\")\n",
    "\n",
    "# Loop through the DataFrame, one row per land cover class\n",
    "for index, row in stats_df.iterrows():\n",
    "    lc_code = row['LC_Code']\n",
    "    class_name = row['LC_Name']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Display Sentinel RGB as background\n",
    "    ax.imshow(sentinel_rgb_norm, extent=[xmin_grid, xmax_grid, ymin_grid, ymax_grid],\n",
    "              origin='upper', alpha=0.4)\n",
    "\n",
    "    fill_color = tuple(c/255 for c in CORINE_COLORS.get(lc_code, (128, 128, 128)))\n",
    "\n",
    "    # --- Visualization (Masking and Vectorizing is still required here) ---\n",
    "    lc_mask = (corine_10m == lc_code)\n",
    "\n",
    "    # 1. Draw COVERAGE areas (with data)\n",
    "    lc_with_coverage = lc_mask & (~void_mask)\n",
    "    if np.any(lc_with_coverage):\n",
    "        coverage_shapes = shapes(lc_with_coverage.astype(np.uint8), mask=lc_with_coverage, transform=target_transform)\n",
    "        for geom, val in coverage_shapes:\n",
    "            if val == 1:\n",
    "                poly = shape(geom)\n",
    "                if poly.is_valid:\n",
    "                    x, y = poly.exterior.xy\n",
    "                    ax.fill(x, y, color=fill_color, alpha=0.35, edgecolor='none', hatch='///')\n",
    "                    ax.plot(x, y, color='black', linewidth=2.0)\n",
    "                    ax.plot(x, y, color=fill_color, linewidth=1.2)\n",
    "\n",
    "    # 2. Draw VOID areas (no data)\n",
    "    lc_void = lc_mask & void_mask\n",
    "    if np.any(lc_void):\n",
    "        void_shapes = shapes(lc_void.astype(np.uint8), mask=lc_void, transform=target_transform)\n",
    "        for geom, val in void_shapes:\n",
    "            if val == 1:\n",
    "                poly = shape(geom)\n",
    "                if poly.is_valid:\n",
    "                    x, y = poly.exterior.xy\n",
    "                    ax.fill(x, y, color='white', alpha=0.8, edgecolor='none', hatch='....')\n",
    "                    ax.plot(x, y, color='red', linewidth=1.5, linestyle='--')\n",
    "                    ax.plot(x, y, color='gray', linewidth=0.8, linestyle='--')\n",
    "\n",
    "    hull_gdf.boundary.plot(ax=ax, color='black', linewidth=3, linestyle='-')\n",
    "\n",
    "    # --- Use Pre-Calculated Stats for Title and Text ---\n",
    "    ax.set_title(\n",
    "        f\"Land Cover: {class_name} (Code {lc_code})\\n\"\n",
    "        f\"Total: {row['Total_km2']:.1f} km² ({row['Pct_of_Study_Area']:.1f}% of study area) | \"\n",
    "        f\"Coverage: {row['Coverage_km2']:.1f} km² ({row['Pct_Coverage']:.1f}%) | \"\n",
    "        f\"Void: {row['Void_km2']:.1f} km² ({row['Pct_Void']:.1f}%)\",\n",
    "        fontweight='bold', fontsize=12, pad=15\n",
    "    )\n",
    "\n",
    "    stats_text = (\n",
    "        f\"Coverage: {row['Pct_Coverage']:.1f}%\\n\"\n",
    "        f\"Void: {row['Pct_Void']:.1f}%\\n\"\n",
    "        f\"Area w/ data: {row['Coverage_km2']:.1f} km²\\n\"\n",
    "        f\"Area w/o data: {row['Void_km2']:.1f} km²\"\n",
    "    )\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='black'))\n",
    "\n",
    "    # --- Legend ---\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=fill_color, edgecolor='black', linewidth=2, alpha=0.35, hatch='///', label=f'{class_name} (Coverage)'),\n",
    "        Patch(facecolor='white', edgecolor='red', linewidth=1.5, alpha=0.8, hatch='....', linestyle='--', label=f'{class_name} (Void/No Data)'),\n",
    "        Patch(facecolor='none', edgecolor='black', linewidth=3, label='Study Area Boundary')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10, frameon=True, fancybox=False, edgecolor='black', title='Legend')\n",
    "\n",
    "    ax.set_xlabel('UTM Easting (m)')\n",
    "    ax.set_ylabel('UTM Northing (m)')\n",
    "    ax.grid(True, alpha=0.3, color='gray', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save File ---\n",
    "    safe_name = class_name.replace(' ', '_').replace(',', '').replace('/', '_')\n",
    "    filename = f'landcover_{lc_code}_{safe_name}_coverage_void.png'\n",
    "    plt.savefig(RESULTS_DIR / filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(stats_df)} land cover maps.\")\n",
    "print(f\"All maps saved to: {RESULTS_DIR}\")"
   ],
   "id": "5d96be91dab3fa96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Land cover histograms",
   "id": "f0eec84a041ef2aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Re-define necessary variables and functions from your notebook\n",
    "# =============================================================================\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "NODATA = -9999\n",
    "CORINE_CLASSES = {\n",
    "    111: 'Continuous urban fabric', 112: 'Discontinuous urban fabric',\n",
    "    121: 'Industrial or commercial units', 122: 'Road and rail networks and associated land',\n",
    "    123: 'Port areas', 124: 'Airports', 131: 'Mineral extraction sites',\n",
    "    132: 'Dump sites', 133: 'Construction sites', 141: 'Green urban areas',\n",
    "    142: 'Sport and leisure facilities', 211: 'Non-irrigated arable land',\n",
    "    212: 'Permanently irrigated land', 213: 'Rice fields', 221: 'Vineyards',\n",
    "    222: 'Fruit trees and berry plantations', 223: 'Olive groves',\n",
    "    231: 'Pastures', 241: 'Annual crops associated with permanent crops',\n",
    "    242: 'Complex cultivation patterns', 243: 'Agriculture/natural vegetation mix',\n",
    "    244: 'Agro-forestry areas', 311: 'Broad-leaved forest',\n",
    "    312: 'Coniferous forest', 313: 'Mixed forest', 321: 'Natural grasslands',\n",
    "    322: 'Moors and heathland', 323: 'Sclerophyllous vegetation',\n",
    "    324: 'Transitional woodland-shrub', 331: 'Beaches, dunes, sands',\n",
    "    332: 'Bare rocks', 333: 'Sparsely vegetated areas', 334: 'Burnt areas',\n",
    "    335: 'Glaciers and perpetual snow', 411: 'Inland marshes',\n",
    "    412: 'Peat bogs', 421: 'Salt marshes', 422: 'Salines',\n",
    "    423: 'Intertidal flats', 511: 'Water courses', 512: 'Water bodies',\n",
    "    521: 'Coastal lagoons', 522: 'Estuaries', 523: 'Sea and ocean'\n",
    "}\n",
    "\n",
    "# Assuming 'corine_10m_masked.tif' is in the RESULTS_DIR from previous cells\n",
    "corine_masked_path = RESULTS_DIR / \"corine_10m_masked.tif\"\n",
    "with rasterio.open(corine_masked_path) as src:\n",
    "    corine_10m = src.read(1)\n",
    "    target_transform = src.transform\n",
    "    grid_height, grid_width = src.height, src.width\n",
    "\n",
    "# Helper function from your notebook\n",
    "def plot_distribution(ax, diff_series, title, metrics):\n",
    "    \"\"\"Helper function to plot a single residual distribution histogram.\"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "    ax.hist(diff_series, bins=20, alpha=0.75, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', label='Zero')\n",
    "    ax.axvline(metrics['mean_diff'], color='green', linestyle='-', label=f\"Mean: {metrics['mean_diff']:+.2f}m\")\n",
    "\n",
    "    stats_text = (f\"n = {metrics['n_points']:,}\\n\"\n",
    "                  f\"RMSE = {metrics['rmse']:.2f} m\\n\"\n",
    "                  f\"NMAD = {metrics['nmad']:.2f} m\\n\"\n",
    "                  f\"Std Dev = {metrics['std_diff']:.2f} m\")\n",
    "\n",
    "    ax.text(0.98, 0.97, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Elevation Difference (m)', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Sample CORINE Land Cover at SAOCOM point locations\n",
    "# =============================================================================\n",
    "landcover_values = []\n",
    "for idx, row in saocom_gdf.iterrows():\n",
    "    row_idx, col_idx = rowcol(target_transform, row.geometry.x, row.geometry.y)\n",
    "    if 0 <= row_idx < grid_height and 0 <= col_idx < grid_width:\n",
    "        lc_val = corine_10m[row_idx, col_idx]\n",
    "        landcover_values.append(lc_val if lc_val != 0 else np.nan)\n",
    "    else:\n",
    "        landcover_values.append(np.nan)\n",
    "\n",
    "saocom_gdf['landcover'] = landcover_values\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Create points dataframes with landcover information\n",
    "# =============================================================================\n",
    "\n",
    "# SAOCOM - TINITALY\n",
    "points_tin = saocom_gdf[['HEIGHT_ABSOLUTE_TIN', 'tinitaly_height', 'landcover']].copy()\n",
    "points_tin.dropna(inplace=True)\n",
    "points_tin['diff'] = points_tin['HEIGHT_ABSOLUTE_TIN'] - points_tin['tinitaly_height']\n",
    "\n",
    "# SAOCOM - Copernicus\n",
    "points_cop = saocom_gdf[['HEIGHT_ABSOLUTE_COP', 'copernicus_height', 'landcover']].copy()\n",
    "points_cop.dropna(inplace=True)\n",
    "points_cop['diff'] = points_cop['HEIGHT_ABSOLUTE_COP'] - points_cop['copernicus_height']\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Group by landcover and calculate metrics\n",
    "# =============================================================================\n",
    "\n",
    "landcover_groups_tin = points_tin.groupby('landcover')\n",
    "landcover_groups_cop = points_cop.groupby('landcover')\n",
    "\n",
    "metrics_by_landcover = {}\n",
    "\n",
    "unique_landcovers = sorted(points_tin['landcover'].unique())\n",
    "\n",
    "for lc_code in unique_landcovers:\n",
    "    if np.isnan(lc_code):\n",
    "        continue\n",
    "    lc_name = CORINE_CLASSES.get(lc_code, f'Unknown ({lc_code})')\n",
    "    metrics_by_landcover[lc_name] = {}\n",
    "\n",
    "    # TINITALY metrics\n",
    "    if lc_code in landcover_groups_tin.groups:\n",
    "        group_tin = landcover_groups_tin.get_group(lc_code)\n",
    "        diff_tin = group_tin['diff']\n",
    "        metrics_by_landcover[lc_name]['tin'] = {\n",
    "            'n_points': len(diff_tin),\n",
    "            'rmse': np.sqrt(np.mean(diff_tin**2)),\n",
    "            'nmad': stats.median_abs_deviation(diff_tin, scale='normal'),\n",
    "            'mean_diff': np.mean(diff_tin),\n",
    "            'std_diff': np.std(diff_tin),\n",
    "            'diff_series': diff_tin\n",
    "        }\n",
    "\n",
    "    # Copernicus metrics\n",
    "    if lc_code in landcover_groups_cop.groups:\n",
    "        group_cop = landcover_groups_cop.get_group(lc_code)\n",
    "        diff_cop = group_cop['diff']\n",
    "        metrics_by_landcover[lc_name]['cop'] = {\n",
    "            'n_points': len(diff_cop),\n",
    "            'rmse': np.sqrt(np.mean(diff_cop**2)),\n",
    "            'nmad': stats.median_abs_deviation(diff_cop, scale='normal'),\n",
    "            'mean_diff': np.mean(diff_cop),\n",
    "            'std_diff': np.std(diff_cop),\n",
    "            'diff_series': diff_cop\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Generate and save histograms for each landcover\n",
    "# =============================================================================\n",
    "\n",
    "for lc_name, metrics in metrics_by_landcover.items():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7), facecolor='white')\n",
    "    fig.suptitle(f'Residual Distributions for Landcover: {lc_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    if 'tin' in metrics:\n",
    "        plot_distribution(axes[0], metrics['tin']['diff_series'], 'SAOCOM - TINITALY', metrics['tin'])\n",
    "    else:\n",
    "        axes[0].set_title('SAOCOM - TINITALY\\n(No Data)', fontweight='bold', fontsize=14)\n",
    "        axes[0].set_facecolor('lightgray')\n",
    "\n",
    "\n",
    "    if 'cop' in metrics:\n",
    "        plot_distribution(axes[1], metrics['cop']['diff_series'], 'SAOCOM - Copernicus', metrics['cop'])\n",
    "    else:\n",
    "        axes[1].set_title('SAOCOM - Copernicus\\n(No Data)', fontweight='bold', fontsize=14)\n",
    "        axes[1].set_facecolor('lightgray')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Sanitize filename\n",
    "    safe_lc_name = lc_name.replace('/', '_').replace(' ', '_').lower()\n",
    "    plt.savefig(RESULTS_DIR / f'saocom_residuals_{safe_lc_name}.png', dpi=300, facecolor='white')\n",
    "    plt.show()"
   ],
   "id": "fc12c828c6c60f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Assuming 'saocom_gdf_lc', 'RESULTS_DIR', etc., are pre-loaded ---\n",
    "\n",
    "# =============================================================================\n",
    "# 1. DEFINE A ROBUST SCATTER PLOTTING FUNCTION\n",
    "# =============================================================================\n",
    "def plot_scatter_comparison(ax, x_data, y_data, x_label, y_label, title, global_lims):\n",
    "    \"\"\"\n",
    "    Creates a 1:1 scatter plot with consistent axes and statistics.\n",
    "    \"\"\"\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # --- Clean data and calculate stats ---\n",
    "    valid_mask = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "    x_val, y_val = x_data[valid_mask], y_data[valid_mask]\n",
    "\n",
    "    if len(x_val) > 1:\n",
    "        n_points = len(x_val)\n",
    "        bias = np.mean(y_val - x_val)\n",
    "        rmse = np.sqrt(mean_squared_error(x_val, y_val))\n",
    "        correlation = np.corrcoef(x_val, y_val)[0, 1]\n",
    "        stats_text = (f\"n = {n_points:,}\\n\"\n",
    "                      f\"Bias = {bias:.2f} m\\n\"\n",
    "                      f\"RMSE = {rmse:.2f} m\\n\"\n",
    "                      f\"Corr (r) = {correlation:.3f}\")\n",
    "    else:\n",
    "        stats_text = \"Not enough data\"\n",
    "\n",
    "    # --- Plotting ---\n",
    "    ax.scatter(x_val, y_val, s=2, alpha=0.4, c='steelblue')\n",
    "    ax.plot(global_lims, global_lims, 'r--', linewidth=2, label='1:1 Line', zorder=10)\n",
    "    ax.set_xlim(global_lims)\n",
    "    ax.set_ylim(global_lims)\n",
    "\n",
    "    # --- Annotation and Styling ---\n",
    "    ax.text(0.04, 0.96, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='black'))\n",
    "    ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel(x_label, fontsize=11)\n",
    "    ax.set_ylabel(y_label, fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CALCULATE GLOBAL AXIS LIMITS FOR CONSISTENCY\n",
    "# =============================================================================\n",
    "# Combine all height data to find the absolute min and max\n",
    "all_heights = pd.concat([\n",
    "    saocom_gdf_lc['HEIGHT_ABSOLUTE_TIN'],\n",
    "    saocom_gdf_lc['tinitaly_height'],\n",
    "    saocom_gdf_lc['copernicus_height']\n",
    "]).dropna()\n",
    "all_heights = np.array([i for i in all_heights if i != -9999])\n",
    "print(sorted(all_heights)[0])\n",
    "min_lim = all_heights.min()\n",
    "max_lim = all_heights.max()\n",
    "print(min_lim, max_lim)\n",
    "buffer = (max_lim - min_lim) * 0.05  # 5% buffer\n",
    "\n",
    "# Define the global limits to be used in all plots\n",
    "global_axis_lims = [min_lim - buffer, max_lim + buffer]\n",
    "\n",
    "# =============================================================================\n",
    "# 3. LOOP THROUGH EACH LAND COVER TYPE AND CREATE PLOTS\n",
    "# =============================================================================\n",
    "# Get a sorted list of unique land cover types\n",
    "unique_land_covers = sorted(saocom_gdf_lc['land_cover'].unique())\n",
    "\n",
    "for lc_name in unique_land_covers:\n",
    "    # Create a new figure for each land cover type\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7.5), facecolor='white')\n",
    "    fig.suptitle(f'Height Comparison for Land Cover: {lc_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Filter the data for the current land cover\n",
    "    subset_gdf = saocom_gdf_lc[saocom_gdf_lc['land_cover'] == lc_name]\n",
    "\n",
    "    # --- Plot 1: SAOCOM vs TINITALY ---\n",
    "    if not subset_gdf['tinitaly_height'].dropna().empty:\n",
    "        plot_scatter_comparison(axes[0],\n",
    "                                x_data=subset_gdf['tinitaly_height'],\n",
    "                                y_data=subset_gdf['HEIGHT_ABSOLUTE_TIN'],\n",
    "                                x_label='TINITALY Height (m)',\n",
    "                                y_label='SAOCOM Height (m)',\n",
    "                                title='SAOCOM vs TINITALY',\n",
    "                                global_lims=global_axis_lims)\n",
    "    else:\n",
    "        axes[0].set_title('SAOCOM vs TINITALY\\n(No Data)', fontweight='bold')\n",
    "        axes[0].set_facecolor('lightgray')\n",
    "        axes[0].set_aspect('equal', 'box')\n",
    "\n",
    "\n",
    "    # --- Plot 2: SAOCOM vs Copernicus ---\n",
    "    if not subset_gdf['copernicus_height'].dropna().empty:\n",
    "        plot_scatter_comparison(axes[1],\n",
    "                                x_data=subset_gdf['copernicus_height'],\n",
    "                                y_data=subset_gdf['HEIGHT_ABSOLUTE_TIN'],\n",
    "                                x_label='Copernicus Height (m)',\n",
    "                                y_label='SAOCOM Height (m)',\n",
    "                                title='SAOCOM vs Copernicus',\n",
    "                                global_lims=global_axis_lims)\n",
    "    else:\n",
    "        axes[1].set_title('SAOCOM vs Copernicus\\n(No Data)', fontweight='bold')\n",
    "        axes[1].set_facecolor('lightgray')\n",
    "        axes[1].set_aspect('equal', 'box')\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.94])\n",
    "\n",
    "    # Sanitize filename and save the figure\n",
    "    safe_lc_name = lc_name.replace('/', '_').replace(' ', '_').lower()\n",
    "    plt.savefig(RESULTS_DIR / f'saocom_scatter_comparison_{safe_lc_name}.png', dpi=300, facecolor='white')\n",
    "    plt.show()"
   ],
   "id": "bce9c16a9dae7ef8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2371ed16e956627b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
